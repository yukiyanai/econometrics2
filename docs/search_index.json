[
["index.html", "KUT 計量経済学応用 統計的因果推論入門 はじめに 0.1 この資料について 0.2 履修条件 0.3 R とRStudio のインストール 0.4 授業計画", " KUT 計量経済学応用 統計的因果推論入門 矢内 勇生 2020-06-22 更新（2020-06-07 公開） はじめに 0.1 この資料について この資料は、高知工科大学 (KUT) 経済・マネジメント学群で2020年度に開講する「計量経済学応用」の補助教材である。 受講生は、以下の3点に注意されたい。 この資料は、授業の進捗にあわせてアップデートされる。 公開時点（2Q開始時点）では、すべてのトピックの説明が完成していない。 各トピックの説明は順次追加する。 一度アップロードしたトピックの内容を修正するときは、Slack でアナウンスする。 ただし、誤字・脱字等については気付いたらアナウンスせずに修正する。 この資料以外の授業資料（解説音声付きスライドや配布資料など）は、KUTLMS (Moodle) にアップロードする。 この資料以外に教科書が必要である。 教科書：安井翔太. 2020.『効果検証入門：正しい比較のための因果推論/計量経済学の基礎』（技術評論社） 購入するのは電子版（たとえば、Kindle版）でも良い。 0.2 履修条件 この授業は、「計量経済学」（とその前提となる「統計学2」）を履修済みであることを前提に進める。そのため、この授業（この資料）では： 基本的な統計用語・統計量（例：分散、共分散、最小二乗推定量、有意水準）や基本的な手続き（例：仮説検定）は説明しない。 R とRStudio の基本的な使い方は説明しない。以下を思い出しておくこと。 RStudio のプロジェクト機能の使い方。 ggplot2 による作図の方法。 RMarkdownの書き方。特に、文章とコードチャンクの使い分け。 これらの点に不安がある場合は、2Qの早い時期（6月の第3週頃まで）に自分で計量経済学の内容を学習（復習）するか、今年度の3Qに「計量経済学」を受講してから、来年度の「計量経済学応用」を受講すること。自分で学習する場合は、最低でも浅野正彦・矢内勇生『Rによる計量政治学』（2018年、オーム社）の第4章から第14章までの内容を学習すること。 0.3 R とRStudio のインストール RとRStudio を自分のパソコンにインストールして使いたい場合は、私が作った以下の資料を参照されたい。 Linux (Ubuntu) 編 (PDF, 4.6MB) macOS 編 (PDF, 4.9MB) Windows 編 （PDF, 5.8MB) 0.4 授業計画 以下の内容を扱う予定である（カッコ内は何回目の授業で扱うかの目安）。 イントロダクション（第1回） セレクションバイアス（第2回） RCT（第3回） 回帰分析（第4回、第5回） 傾向スコア（第6回、第7回） パネルデータ分析（第8回、第9回） 分析計画のプレゼンテーション（第10回） 回帰不連続デザイン（第11回、第12回） 操作変数法（第13回、第14回） 分析結果のプレゼンテーション（第15回） 各トピックの参考文献や予習課題については、シラバス（PDFファイル） を参照されたい。 この資料は上に挙げたトピック単位で作成している。各トピックに例として書かれたRコードは、トピックを途中から実行することを想定していない。たとえば、1.3.6節に書いてあるコードを実行するためには、トピック1の冒頭から 順番にRコードを実行する必要がある。途中のコードだけ実行しても動かない可能性が高い。 他方、各トピックは独立に実行できる。例えば、トピック3に書かれているコードを実行するために、トピック2に書かれたRコードを実行する必要はない。トピック3の冒頭から実行すれば十分である。 ただし、トピック1の内容は全員1度は実行済みであると仮定する。1度実行すれば、Rをインストールし直すか、バージョンアップするまで再度実行する必要はない。 "],
["introduction.html", "Topic 1 イントロダクション 1.1 予習と講義動画の視聴 1.2 Slack 1.3 RStudio Cloud の初期設定 1.4 トピック1の課題", " Topic 1 イントロダクション 1.1 予習と講義動画の視聴 トピック1でやるべきことは、以下のとおりである。 シラバス(PDFファイル) をよく読む。遠隔授業に変更になったことにより、大学の公式サイトに載っているものとは内容が異なるので、このリンクにある最新のPDF版を読むこと。 KUTLMS (Moodle) にあるトピック1の講義動画を視聴する。 この資料の続きを読み、トピック2以降の授業に備える。 特に、最後の課題を忘れずに。 1.2 Slack 1.2.1 Slack とは？ この授業では、担当教員と受講生の間、あるいは受講生同士の間の連絡手段として、Slack を使う。この授業には無料版で十分なので、間違って支払いをしないように注意。 授業に関連する連絡や、オフィスアワー以外の質問の受付はすべてSlack で行うので、必ずSlackが使えるようにしておくこと。準備期間として6月18日まではメールでの質問も受け付けるが、その後は基本的にメールでの質問は受け付けない（とは言っても、実際にはメールに気付けば回答する。メールはたまにしかチェックしない上に、知らない人からのメール（送信者名が設定されていないメール）や添付ファイルがあるメールは読まないので、メールで質問しても読まれていないと思ったほうがいいというだけのことである。また、Slackのほうが回答が早い）。 スマホ用のアプリもあるが、課題の提出とフィードバック（つまり、ファイルの送受信）に利用するので、パソコンで使えるようにしておくこと。パソコンでは、パソコン用のアプリを使うか、アプリをインストールせずにウェブブラウザ上で使うことができる。 Slack を使ったことがないなら、以下の資料が参考になる。 Slack 初心者のためのクイックスタートガイド 【完全初心者向け！】コミュニケーションツールSlack（スラック）の使い方 初心者がSlackを使いこなすために知っておきたい6つのポイント 1.2.2 授業用ワークスペースへの登録 この授業専用のSlack ワークスペース「計量経済学応用」に登録するためのURLは、ポータルから送信済みである（2020年6月8日午前8時に送信）。登録済みでない者は、ポータルのメッセージを確認すること。登録には、KUTのメールアドレス (@ugs.kochi-tech.ac.jp) が必要である。 メンバー登録するときに決める表示名は、匿名でもかまわない（ただし、担当教員はメールアドレスから個人を特定できるので注意）。 KUTのメールアドレスがどうしても使えないという場合は、以下の内容のメールを担当教員宛に送ること（メールアドレスはシラバス・講義スライドに記載されている）。 件名（メールのタイトル）：計量経済学応用 Slack用メールアドレス 本文に以下の内容を記載 氏名 学籍番号 Slackへの登録で使いたいメールアドレス 匿名での登録を希望する場合、希望の「表示名」（後で変更可能; 指定がない場合は本名で登録する） 必要事項が記載されたメールが届いたら登録する。登録確認のメールが届くはずなので、確認すること。 1.2.3 利用上の注意 Slack での発言は授業への参加点に加算するので、積極的に質問してほしい。また、質問だけでなく、他の受講生からの質問に回答したり、Slack 上で議論することも歓迎する（加点する）。対面授業であれば授業中に議論できるが、2020年度の授業は遠隔で実施することになり、毎回 Zoom 等で議論する時間的余裕もない。そこで、Slack で議論の場を設けることとしたい。 また、初めての遠隔授業で担当教員も暗中模索の状態なので、授業の進め方に関する意見も歓迎する。 Slack に投稿する際には以下の点に気をつけてくれると嬉しい（守らなくても減点するわけではない）。 余計な挨拶を毎回書かないこと（メールではないので） 「余計」なものの例： 「お世話になっております」（私の心の声：「早く本題に入って」） 「計量経済学を受講している〇〇です」（「そうでしょうね。名前は表示されてますよ。」） 「経済・マネジメント学群3年の〇〇です」（「経・マネの学生なんて珍しいですね（棒読み）。名前は…(略）」） 「質問してもいいですか？」（「早く質問して」） どの内容についての質問か明確にすること 授業を決められた時間に受ける必要はないので、人によって受講するペースが違うことが想定される：「今日の授業」と言われてもどの授業かわからない 例えば、以下のように質問してくれるとわかりやすい 操作変数法のスライドの、p.15 について質問：（以下、質問の内容） 補助教材の 1.3.3 のカスタマイズについて質問：（以下、質問の内容） 課題4の問3について：（以下、質問の内容） 投稿の際は、適切なチャンネルを選ぶこと 特に、ダイレクトメッセージの場合には、誤った相手に送信しないように注意 提出したファイルが届いたかどうか質問しないで！ Slack上にファイルがアップロードされていることをあなたが確認できれば、私からも見えるのでご心配なく。 この質問の優先順位は最下位に設定する 禁止事項：以下の行為は禁止する 他人を誹謗・中傷するような書き込み 他人の著作物のアップロード これらの行為は学業上の不正行為である。見つけた場合には教務部に報告する。万が一、他の受講生からハラスメント行為を受けた場合は、証拠を保全（スクリーンショットを撮るなど）して担当教員に連絡してほしい。皆さんはもう大学3年生なので、誹謗・中傷（相手を貶める行為）と批判（相手を高めるために、相手の「議論」の弱点を指摘して、改善策を一緒に見つけること）の違いをわきまえましょう。 1.3 RStudio Cloud の初期設定 まず、RStduio Cloud を使うための初期設定をしよう。RStudio Cloud ではなく、自分のパソコンにインストールした（あるいは情報演習室のパソコンにインストールされている）RStudio を使う場合は、自分の環境に合わせて適宜読み替えること。 念のためにもう1度注意しておくが、この授業は「統計学2」と「計量経済学」を受講済みであることを前提にしている。よって、受講生は全員RStudio（デスクトップ版）の基本的な使い方を理解していると仮定して、RStudio Cloud の使い方を説明する。 たとえば、「プロジェクトとは何？」、「パッケージとは何？」という疑問がある人は、この資料を読んでも内容が理解できないかもしれない。そういう人は、「統計学2」や「計量経済学」を先に受講（あるいは復習）してからもう一度挑戦してほしい。 1.3.1 ユーザ登録 RStudio Cloud にアクセスしてログイン (Log In) する。初めて使う場合は、登録（サインアップ [Sign Up]）が必要である。自分で決めたパスワードを忘れないように注意。 1.3.2 授業用のプロジェクトを作る RStudio Cloud のアカウントを作り、無事にログインできたら、この授業で使うプロジェクトを作ろう。 Projects タブを開いて [New Project] ボタンを押せば、新しいプロジェクトを作成することができる。 新規プロジェクトが立ち上がると、画面上部に [Your Workspace / Untitled Project] と表示されるので、“Untitled Project” の部分をクリックしてプロジェクトに名前を（アルファベットと数字で）つけよう。好きな名前をつけて良い。2つ目の計量経済学 (Econometics) の授業なので、“metrics2” などとしておけばいいだろう。 デスクトップ版のRStudio を使う場合は、いつも通りの方法で授業用のプロジェクトを作ろう。 1.3.3 RStudio のカスタマイズ まず、RStudio Cloud を自分が使いやすいようにカスタマイズしよう。[Tools] -&gt; [Global Options] を開いてカスタマイズする。どのようにカスタマイズすべきかについては、RとRStudio のインストール方法を解説した資料 の後半に書いてある。 デスクトップ版とは異なり（実際には、デスクトップ版でも複数のバージョンをインストールしていれば選べるが）、RStudio Cloud ではRのバージョンが選べるので、Global Options の [General] -&gt; [Basic] で、[Default versions of R:] を “R version 3.6.3” に設定しよう。 （この資料を作成した時点での最新版は R 4.0.1 である。大学の情報演習室にインストールされているのが R 3.6.3 であり、今年度中は更新されないので、そちらに合わせる。2020年6月9日現在、自分のパソコンに新たにR をインストールするとバージョンが4.0.1になるはずだが、その場合はその 4.0.1 で問題ない。） 1.3.4 パッケージのインストール 次に、授業で使うことが予想されるパッケージをインストールしてしまおう。 まず、RStuido Cloud で新たにR Markdown ファイルを作成してみよう（File -&gt; New File -&gt; R Markdown）。初めてこれをやると、次のような表示が出るはずだ。 これが表示されたら、[Yes] をクリックしよう。すると、RMarkdown を使うために必要なパッケージがインストールされる。あとはデスクトップ版と同じようにR Markdown ファイルが使える。 続いて、「計量経済学」の授業でも毎回お世話になった tidyverse パッケージをインストールしよう。RStudio Cloud の Console で次のコードを実行する。 install.packages(&quot;tidyverse&quot;) このインストールには少し時間がかかる。待っている間に、tidyverseがggplot2, dplyr, readr などの便利なパッケージをまとめたパッケージ群であることを思い出そう。最近、dplyr のバージョンが上がり、「計量経済学」で勉強したときとは使い方が少し変わっているので注意しよう（授業で説明するので心配無用）。 次に、pacman パッケージをインストールする。 install.packages(&quot;pacman&quot;) pacman パッケージは、パッケージの読み込みとインストールに利用する。 これまでは、install.packages() でパッケージをインストールし、インストール済みのパッケージをlibrary() で読み込んで使っていた。この方法は、今後も引き続き使える。しかし、この方法だと、library() を使うためにはパッケージがインストール済みでなければいけないという問題がある（実際には全然「問題」ではなく、単に面倒だというだけ）。 この問題は。pacman::p_load() を使うことで（ほとんどの場合）解決する。この方法の利点は2つある。 インストール済みでないパッケージを指定すると、（そのパッケージがCRANに登録されていれば）読み込む前にインスト－ルしてくれる。 複数パッケージの読み込みが一度にできる。 試しに、既にインストール済みの tidyverse と、まだインストールしていない（はずの）patchwork、estimatr, devtools, showtextの計5 つのパッケージを同時に読み込んでみよう。 pacman::p_load(tidyverse, patchwork, estimatr, devtools, showtext) patchwork 、estimatr、devtools、showtext の4つのパッケージのインストールと、既にインストール済みのtidyverseを合わせた5つのパッケージの読み込みが完了した。 試しに使ってみよう。 set.seed(321) myd &lt;- tibble(x = rnorm(100), y = rnorm(100)) p1 &lt;- ggplot(myd, aes(x = x, y = after_stat(density))) + geom_histogram(binwidth = 0.25, color = &quot;black&quot;) + ylim(0, 0.6) p2 &lt;- ggplot(myd, aes(x = y, y = after_stat(density))) + geom_histogram(binwidth = 0.25, color = &quot;black&quot;, fill = &quot;dodgerblue&quot;) + ylim(0, 0.6) plot(p1 + p2) tibble とggplot2 (どちらもtidyverseに含まれる) と patchwork が使えることがわかる。 pacman::p_load() で書いたコマンドは、pacman なしだと次のように書かなければならない。 install.pakcages(c(&quot;patchwork&quot;, &quot;estimatr&quot;, &quot;devtools&quot;, &quot;showtext&quot;)) library(tidyverse) library(patchwork) library(esimatr) library(devtools) library(showtext) 複数のパッケージを読み込むだけ（すべてのパッケージがインストール済み）なら次のようにも書けるが、やや面倒だ。 sapply(c(&quot;tidyverse&quot;, &quot;patchwork&quot;, &quot;estimatr&quot;, &quot;devtools&quot;, &quot;showtext&quot;), require, character.only = TRUE) 今後、この授業では pacman::p_laod() でパッケージの読み込みを行う。 ただし、CRANに登録されていないパッケージは手動でインストールする必要がある。GitHub にアップロードされているパッケージは、devtools::install_github() または remotes::install_github() でインストールする。 試しに、宋財泫 (SONG Jaehyun) さんが作って GitHub で公開している BalanceR パッケージをインストールしてみよう。 devtools::install_github(&quot;JaehyunSong/BalanceR&quot;) インストールさえ済めば、pacman::p_load() が使える。 pacman::p_load(BalanceR) CRANに登録されていないパッケージを授業で使う場合は、その都度インストールを指示する。 1.3.5 ディレクトリの作成 授業でよく使うディレクトリ（フォルダ）を作っておこう。（ファイルパスに自分で対応できるなら、ここは自分の好みで変えて良い。） dir.create() で2つのディレクトリを作る。 dir.create(&quot;data&quot;) dir.create(&quot;figs&quot;) 今後、授業で使うデータセットは data ディレクトリに、作成した図は figs ディレクトリに保存する。 1.3.6 図で日本語が使えるようにする 日本語の論文・レポート用に図を作るとき、軸ラベルやタイトルには日本語を使う。RStudio Cloud ではなくデスクトップ版のRStudio を使うとき、Windowsなら特に何もしなくてもggplot2 で日本語が使える（この資料はmacOS で作っているので、図は省略）。 p1_jp &lt;- p1 + labs(y = &quot;確率密度&quot;, title = &quot;ヒストグラム（日本語のテスト）&quot;) plot(p1_jp) Mac でも、次のようにthem_set() で base_family を指定すれば日本語が使える。 theme_set(theme_gray(base_size = 10, base_family = &quot;HiraginoSans-W3&quot;)) p1_jp &lt;- p1 + labs(y = &quot;確率密度&quot;, title = &quot;ヒストグラム（日本語のテスト）&quot;) plot(p1_jp) しかし、RStudio Cloud だと次のような図になってしまう。 この問題に対処するために、日本語が表示できるフォントを使う。次のように指定する。 sysfonts::font_add_google(name = &quot;Noto Sans JP&quot;, family = &quot;noto&quot;) showtext::showtext_auto() theme_set(theme_gray(base_size = 10, base_family = &quot;noto&quot;)) 上のコマンドを実行したら、もう1度図を表示してみる plot(p1_jp) 図は省略するが、RStudio Cloud に表示されている図では、先ほどと同じように日本語が文字化けしているだろう。 しかし、これをファイルに保存すれば、日本語が正しく表示される。 次のコマンドで図をPDFファイルに保存する。（PNGファイルにするには、.pdfを.png に変えれば良い。ただし、上の base_size のところで文字サイズを調整する必要がある。） ggsave(filename = &quot;figs/japanese-test.pdf&quot;, plot = p1_jp, width = 4, height = 3) figs ディレクトリに japanese-test.pdf というファイルができているので、クリックして開いてみよう。日本語が正しく表示されているはずだ。 1.3.7 R Markdown からPDFファイルを作る 統計学2と計量経済学では、R Markdown からHTML ファイルを作る（“knit” する）方法を学んだ。 そのときに少し説明したが、R Markdown からPDF ファイルを作ることもできる。今年度は遠隔授業でファイルによる課題提出が必要になるので、HTMLをブラウザに表示したものを印刷して提出する代わりに、PDFファイルで提出してもらう。（どうしても HTMLしかできなれけば、HTMLブラウザで表示して、表示された内容 を「ファイルに印刷」してPDFファイルを作ってもかまわない。） そこで、R Markdown ファイルからPDFファイルを作る方法を説明する。この方法を身につければ、卒業論文も R Markdown で書ける（草川先生が作ってくれた卒論用テンプレートがある。草川先生に感謝しましょう）。 必要なパッケージをインストールするが、デスクトップ版のRStudio を使っていて、既にLaTeX （TeX Live やMacTeX など）がインストールされているなら、これはインストールしなくて良い（しないほうが良いかも）。 まず、次のコマンドを実行して tinytex をインストールする。 pacman::p_load(tinytex) install_tinytex() デスクトップ版のRStudio を使っている場合は、インストールが完了したら一旦RStudio を終了し、再起動する。 これができたら、.Rmd ファイルのYAMLヘッダを以下のように書けば、本文に日本語を含む PDF ファイルが knit できる（初めてPDFをknitするときは、追加で必要なものがインストールされる [よって、ネット接続が必須] ので時間がかかる。）。date 以下はコピペで良い。 --- title: &quot;計量経済学応用&quot; subtitle: &quot;日本語PDFできるかな&quot; author: &quot;猫好きのRユーザ&quot; date: &quot;`r Sys.Date()`&quot; output: pdf_document: highlight: tango latex_engine: xelatex toc: false header-includes: - \\usepackage{zxjatype} - \\usepackage[haranoaji]{zxjafont} documentclass: bxjsarticle --- ただし、この時点では図の中に日本語があるとエラーが出るので、日本語入りの図がない状態で一度 knit してみよう。（ここでは、haranoaji で原ノ味フォントを指定している。自分で他のフォントが使える状態にできるなら、他のフォントでも良い。例えば、ヒラギノフォント [hiragino-pron] やIPAex フォント [ipaex] などにしても良いだろう。） しかし、RStduio Cloud では、平仮名の「う」がなぜが表示されない（誰か助けて…）。他にも表示されない文字があるかもしない（気付いたら教えてほしい）。この授業では、「う」が表示されていなくても大目に見る（皆さんのせいではないので）。 また、出来上がったPDFファイルをクリックしてダウンロードすると、ファイル名が file_show に代わり、ファイル名拡張子もなくなっている。これはファイルをダウンロードした後に自分でファイル名を付け直す（.pdf も忘れずに）か、次の手順でファイルをダウンロードすれば良い（ggplotで作った図をPDFにした場合にも、この方法を使う）。 RStudio Cloud の[Files] タブで、ファイル名の左にあるチェックボックスにチェックをつける。 [More] -&gt; [Export] を選択する。 正しいファイル名が表示されていることを確認して [Download] をクリックする。 日本語を使った図が含まれるR Markdown ファイルをPDF にknit するためには、次のようなRチャンクをR Markdown ファイルの最初のほう（YAML ヘッダのすぐ後）に書いておく。 ```{r global_option, include = FALSE} knitr::opts_chunk$set(warning = FALSE, echo = TRUE, message = FALSE, fig.height = 3, fig.width = 4, dev = &quot;cairo_pdf&quot;) ``` ここで重要なのは、 dev = \"cairo_pdf\" を指定することである。 また、デスクトップ版のRStudioでは、PDFに日本語の図を入れる際に日本語フォントの指定が必要である。 （Macを使っていてXQuartz もインストールされているなら、cairo_pdf の代わりに quartz_pdf も使える。） Macならいつも通りに、 theme_set(theme_gray(base_size = 10, base_family = &quot;HiraginoSans-W3&quot;)) と、書く。 Windows でも、PDF をknit する場合には同様の作業が必要である。ヒラギノフォントが使えないので、次のようにする。 theme_set(theme_gray(base_size = 10, base_family = &quot;Meiryo&quot;)) Ubuntuの場合は、（IPAex フォントがあるという前提で）次のようにする。 theme_set(theme_gray(base_size = 10, base_family = &quot;ipaex&quot;)) これらのうち、自分のOSに合ったもの1つを、tidyverse（または ggplot2） パッケージを読み込んだ直後に一度書いておけばよい。これで、図に日本語が含まれていても PDFがknit される。 ただし、RStudio Cloud を使っている場合は、これでも文字化けが直らない。文字化けした図が表示されるようになるだけである。このように、RStudio Cloud は日本語の処理に難がある。 この授業では、図のラベルや凡例などはすべて英語でも減点しない。意味がわかればローマ字 でも良い （例：Mitsudo）。しかし、これは不便なので、やはり自分のパソコンにRとRStudio をインストールして使ったほうが良いだろう。インストール手順については、ココ にある資料を参照。 .Rmd ファイルのサンプルをRStudio Cloud 上の KUT_R プロジェクト に 置いておくので、必要なら自分のOS用のファイルをダウンロードして中身を確認されたい。 macOS用：jpntest_mac.Rmd Ubuntu用：jpntest_ubuntu.Rmd Windows用：jpntest_win.Rmd RStudio Cloud用：jpntest_cloud.Rmd （図の日本語は文字化けする） RStudio Cloud を閉じるとき、ブラウザ（あるいはタブ）を閉じてもRセッションが終了しないので、コンソールにq(\"no\")と入力してRを終了しよう。 1.4 トピック1の課題 上のサンプル（.Rmd ファイル）を参考にして、R Markdown ファイルから PDFファイルを作りなさい。その際、以下の指示を守ること。 図をヒストグラム以外（例えば、バイオリン図や散布図など）に変えなさい。 図の説明を日本語で加えなさい（1文で十分）。 ヘッダ部分に、自分の氏名を書きなさい。 サブタイトルは、「課題1」に変えなさい。 提出するファイル名：metrics2_hw01_LastFirst.pdf LastFirstの部分を自分の名前に変えること。 例：metrics2_hw01_YanaiYuki.pdf 提出期限：2020年6月19日午後5時（日本時間） 提出方法：Slack のダイレクトメッセージで矢内に送る。 "],
["selection-bias.html", "Topic 2 セレクションバイアス 2.1 準備 2.2 セレクションバイアスのシミュレーション 2.3 トピック2の課題", " Topic 2 セレクションバイアス トピック2の講義スライド (PDF, 2.6MB) 2.1 準備 2.1.1 予習、講義動画、実習課題 このトピックでやるべきことは、以下のとおりである。 シラバス(PDFファイル) に記載されているトピック2の予習課題を読む。 KUTLMS (Moodle) にあるトピック2の講義動画を視聴する。 この資料の続きを読み、Rを使った実習を行うことでセレクションバイアスの理解を深める。 まず、書いてあるコードをそのまま実行する。 自分で数字（シミュレーションの条件）を変えて、結果がどう変わるか研究する（これが課題）。 （おまけ：希望者のみ）Josh Angrist による以下の解説動画（英語）を視聴する。 Ceteris Paribus （他の条件が等しければ） Selection Bias（セレクションバイアス） 2.1.2 Rパッケージの読み込み 必要なパッケージを読み込み、作図用の日本語フォントを設定する。 pacman::p_load(tidyverse) theme_set(theme_gray(base_size = 10, base_family = &quot;HiraginoSans-W3&quot;)) # macOS用 #theme_set(theme_gray(base_size = 10, base_family = &quot;Meiryo&quot;)) # Windows用 #theme_set(theme_gray(base_size = 10, base_family = &quot;ipaex&quot;)) # Ubuntu用 #showtext::showtext_auto() # Cloud用 #theme_set(theme_gray(base_size = 10, base_family = &quot;noto&quot;)) # Cloud用 2.1.3 このトピックで使うRコードの説明 このトピックで新たに使うRの関数について説明する。 2.1.3.1 dplyr::case_when() dplyr::case_when() は、複数の条件によって変数の値を変えるときに使う。 例えば、gender という変数があり、値が「女」と「男」の二値だけであるとしよう。 gender &lt;- sample(c(&quot;女&quot;, &quot;男&quot;), size = 100, replace = TRUE) table(gender) ## gender ## 女 男 ## 60 40 この変数の値が「女」のときは1、「男」のときは0になる female というダミー変数は、ifelse() で作れる。 female &lt;- ifelse(gender == &quot;女&quot;, 1, 0) table(female) ## female ## 0 1 ## 40 60 同様に、male ダミーは、 #male &lt;- 1 - female # female が既にあるのでこれでもOK male &lt;- ifelse(gender == &quot;男&quot;, 1, 0) table(male) ## male ## 0 1 ## 60 40 で作れる。 このように、ifelse() は、条件が1つしかない場合分け（つまり、2つの場合に分けるとき）には便利である。 次に、gender2 という変数があり、取り得る値が「女」「男」「その他」の3種類であるとする。 gender2 &lt;- sample(c(&quot;女&quot;, &quot;男&quot;, &quot;その他&quot;), size = 100, replace = TRUE, prob = c(0.45, 0.45, 0.1)) table(gender2) ## gender2 ## その他 女 男 ## 9 41 50 この変数の値を英語に変換したいとする。これも、ifelse()でできる。 gender_eng1 &lt;- ifelse(gender2 == &quot;女&quot;, &quot;female&quot;, ifelse(gender2 == &quot;男&quot;, &quot;male&quot;, &quot;other&quot;)) table(gender_eng1) ## gender_eng1 ## female male other ## 41 50 9 このように、ifelse() を入れ子にして使えば、変数を3つ以上の場合に分けることもできる。 しかし、ifelse() を入れ子にするとコードが読みにくい。3つの場合分けならまだマシだが、場合分けの数が増えると厄介だ。そこで、dplyr::case_when() を使う。 次のようにする。 gender_eng2 &lt;- case_when( gender2 == &quot;女&quot; ~ &quot;female&quot;, gender2 == &quot;男&quot; ~ &quot;male&quot;, TRUE ~ &quot;other&quot; ) table(gender_eng2) ## gender_eng2 ## female male other ## 41 50 9 このように、case_when() では、条件 ~ 条件がTRUE のときの値 という書き方をする。条件の評価は、上から順番に行われる。したがって、上の例では gender2 == \"男\" の評価が終わった時点で残りは 「その他」だけなので、残り全てを “ohter” にするために、最後の条件を TRUE にしている。 条件が順番に評価されることを理解するために、もう1つ例をあげる。 まず、アルファベットをランダムに生成する。 rchs &lt;- sample(letters, size = 500, replace = TRUE) table(rchs) ## rchs ## a b c d e f g h i j k l m n o p q r s t u v w x y ## 19 15 19 14 21 21 23 17 19 15 21 13 28 16 16 20 21 24 24 11 16 28 19 23 19 ## z ## 18 これをアルファベット順に基づいて適当なグループに分ける。 group_chs &lt;- case_when( rchs &lt; &quot;e&quot; ~ &quot;a2d&quot;, rchs &lt; &quot;i&quot; ~ &quot;e2h&quot;, rchs &lt; &quot;o&quot; ~ &quot;i2n&quot;, rchs &lt; &quot;t&quot; ~ &quot;o2s&quot;, rchs &lt; &quot;y&quot; ~ &quot;t2x&quot;, TRUE ~ &quot;y2z&quot; ) table(group_chs) ## group_chs ## a2d e2h i2n o2s t2x y2z ## 67 82 112 105 97 37 2.2 セレクションバイアスのシミュレーション 2.2.1 メールによる販促の効果 教科書 (安井 2020) の第1章（pp.4-6）にある、メールによる販売促進施策のセレクションバイアスを、シミュレーションによって確かめてみよう。 まず、対象全体の人数を決める。 N &lt;- 1000 次に、N人をメールがないときに商品を買いやすいグループAと、商品をあまり買わないグループBに分けよう。ここでは、同じ人数に分けることにする。 d1 &lt;- tibble(group = rep(c(&quot;A&quot;, &quot;B&quot;), each = N /2)) グループAとBが、メールを受け取らなかったときに商品を買う確率 pA と pB を決める。ただし、pA \\(&gt;\\) pB である。 pA &lt;- 0.6 pB &lt;- 0.3 次に、誰にメールを送るかを決めよう。教科書 (安井 2020) に書かれているとおり、元々商品を買いそうな人にメールを送りやすいと考えて、各グループのメンバがメールを受け取る確率をそれぞれ pA / (pA + pB)、pB / (pA + pB ) としよう。また、メールは全部で N/2 人に送ることにする。メールを受け取れば1、受けとらなければ0をとる mail という変数を作る。 n_mail &lt;- N / 2 n_receive &lt;- round(n_mail * c(pA, pB) / sum(pA, pB)) d1$mail &lt;- rep(c(1, 0, 1, 0), times = c(n_receive[1], N / 2 - n_receive[1], n_receive[2], N / 2 - n_receive[2])) メールを送ることによって商品を購入する確率がどれくらい上がるか、つまり、メールの効果である tau (\\(\\tau\\)) の値を決める。ここでは、0.05ポイント上昇することにしよう。ここで設定する値が本当の因果効果である。 tau &lt;- 0.05 メールの送信が終わった後の購買行動を決める。まず、メール送信後の各人の購買確率を計算する。 Aの購買確率はメールを受け取らなければ pA、受け取れば pA + tau である。同様に、Bの購買確率はメールを受け取らなければ pB、受け取れば pB + tau である。 d1 &lt;- d1 %&gt;% mutate(p_after = ifelse(group == &quot;A&quot;, pA + tau * mail, pB + tau * mail)) 確率によって、商品を買うかどうかをベルヌーイ 試行 (Bernoulli) で決める。つまり、確率 \\(p\\) で表が出るコインを投げて、表が出たら購入し、裏が出たら購入しないと考える。 \\(\\mbox{Bernoulli}(p) = \\mbox{Binomial}(1, p)\\) なので、Rでベルヌーイ試行を実行するには、二項分布 (binomial distribution) から乱数を生成する rbinom()をsize = 1 にして使えば良い。 set.seed(2020) d1 &lt;- d1 %&gt;% mutate(purchase = rbinom(N, size = 1, prob = p_after)) メール受信状況別の購入割合は d1_gr &lt;- d1 %&gt;% mutate(mail = factor(mail, labels = c(&quot;メールなし&quot;, &quot;メールあり&quot;))) %&gt;% group_by(mail) %&gt;% summarize(purchase_rate = mean(purchase)) %&gt;% print() ## # A tibble: 2 x 2 ## mail purchase_rate ## &lt;fct&gt; &lt;dbl&gt; ## 1 メールなし 0.366 ## 2 メールあり 0.574 である。図にすると、 p1 &lt;- ggplot(d1_gr, aes(x = mail, weight = purchase_rate)) + geom_bar(width= 0.5) + labs(x = &quot;&quot;, y = &quot;購買率&quot;) plot(p1) となる。単純に比較すると、 d1_gr %&gt;% pull(purchase_rate) %&gt;% diff() ## [1] 0.208 がメールの効果のように見えてしまう。しかし、実際のメールの効果は、先ほど設定したとおり0.05 である。 ちなみに、この「バイアスを含む効果」は単回帰によっても得られる。 fit &lt;- lm(purchase ~ mail, data = d1) summary(fit) ## ## Call: ## lm(formula = purchase ~ mail, data = d1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.574 -0.366 -0.366 0.426 0.634 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.36600 0.02185 16.749 &lt; 2e-16 ## mail 0.20800 0.03090 6.731 2.85e-11 ## ## Residual standard error: 0.4886 on 998 degrees of freedom ## Multiple R-squared: 0.04342, Adjusted R-squared: 0.04246 ## F-statistic: 45.3 on 1 and 998 DF, p-value: 2.846e-11 mail の効果の推定値は、0.21 である。また、その \\(p\\)値が\\(2.85 \\times 10^{-11} &lt; 0.001\\) なので、この効果は有意水準0.001（0.1%）で統計的に有意である。単に「統計的に有意かどうか」を調べることには意味がないことがよくわかるだろう。 このように、処置（介入）の値が結果（購入確率）に依存していると、バイアスが生じる。この場合は、効果が過大評価されてしまう。 1回のシミュレーションでは、偶然そうなっただけかもしれないので、これを複数回（できるだけ多く）繰り返そう。 そのために、関数を用意する。返り値（戻り値）は、単純比較から得られる効果の大きさとする。 sim_mail &lt;- function(tau = 0.05, N = 1000, n_mail = N / 2, pA = 0.6, pB = 0.3) { # 引数の条件を設定する：条件を満たさない場合はエラー if (pA &lt;= pB) stop(&quot;pA must be larger than pB.&quot;) if (N &lt; n_mail) stop(&quot;N must be larger than n_mail.&quot;) if (pA &gt; 1 | pB &lt; 0) stop(&quot;pA and pB must be in the range [0, 1].&quot;) if (tau + pA &gt; 1) stop(&quot;beta + pA must be equal to or smaller than 1.&quot;) if (tau + pB &lt; 0) stop(&quot;beta + pB must be equal to or greater than 0.&quot;) group &lt;- rep(c(&quot;A&quot;, &quot;B&quot;), each = N /2) n_receive &lt;- round(n_mail * c(pA, pB) / sum(pA, pB)) mail &lt;- rep(c(1, 0, 1, 0), times = c(n_receive[1], N / 2 - n_receive[1], n_receive[2], N / 2 - n_receive[2])) p_after &lt;- ifelse(group == &quot;A&quot;, pA + tau * mail, pB + tau * mail) purchase &lt;- rbinom(N, size = 1, prob = p_after) fit &lt;- lm(purchase ~ mail) return(coef(fit)[2]) } 試しに、tau = 0.05 で1回シミュレーションしてみる。 sim_mail(tau = 0.05) ## mail ## 0.142 tau、pA、pB の値を変えてみる。 sim_mail(tau = 0.1, pA = 0.8, pB = 0.7) ## mail ## 0.154 最初と同じ条件で、シミュレーションを1000回繰り繰り返してみる。 s1_1000 &lt;- replicate(1000, sim_mail()) この結果を可視化する。本当の因果効果である 0.05 の位置を赤い縦線で示す。 p_s1 &lt;- tibble(tau = s1_1000) %&gt;% ggplot(aes(x = tau, y = after_stat(density))) + geom_histogram(color = &quot;black&quot;, binwidth = 0.02) + geom_vline(xintercept = 0.05, color = &quot;tomato&quot;) + labs(x = &quot;単純比較から得られる「効果」&quot;, y = &quot;確率密度&quot;) plot(p_s1) 本当の効果は0.05なのに、推定された効果の平均値は0.15 、中央値は 0.15 である。 このように、サンプルセレクションのせいでセクションバイアスが生じ、効果が過大推定されることがわかる。 サンプルセレクションの内容によっては、効果が過小評価される場合もある。 2.2.1.1 購買行動のモデリング：発展的内容* この内容はセレクションバイアスとはあまり関係ないので、興味と余力がある人のみ読めば良い。 上の説明では、メールによる販促効果が一定であると考えたが、実際には まったく買う気がない人にはあまり効果がない。 元々買う予定の人にはあまり効果がない。 買うか買わないか迷っている人には効果が大きい。 ということが予想される。そのような効果をモデル化してみよう。 個人 \\(i\\) が商品を買うかどうかを表す変数を \\(Y_i\\) とする。\\(Y_i = 1\\) ならば購入、\\(Y_i = 0\\) ならば非購入とする。\\(Y_i\\) は二値変数なので、個人\\(i\\)が商品を買う確率を \\(\\theta_i\\) として、ベルヌーイ分布で購買モデルを考えることができる。すなわち、 \\[ Y_i \\sim \\mbox{Bernoulli}(\\theta_i) \\] と考える。ここで、購買確率 \\(\\theta_i\\) は、メールがない場合に商品を買おうと思っていた度合い \\(\\alpha\\) と、メールの効果 \\(\\tau\\) によって決まると考える。 \\(\\alpha\\) が0に近ければ買うかどうか迷っている状態、絶対値が大きい負の値ならほとんど買う気がない状態、大きい正の値ならば買うつもりの状態を表す。商品を買いやすい集団Aと買いにくい集団Bがいるとすると、\\(\\alpha\\) も集団ごとに異なると考えられる。そこで、個人 \\(i\\) が属するグループを \\(G_i \\in \\{A, B\\}\\) とすると、この度合いは、\\(\\alpha_{G_i}\\) と表すことができる。 \\(M_i\\) をメールを受け取ったことを表すダミー変数、つまり、メールを受け取れば \\(M_i = 1\\)、受け取らなければ \\(M_i = 0\\) になる変数だとすると、個人 \\(i\\) が商品を買おうと思う「度合い（確率ではない）」は、\\(\\alpha_{G_i} + \\tau M_i\\) と表せる。 この「度合い」は確率ではなく、\\((-\\infty, \\infty)\\) の値をとる。確率は \\([0, 1]\\) でなければいけないので、\\((-\\infty, \\infty)\\) を \\([0, 1]\\) に変換する必要がある。 そのような変換を行うことができる関数の1つが、ロジスティック関数（ロジットの逆関数）である（詳しくは、浅野 ・矢内 (2018) の第15章 を参照されたい）。 この関数を使うと、購買確率は \\[ \\theta_i = \\mathrm{logit}^{-1}(\\alpha_{G_i} + \\tau M_i) \\] となる。ただし、 \\[ \\mathrm{logit}^{-1}(x) = \\frac{\\exp(x)}{1 + \\exp(x)} = \\frac{1}{1 + \\exp(-x)} \\] である。この関数をRで定義しよう。 inv_logit &lt;- function(x) { return(1 / (1 + exp(-x))) } これを使うと、\\(\\tau\\) を1つの値に決めても、それが購買確率 \\(\\theta\\) に与える影響は一定ではなく、\\(\\alpha\\) の大きさに依存して影響の大きさが変化することになる。 グラフにすると、その様子がわかる。 myd &lt;- tibble(x = seq(from = -5, to = 5, length.out = 1000)) %&gt;% mutate(p = inv_logit(x)) p_logistic &lt;- ggplot(myd, aes(x = x, y = p)) + geom_line(color = &quot;royalblue&quot;) + labs(x = expression(alpha[G[i]] + tau * M[i]), y = &quot;購買確率&quot;) plot(p_logistic) グラフが直線ではなく曲線になっており、\\(\\alpha_{G_i} + \\tau M_i\\) の増分が一定でも、横軸上でどこにいるかによって変化の大きさが変わることがわかる。 このような効果を想定してシミュレーションを行うと、結果は変わるだろうか？ 2.2.2 通院と健康状態：セルフセレクション 講義で扱った、病院と健康状態の例 (Angrist and Pischke 2009) を使い、セルフセレクションによるセレクションバイアスをシミュレーションによって確かめてみよう。 まず、全体の人数 \\(N\\) を決める。 N &lt;- 1e4 次に、元々の健康状態をランダムに決める（本当は、ここはランダムでなくても良い）。1が最悪の健康状態、5が最善の状態とする。中程度の健康状態の人のが多いことにする。これは、病院に行く前の「隠れた」健康状態であり、観測されない変数であることに注意しよう。 set.seed(2020-06-09) d2 &lt;- tibble(h_hidden = sample(1:5, size = N, replace = TRUE, prob = c(1, 2, 3, 2, 1))) 隠れた健康状態の分布を確認してみる。 hist_h_hidden &lt;- ggplot(d2, aes(x = h_hidden)) + geom_bar(fill = &quot;tomato&quot;, width = 0.5) + labs(x = &quot;健康状態&quot;, y = &quot;人数&quot;) plot(hist_h_hidden) この隠れた健康状態に基づき、各個人が病院に行くかどうか決められることにしよう。つまり、各個人が処置である「病院に行くこと」を、「隠れた健康状態」という結果に密接に関連する変数に基づいて自己選択する（セルフセレクション）という状況をシミュレートする。 他の条件が等しければ (ceteris paribus)、健康状態が悪いほど病院に行きやすいはずだ。ここではまず、健康状態ごとに病院に行く確率の平均値 \\(\\mu\\) が異なると考えよう。そして、各個人が病院に行く確率は、平均値 \\(\\mu\\) の正規分布からランダムに生成されると考える。話を単純にするため、標準偏差は同じだと仮定する。 （上の「購買行動のモデリング：発展的内容*」の節と同じように、健康状態を説明変数とする線形予測子を、ロジット関数を使って確率に結び付けても良い。） つまり、健康状態が \\(s\\) の人が病院に行く確率 \\(p_s\\) は、\\(p_s \\sim \\mbox{Normal}(\\theta_s, \\sigma)\\) によって決まる。ただし、\\(0 \\leq p_s \\leq 1\\) になるように調整する。例として、健康状態ごとの \\(\\mu_s\\) を \\((\\mu_1, \\mu_2, \\mu_3, \\mu_4, \\mu_5) = (0.75, 0.6, 0.4, 0.3, 0.2)\\) としてみよう。\\(\\sigma\\) は0.1とする。 Rで以下を実行して、各個人の通院確率を決める。 mu &lt;- c(0.75, 0.6, 0.4, 0.3, 0.2) sigma &lt;- 0.1 d2 &lt;- d2 %&gt;% mutate(prob = rnorm(n(), mean = mu[h_hidden], sd = sigma), prob = case_when( prob &gt; 1 ~ 1, prob &lt; 0 ~ 0, TRUE ~ prob )) 健康状態別の通院確率の分布を図示する。 hist_prob &lt;- ggplot(d2, aes(x = prob)) + geom_histogram(binwidth = 0.05, color = &quot;black&quot;) + facet_grid(rows = vars(h_hidden)) + labs(x = &quot;病院に行く確率&quot;, y = &quot;人数&quot;) plot(hist_prob) 健康状態が良い（5の）場合は、ランダムに生成した「確率」が0より小さくなってしまったものを後から0に調整しているので、0の度数が正規分布より大きくなっている。したがって、このモデルは通院を説明するものとしてはあまり望ましくない。しかし、ここでの目的はセルフセレクションによるセレクションバイアスを理解することなので、これで良しとしよう。（気になるなら、もっといいモデルを自分で考えよう！） この確率に基づいて、ベルヌーイ試行で病院に行くかどうかを表す変数 \\(D_i \\in \\{0,1\\}\\) の値を決める。これが観察される処置の値である。 d2 &lt;- d2 %&gt;% mutate(D = rbinom(n(), size = 1, prob = prob)) 病院に行く人の割合は、 mean(d2$D) ## [1] 0.4426 である。（現実よりかなり大きな値になっているが、とりあえずこれで進める。気になるなら、シミュレーションの条件を変えていろいろ試してみよう！） ここで、通院が健康状態に与える平均処置効果 (ATE) beta を設定する。単純化のため、ATE = ITE とする。つまり、処置効果はどの個人にとっても同じだと仮定する。試しに、beta = 0.6 にしてみよう。これは、隠れた健康状態が3の人が病院に行くと健康状態が3.6 になるということである。実際には、健康状態は1から5の整数で観測される。隠れた健康状態が5の人が病院に行っても健康状態は5のままのはずであるが、ここでは5.6になることを許そう。どちらも、シミュレーションを単純化するための妥協である。（調査される整数値の健康状態の背景に連続的な健康状態があり、回答するときに最も近い値を選ぶと考えれば、それほど変な設定ではない。） beta &lt;- 0.6 この効果を、通院した人にのみ与え、健康状態 \\(Y\\) を観測する。 d2 &lt;- d2 %&gt;% mutate(Y = h_hidden + beta * D) これで、データが揃った。シミュレーションでなければ、観測されるのは \\(D\\) と \\(Y\\)のみである。 病院に行った人と行かなかった人の健康状態を単純に比較してみよう。 d2_D &lt;- d2 %&gt;% mutate(D = factor(D, label = c(&quot;病院に行かなかった&quot;, &quot;病院に行った&quot;))) %&gt;% group_by(D) %&gt;% summarize(health = mean(Y)) %&gt;% print() ## # A tibble: 2 x 2 ## D health ## &lt;fct&gt; &lt;dbl&gt; ## 1 病院に行かなかった 3.34 ## 2 病院に行った 3.18 健康状態は、病院に行った人のほうが、病院に行かなかった人よりも悪いことがわかる。 このように、本当の ATE は 0.6 なのに、観察された値を単純比較すると、-0.16 だと誤解してしまう。 これはシミュレーションなので、本来は計算できないはずのセレクションバイアスも計算することができる。 セレクションバイアスは、 \\[ \\mathbb{E}[Y(0) \\mid D = 1 ] - \\mathbb{E}[Y(0) \\mid D = 0] \\] である。これを計算してみよう。 まず、\\(\\mathbb{E}[Y(0) \\mid D = 1]\\)は、 e1 &lt;- d2 %&gt;% filter(D == 1) %&gt;% pull(h_hidden) %&gt;% mean() %&gt;% print() ## [1] 2.580434 である。\\(\\mathbb{E}[Y(0) \\mid D = 0]\\) は、 e0 &lt;- d2 %&gt;% filter(D == 0) %&gt;% pull(h_hidden) %&gt;% mean() %&gt;% print() ## [1] 3.336204 である。よって、この場合のセレクションバイアスは、 (sb &lt;- e1 - e0) ## [1] -0.75577 である。セルフセレクションの影響で、負のセレクションバイアスが生じていることがわかる。ATEとセレクションバイアスを足した値 beta + sb ## [1] -0.15577 は、単純比較による効果の推定値 diff(d2_D$health) ## [1] -0.15577 に一致する。 単純比較による効果の推定を回帰分析で行ってみよう。 fit2 &lt;- lm(Y ~ D, data = d2) summary(fit2) ## ## Call: ## lm(formula = Y ~ D, data = d2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.3362 -0.5804 -0.3362 0.6638 2.4196 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.33620 0.01465 227.735 &lt; 2e-16 ## D -0.15577 0.02202 -7.074 1.61e-12 ## ## Residual standard error: 1.094 on 9998 degrees of freedom ## Multiple R-squared: 0.00498, Adjusted R-squared: 0.004881 ## F-statistic: 50.04 on 1 and 9998 DF, p-value: 1.606e-12 （当たり前だが）上と同じ推定値が得られた。また、その効果は有意水準0.001 で統計的に有意である。繰り返すが、「統計的に有意」な結果を見つけても、それ自体は因果推論の役に立たないことが、ここからわかるだろう。 以上のシミュレーションを、繰り返し実行できるように関数にまとめよう。返り値は、単純比較によって得られる「バイ アスを含んだ因果効果」とする。 sim_hospital &lt;- function(beta = 0.6, N = 1e4, mu = c(0.75, 0.6, 0.4, 0.3, 0.2), sigma = rep(0.1, 5)) { # sigma は、健康状態ごとに変えても良いことにする if (length(sigma == 1)) sigma &lt;- rep(sigma, 5) h_hidden &lt;- sample(1:5, size = N, replace = TRUE, prob = c(1, 2, 3, 2, 1)) prob &lt;- rnorm(N, mean = mu[h_hidden], sd = sigma[h_hidden]) prob &lt;- case_when( prob &gt; 1 ~ 1, prob &lt; 0 ~ 0, TRUE ~ prob ) D &lt;- rbinom(N, size = 1, prob = prob) Y &lt;- h_hidden + beta * D fit &lt;- lm(Y ~ D) return(coef(fit)[2]) } beta = 0.6 でこの関数を1度だけ実行してみる。 sim_hospital(beta = 0.6) ## D ## -0.1743207 シミュレーションを1000回繰り返してみよう。 s2_1000 &lt;- replicate(1000, sim_hospital()) この結果を図示する。 p_s2 &lt;- tibble(beta = s2_1000) %&gt;% ggplot(aes(x = beta, y = after_stat(density))) + geom_histogram(color = &quot;black&quot;, binwidth = 0.01) + #geom_vline(xintercept = 0.6, color = &quot;tomato&quot;) + labs(x= &quot;単純比較から得られる「効果」&quot;, y = &quot;確率密度&quot;) plot(p_s2) 本当の因果効果は0.6である。しかし、1,000回のシミュレーションで推定された因果効果の平均値は-0.17、中央値は-0.17であり、効果を大幅に過小推定している。 セルフセレクションによって、セレクションバイアスが生じているためである。 このように、セレクションバイアスは因果推論の敵である。今回の例では負のバイアスが生じ、本来は正であるはずの効果を負だと誤解する危険があることがわかった。しかし、セレクションの内容によっては、負の効果を正と誤解したり、弱い正の効果を強い正の効果だと誤解したりするようなことも考えられる。 セレクションバイアスが生じるような状況では、単純比較（単回帰）によって因果効果を推定することはできない。 2.3 トピック2の課題 上で行ったシミュレーションを、条件を変えて色々試しなさい。また、面白い結果や納得できない結果が出たら、Slack でシェアし、受講生同士で議論しなさい。 今回の課題は提出不要だが、必ず自分で実行すること。 参考文献 "],
["RCT.html", "Topic 3 RCT（ランダム化比較試験） 3.1 準備 3.2 ランダム化のシミュレーション 3.3 トピック3の課題", " Topic 3 RCT（ランダム化比較試験） トピック3の講義スライド (PDF, 1.4MB) 3.1 準備 3.1.1 予習、講義動画、実習課題 このトピックでやるべきことは、以下のとおりである。 シラバス(PDFファイル) に記載されているトピック3の予習課題を読む。 KUTLMS (Moodle) にあるトピック3の講義動画を視聴する。 この資料の続きを読み、Rを使った実習を行うことでRCTの理解を深める。 まず、書いてあるコードをそのまま実行する。 自分で数字（シミュレーションの条件）を変えて、結果がどう変わるか研究する（課題）。 （おまけ：希望者のみ）Josh Angrist による以下の解説動画（英語）を視聴する。 Randomized Trials: The Ideal Weapon 教科書 (安井 2020) 第1章のRを使った分析を自分でやってみる（課題）。 3.1.2 Rパッケージの読み込み 必要なパッケージを読み込み、作図用の日本語フォントを設定する。 pacman::p_load(tidyverse, patchwork) theme_set(theme_gray(base_size = 10, base_family = &quot;HiraginoSans-W3&quot;)) # macOS用 #theme_set(theme_gray(base_size = 10, base_family = &quot;Meiryo&quot;)) # Windows用 #theme_set(theme_gray(base_size = 10, base_family = &quot;ipaex&quot;)) # Ubuntu用 #showtext::showtext_auto() # Cloud用 #theme_set(theme_gray(base_size = 10, base_family = &quot;noto&quot;)) # Cloud用 3.1.3 このトピックで使うRコードの説明 このトピックでは新しい関数は使わない。 理解できないコードがあれば、遠慮なくSlack で質問を。 3.2 ランダム化のシミュレーション 3.2.1 母集団の設定 ある処置 \\(D\\) の平均処置効果が正であると仮定して、母集団のデータを作る。 共変量として二値の性別と、年齢（20歳から65歳）を考える。 set.seed(2020-06-09) N &lt;- 1e6 y_1_m &lt;- rnorm(N, mean = 10, sd = 4) y_1_f &lt;- rnorm(N, mean = 12, sd = 4) y_0_m &lt;- rnorm(N, mean = 0, sd = 2) y_0_f &lt;- rnorm(N, mean = 4, sd = 2) age &lt;- sample(20:65, size = N, replace = TRUE) df_pop &lt;- tibble(id = 1:N, age = age) %&gt;% mutate(male = rbinom(n(), size = 1, prob = 0.5), y_1 = ifelse(male, y_1_m, y_1_f) + 0.05 * (age - mean(age)), y_0 = ifelse(male, y_0_m, y_0_f) + 0.05 * (age - mean(age)), ITE = y_1 - y_0) 作成した母集団の特徴を確認する。 summary(df_pop) ## id age male y_1 ## Min. : 1 Min. :20.00 Min. :0.0000 Min. :-9.407 ## 1st Qu.: 250001 1st Qu.:31.00 1st Qu.:0.0000 1st Qu.: 8.176 ## Median : 500000 Median :42.00 Median :1.0000 Median :10.999 ## Mean : 500000 Mean :42.48 Mean :0.5003 Mean :10.999 ## 3rd Qu.: 750000 3rd Qu.:54.00 3rd Qu.:1.0000 3rd Qu.:13.823 ## Max. :1000000 Max. :65.00 Max. :1.0000 Max. :31.507 ## y_0 ITE ## Min. :-10.5585 Min. :-12.437 ## 1st Qu.: -0.1295 1st Qu.: 5.901 ## Median : 1.9970 Median : 9.008 ## Mean : 1.9990 Mean : 9.000 ## 3rd Qu.: 4.1286 3rd Qu.: 12.092 ## Max. : 13.3120 Max. : 31.514 ITE（個体の処置効果）の分布を確認しておこう。 pop_ite &lt;- ggplot(df_pop, aes(x = ITE), after_stat(density)) + geom_histogram(color = &quot;black&quot;) + labs(y = &quot;確率密度&quot;, title = &quot;母集団における処置効果&quot;) plot(pop_ite) 平均処置効果を計算しておこう。 ## 平均処置効果 pop_ATE &lt;- mean(df_pop$ITE) %&gt;% print() ## [1] 8.999995 ## 男性における平均処置効果 pop_ATE_m &lt;- df_pop %&gt;% filter(male == 1) %&gt;% with(mean(ITE)) %&gt;% print() ## [1] 9.993789 ## 女性における平均処置効果 pop_ATE_f &lt;- df_pop %&gt;% filter(male == 0) %&gt;% with(mean(ITE)) %&gt;% print() ## [1] 8.005113 以下では、この母集団に対して異なる方法でRCTを実施した場合にどのような結果が得られるか、シミュレーションで確かめよう。 3.2.2 ベルヌーイ実験 ベルヌーイ実験 (Bernoulli experiments) をRで実行しよう。まず、シミュレーションを繰り返し行うために、実験を実行する関数を作る。標本サイズ（1回の実験における被験者数） を sample_size で、各ベルヌーイ試行で処置に割付ける確率を prob で指定できるようにする。 bern_experiment &lt;- function(population, sample_size = 100, prob = 0.5, info = FALSE) { df &lt;- slice_sample(.data = population, n = sample_size) df &lt;- df %&gt;% mutate(D = rbinom(n(), size = 1, prob = prob)) ATE &lt;- with(df, mean(y_1[D == 1]) - mean(y_0[D == 0])) if (info) cat(&#39;処置群の個体数:&#39;, sum(df$D), &#39;; 統制群の個体数:&#39;, sample_size - sum(df$D), &#39;\\n&#39;) return(ATE) } この関数を使ってベルヌーイ実験を1度実行してみる。sample_size = 100、prob = 0.5 とする（既定値なので指定しなくて良い）。 bern_experiment(population = df_pop, info = TRUE) ## 処置群の個体数: 57 ; 統制群の個体数: 43 ## [1] 8.538327 もう1回やってみる。 bern_experiment(population = df_pop, info = TRUE) ## 処置群の個体数: 48 ; 統制群の個体数: 52 ## [1] 9.082204 もう1回やってみる。 bern_experiment(population = df_pop, info = TRUE) ## 処置群の個体数: 47 ; 統制群の個体数: 53 ## [1] 8.429646 当然ながら、実験結果は毎回変わる。 実験を1000回繰り返し、結果を図示してみよう。母集団における本当の平均因果効果を赤い縦線で示す。 標本サイズは100である。 bern_100 &lt;- replicate(1000, bern_experiment(df_pop)) hist_bern_100 &lt;- tibble(ATE = bern_100) %&gt;% ggplot(aes(x = ATE)) + geom_histogram(binwidth = 0.2, color = &quot;black&quot;) + geom_vline(xintercept = pop_ATE, color = &quot;tomato&quot;) + labs(y = &quot;度数&quot;, title = &quot;ベルヌーイ実験&quot;) plot(hist_bern_100) 1つひとつの実験は必ずしも ATE を正確に推定しているわけではないが、平均すれば正しい効果を推定できていることがわかる。「正しい」ATEが9 であるのに対し、RCT による推定の平均値は 9 である。 処置に割付ける確率は、0.5 でなくても良い。 bern_experiment(population = df_pop, prob = 0.8, info = TRUE) ## 処置群の個体数: 78 ; 統制群の個体数: 22 ## [1] 9.000707 bern_experiment(population = df_pop, prob = 0.2, info = TRUE) ## 処置群の個体数: 18 ; 統制群の個体数: 82 ## [1] 7.948835 bern_experiment(population = df_pop, prob = 0.1, info = TRUE) ## 処置群の個体数: 10 ; 統制群の個体数: 90 ## [1] 7.335998 bern_p80 &lt;- replicate(1000, bern_experiment(df_pop, prob = 0.8)) hist_bern_p80 &lt;- tibble(ATE = bern_p80) %&gt;% ggplot(aes(x = ATE)) + geom_histogram(binwidth = 0.2, color = &quot;black&quot;) + geom_vline(xintercept = pop_ATE, color = &quot;tomato&quot;) + labs(y = &quot;度数&quot;) plot(hist_bern_p80) 標本サイズ（被験者の数）を変えるとどうなるだろうか。 標本サイズが30の場合： bern_30 &lt;- replicate(1000, bern_experiment(df_pop, sample_size = 30)) hist_bern_30 &lt;- tibble(ATE = bern_30) %&gt;% ggplot(aes(x = ATE)) + geom_histogram(binwidth = 0.2, color = &quot;black&quot;) + geom_vline(xintercept = pop_ATE, color = &quot;tomato&quot;) + labs(y = &quot;度数&quot;) plot(hist_bern_30) 標本サイズが50の場合： bern_50 &lt;- replicate(1000, bern_experiment(df_pop, sample_size = 50)) hist_bern_50 &lt;- tibble(ATE = bern_50) %&gt;% ggplot(aes(x = ATE)) + geom_histogram(binwidth = 0.2, color = &quot;black&quot;) + geom_vline(xintercept = pop_ATE, color = &quot;tomato&quot;) + labs(y = &quot;度数&quot;) plot(hist_bern_50) 標本サイズが500の場合： bern_500 &lt;- replicate(1000, bern_experiment(df_pop, sample_size = 500)) hist_bern_500 &lt;- tibble(ATE = bern_500) %&gt;% ggplot(aes(x = ATE)) + geom_histogram(binwidth = 0.2, color = &quot;black&quot;) + geom_vline(xintercept = pop_ATE, color = &quot;tomato&quot;) + labs(y = &quot;度数&quot;) plot(hist_bern_500) 標本サイズが小さくても、平均的には正しい因果効果を推定できている。 しかし、標本サイズが小さいと、推定のばらつき（標準誤差）が大きくなる。 sd(bern_30) ## [1] 1.303407 sd(bern_50) ## [1] 1.004959 sd(bern_100) ## [1] 0.7140102 sd(bern_500) ## [1] 0.330548 標準誤差が大きいと、過小推定や過大推定が多くなることがわかる。実験を1回（2回、3回）しか行わないなら、標本サイズを十分な大きさにしないと、過小推定や過大推定をしてしまうかもしれない。 3.2.3 完全ランダム化実験 次に、完全ランダム化実験 (completely random experiments) を行う。 sample_size と、処置に割付ける個体の数 n_treated を選べるようにする。ただし、sample_size &gt; n_treated である。 cr_experiment &lt;- function(population, sample_size = 100, n_treated = ceiling(sample_size / 2), info = FALSE) { if (sample_size &lt;= n_treated | n_treated &lt;= 0) stop(&#39;n_treated must be a positive integer smaller than sample_size.&#39;) df &lt;- slice_sample(.data = population, n = sample_size) %&gt;% mutate(D = sample(rep(c(1, 0), c(n_treated, sample_size - n_treated)), size = sample_size, replace = FALSE)) ATE &lt;- with(df, mean(y_1[D == 1]) - mean(y_0[D == 0])) if (info) cat(&#39;処置群の個体数:&#39;, n_treated, &#39;; 統制群の個体数:&#39;, sample_size - n_treated, &#39;\\n&#39;) return(ATE) } sample_size = 100、n_treatd = 50 （どちらも既定値）にして、1回実験を行ってみよう。 cr_experiment(df_pop, info = TRUE) ## 処置群の個体数: 50 ; 統制群の個体数: 50 ## [1] 8.584128 もう1度やってみる。 cr_experiment(df_pop, info = TRUE) ## 処置群の個体数: 50 ; 統制群の個体数: 50 ## [1] 9.89403 この実験を1000回繰り返し、結果を可視化しよう。 cr_100 &lt;- replicate(1000, cr_experiment(df_pop)) hist_cr_100 &lt;- tibble(ATE = cr_100) %&gt;% ggplot(aes(x = ATE)) + geom_histogram(binwidth = 0.2, color = &quot;black&quot;) + geom_vline(xintercept = pop_ATE, color = &quot;tomato&quot;) + labs(y = &quot;度数&quot;, title = &quot;完全ランダム化実験&quot;) plot(hist_cr_100) やはり、平均的にはうまく推定できているようだ。ATEの推定値の平均値は、9 である。 完全ランダム化実験で処置に割付ける数は、標本サイズの半分でなくても良い。 cr_experiment(df_pop, sample_size = 100, n_treated = 70, info = TRUE) ## 処置群の個体数: 70 ; 統制群の個体数: 30 ## [1] 7.992297 cr_experiment(df_pop, sample_size = 100, n_treated = 25, info = TRUE) ## 処置群の個体数: 25 ; 統制群の個体数: 75 ## [1] 9.782785 この実験を1000回繰り返し、結果を可視化しよう。 cr_prop20 &lt;- replicate(1000, cr_experiment(df_pop, sample_size = 100, n_treated = 20)) hist_cr_prop20 &lt;- tibble(ATE = cr_prop20) %&gt;% ggplot(aes(x = ATE)) + geom_histogram(binwidth = 0.2, color = &quot;black&quot;) + geom_vline(xintercept = pop_ATE, color = &quot;tomato&quot;) + labs(y = &quot;度数&quot;) plot(hist_cr_prop20) 標本サイズ（被験者数）の20％のみを処置に割付けても、平均的には正しいATEを推定できる。 3.2.4 ブロック別ランダム化実験 続いて、ブロック別ランダム化実験 (stratified randomized experiments) を実施してみよう。 ここでは、性別（男性ダミー変数）によってブロックを作る。 処置に割付ける数は、各群における処置の割合で指定できるようにする。 例えば、男性ブロックでは7割を処置、女性ブロックでは4割を処置するなら、prop = c(0.7, 0.4) と指定できるようにする。 strat_experiment &lt;- function(population, sample_size = 100, prop = c(0.5, 0.5), info = FALSE) { if (min(prop) &lt;= 0 | max(prop) &gt;= 1) stop(&quot;prop must be in (0, 1).&quot;) df &lt;- slice_sample(.data = population, n = sample_size) Male &lt;- df %&gt;% filter(male == 1) Female &lt;- df %&gt;% filter(male == 0) n_treated &lt;- ceiling(c(nrow(Male), nrow(Female)) * prop) ATE_male &lt;- cr_experiment(Male, sample_size = nrow(Male), n_treated = n_treated[1]) ATE_female &lt;- cr_experiment(Female, sample_size = nrow(Female), n_treated = n_treated[2]) male_prop &lt;- mean(df$male) ATE &lt;- male_prop * ATE_male + (1 - male_prop) * ATE_female if (info) { cat(&#39;男性ブロック 処置群の個体数&#39;, n_treated[1], &#39;; 統制群の個体数:&#39;, nrow(Male) - n_treated[1], &#39;\\n&#39;) cat(&#39;女性ブロック 処置群の個体数&#39;, n_treated[2], &#39;; 統制群の個体数:&#39;, nrow(Female) - n_treated[2], &#39;\\n&#39;) } return(ATE) } sample_size = 100、prop = c(0.5, 0.5) （どちらも既定値）として、1回実験してみる。 strat_experiment(df_pop, info = TRUE) ## 男性ブロック 処置群の個体数 28 ; 統制群の個体数: 27 ## 女性ブロック 処置群の個体数 23 ; 統制群の個体数: 22 ## [1] 8.558515 もう1度やってみる strat_experiment(df_pop, info = TRUE) ## 男性ブロック 処置群の個体数 26 ; 統制群の個体数: 26 ## 女性ブロック 処置群の個体数 24 ; 統制群の個体数: 24 ## [1] 8.715336 この実験を1000回繰り返し、結果を可視化しよう。 strat_100 &lt;- replicate(1000, strat_experiment(df_pop)) hist_strat_100 &lt;- tibble(ATE = strat_100) %&gt;% ggplot(aes(x = ATE)) + geom_histogram(binwidth = 0.2, color = &quot;black&quot;) + geom_vline(xintercept = pop_ATE, color = &quot;tomato&quot;) + labs(y = &quot;度数&quot;, title = &quot;ブロック別ランダム化実験&quot;) plot(hist_strat_100) やはり、平均的にはうまく推定できているようだ。ATEの推定値の平均値は、9.01 である。 処置する個体の数（割合）は、ブロックごとに変えても良い。 strat_experiment(df_pop, prop = c(0.3, 0.15), info = TRUE) ## 男性ブロック 処置群の個体数 17 ; 統制群の個体数: 38 ## 女性ブロック 処置群の個体数 7 ; 統制群の個体数: 38 ## [1] 9.260837 strat_experiment(df_pop, prop = c(0.8, 0.1), info = TRUE) ## 男性ブロック 処置群の個体数 42 ; 統制群の個体数: 10 ## 女性ブロック 処置群の個体数 5 ; 統制群の個体数: 43 ## [1] 9.769045 1000回繰り返してみよう。 strat_b &lt;- replicate(1000, strat_experiment(df_pop, prop = c(0.8, 0.2))) hist_strat_b &lt;- tibble(ATE = strat_b) %&gt;% ggplot(aes(x = ATE)) + geom_histogram(binwidth = 0.2, color = &quot;black&quot;) + geom_vline(xintercept = pop_ATE, color = &quot;tomato&quot;) + labs(y = &quot;度数&quot;) plot(hist_strat_b) ブロックごとに処置に割り付ける割合が違っても、平均的には正しい推定ができる。 3.2.5 ペア毎のランダム化実験 4番目の方法として、ペア毎のランダム化試験 (paired randomized experiments) を実施しよう。 サンプルの中で、性別が同じで、年齢が近い者同士をペアにして、ペア毎に一方を処置に、他方を統制に割付ける。 ペアを組む都合上、標本サイズは偶数に制限し、サンプル内の男女の数がそれぞれ偶数になるように調整する。 paired_experiment &lt;- function(population, sample_size = 100) { ## sample_size が奇数の場合はエラー if (sample_size %% 2 != 0) stop(&quot;sample_size must be an even number.&quot;) n_male &lt;- sample_size / 2 if (n_male %% 2 != 0) n_male &lt;- n_male + sample(c(-1, 1), size = 1) n_female &lt;- sample_size - n_male Male &lt;- population %&gt;% filter(male == 1) %&gt;% slice_sample(n = n_male) %&gt;% arrange(age) %&gt;% mutate(D = as.vector(replicate(n() / 2, sample(0:1, size = 2)))) Female &lt;- population %&gt;% filter(male == 0) %&gt;% slice_sample(n = n_female) %&gt;% arrange(age) %&gt;% mutate(D = as.vector(replicate(n() / 2, sample(0:1, size = 2)))) df &lt;- bind_rows(Male, Female) ATE &lt;- with(df, mean(y_1[D == 1]) - mean(y_0[D == 0])) return(ATE) } 標本サイズ sample_size = 100 （既定値）で1回実験してみる。 paired_experiment(df_pop) ## [1] 8.230426 もう1回やってみよう。 paired_experiment(df_pop) ## [1] 8.688203 この実験を1000回繰り返し、結果を可視化しよう（そこそこ時間がかかるので注意）。 pair_100 &lt;- replicate(1000, paired_experiment(df_pop)) hist_pair_100 &lt;- tibble(ATE = pair_100) %&gt;% ggplot(aes(x = ATE)) + geom_histogram(binwidth = 0.2, color = &quot;black&quot;) + geom_vline(xintercept = pop_ATE, color = &quot;tomato&quot;) + labs(y = &quot;度数&quot;, title = &quot;ペア毎のランダム化実験&quot;) plot(hist_pair_100) やはり、平均的にはうまく推定できているようだ。ATEの推定値の平均値は、9.02 である。 各ペアで処置に割り付ける確率は、0.5 でなくても良い。自分で確かめてみよう。 3.2.6 4つのRCT を比較する 最後に、それぞれのRCTの推定精度を比較しよう。どれも標本サイズは100で、処置の確率・割合・数が全体の半分（程度）になるようにしたものを比べる。 1000回の実験をシミュレートしたヒストグラムを再掲する。 MIN &lt;- min(c(bern_100, cr_100, strat_100, pair_100)) - 0.2 MAX &lt;- max(c(bern_100, cr_100, strat_100, pair_100)) + 0.2 ((hist_bern_100 + xlim(MIN, MAX) + ylim(0, 150)) + (hist_cr_100 + xlim(MIN, MAX) + ylim(0, 150))) / ((hist_strat_100 + xlim(MIN, MAX) + ylim(0, 150)) + (hist_pair_100 + xlim(MIN, MAX) + ylim(0, 150))) 標準誤差を比較する。 sd(bern_100) ## [1] 0.7140102 sd(cr_100) ## [1] 0.6964512 sd(strat_100) ## [1] 0.6364027 sd(pair_100) ## [1] 0.6304716 このように、処置のパタンの数が最も少ない（かつブロック[ペア]がより同質的な）ペア毎のランダム化実験の標準誤差が最も小さく、推定精度が高いことがわかる。 経済実験におけるランダム化について、さらに詳細な説明は List, Sadoff, and Wagner (2011) を参照。また、RCT全般については、実験経済学（岡野先生）と実験デザイン（小谷先生）の授業で詳しく扱うはずなので、それらの授業まだ受講していない人はぜひ受講してほしい。 3.3 トピック3の課題 上で行ったシミュレーションを、条件を変えて試し、どのような場合に実験がうまくいき、どのような条件だと失敗しやすいか研究しなさい。また、面白い結果や納得できない結果が出たら、Slack でシェアし、受講生同士で議論しなさい。 教科書 (安井 2020) 第1章の1.4節 (pp.24-33) の分析を自分で実行しなさい。 今回の課題はいずれも提出不要だが、必ず自分で実行すること。 参考文献 "],
["regression.html", "Topic 4 回帰分析 4.1 準備 4.2 回帰分析のシミュレーション 4.3 脱落変数バイアスと処置後変数バイアス 4.4 DAG（有向非巡回グラフ） 4.5 トピック4の課題", " Topic 4 回帰分析 トピック4の講義スライド (PDF, 1.4MB) 4.1 準備 4.1.1 予習、講義動画、実習課題 このトピックでやるべきことは、以下のとおりである。 シラバス(PDFファイル) に記載されているトピック4の予習課題を読む。 KUTLMS (Moodle) にあるトピック4の講義動画を視聴する。 この資料の続きを読み、Rを使った実習を行うことで、回帰分析の理解を深める。特に、因果推論で回帰分析を使う意味を理解する。 まず、書いてあるコードをそのまま実行する。 自分で数字（シミュレーションの条件）を変えて、結果がどう変わるか研究する（課題）。 教科書 (安井 2020) 第2章のRを使った分析を自分でやってみる。 課題を提出する。 このトピックの説明は、以下の事項を理解しているという前提で書かれている。 回帰直線とは何か 回帰係数とは何か Rで回帰分析を実行する方法 lm() の使い方 broom::tidy() の使い方 推定結果の読み方 これらの理解に不安がある場合は、浅野 and 矢内 (2018) の第10–14章や計量経済学の講義資料 などを参照されたい。より厳密な説明は、計量経済学の教科書（たとえば、Angrist and Pischke (2009) の第3章、 Hansen (2020) の第2章から第5章、 縄田 (2013) の第6章、西山 et al. (2019) の第6章、末石 (2015) の第1章など）を参照。 注意： 下の説明では、replicate() でシミュレーションを繰り返す回数を1,000 に設定しているが、自分の環境合わせて調整するように。あまり処理能力が高くないパソコンを使っている場合は、繰り返し回数を少なめ（例えば、500）にしたほうがよい。シミュレーションの結果を安定させたいなら、繰り返し回数をさらに大きくしたほうが良い。また、set.seed() で指定する値は適宜変えるように。 4.1.2 Rパッケージの読み込み 必要なパッケージを読み込み、作図用の日本語フォントを設定する。 pacman::p_load(tidyverse, ggbeeswarm, broom, patchwork, dagitty, ggdag) theme_set(theme_gray(base_size = 10, base_family = &quot;HiraginoSans-W3&quot;)) # macOS用 #theme_set(theme_gray(base_size = 10, base_family = &quot;Meiryo&quot;)) # Windows用 #theme_set(theme_gray(base_size = 10, base_family = &quot;ipaex&quot;)) # Ubuntu用 #showtext::showtext_auto() # Cloud用 #theme_set(theme_gray(base_size = 10, base_family = &quot;noto&quot;)) # Cloud用 4.1.3 関数の自作 ロジットの逆関数（ロジスティック関数）を用意する。 inv_logit &lt;- function(x) { return(1 / (1 + exp(-x))) } 4.1.4 このトピックで使うRコードの説明 4.1.4.1 weighted.mean() weighted.mean()は加重平均を計算する。 10と20の単純な算術平均は a &lt;- c(A = 10, B = 20) mean(a) ## [1] 15 である。A と B の重みを 5:2 にする。 weight &lt;- c(5, 2) この重みを使って加重平均を計算する。 weighted.mean(a, w = weight) ## [1] 12.85714 これは、 sum(a * weight) / sum(weight) ## [1] 12.85714 である。つまり、 (10 * 5 + 20 * 2) / (5 + 2) ## [1] 12.85714 である。 4.1.4.2 purrr::map()と sapply() purrr::map() は、関数をリストまたはベクトルの各要素に適用し、リストを返す。 sapply() も同様の働きをするが、返り値を単純なもの（次元が低いもの）にできる場合には単純化して値を返してくれる。例えば、各要素の長さが1で全体の長さが L のリストを返す代わりに、長さ L のベクトルを返す。 （実は、 sapply() は lapply() を simplify = TRUE として使っているだけである。） 例として、ある数を s 倍にする関数を作る。s の既定値は10にする。 multiply_s &lt;- function(x, s = 10) { return(x * s) } この関数は、次のように使う。 multiply_s(5) # 5 の10倍 ## [1] 50 multiply_s(5, s = 8) # 5の8倍 ## [1] 40 この関数を、あるベクトルの各要素に対して使いたいとする。まず、対象となるベクトルを作る。 (vec1 &lt;- 1:10) ## [1] 1 2 3 4 5 6 7 8 9 10 このベクトルの各要素に関数を適用する。まずは、for ループでやってみる。 res_for &lt;- rep(NA, length(vec1)) # 結果を保存するベクトル for (i in seq_along(vec1)) { res_for[i] &lt;- multiply_s(vec1[i]) } res_for ## [1] 10 20 30 40 50 60 70 80 90 100 これを purrr::map() で実行すると、次のように書ける。%&gt;% print() は結果を表示するために使っているだけなので、表示しなくていいなら不要（以下も同じ）。 res_map &lt;- vec1 %&gt;% map(.f = multiply_s) %&gt;% unlist() %&gt;% print() ## [1] 10 20 30 40 50 60 70 80 90 100 このように、map() は、map(.x = 対象となるベクトルまたはリスト, .f = 適用する関数, .x 以外の引数) という形式で使う。map() はリストを返すので、ここではリストをベクトルにするために unlist() を使っている。 使用する関数の引数も指定できる。multiply_s() で s = 20 を指定する。 res_map_20 &lt;- vec1 %&gt;% map(.f = multiply_s, s = 20) %&gt;% unlist() %&gt;% print() ## [1] 20 40 60 80 100 120 140 160 180 200 この例の場合には、sapply() を使うほうが簡単である。sapply() は sapply(X = ベクトル, FUN = 適用する関数, X以外の引数) というように使う。X に指定できるのはベクトルであり、結果もベクトルで返される。 res_apply &lt;- vec1 %&gt;% sapply(FUN = multiply_s, s = 20) %&gt;% print() ## [1] 20 40 60 80 100 120 140 160 180 200 map() はリストに対しても同様に使える。 まず、データを生成する関数を作る。 dgp_example &lt;- function(N = 100) { X &lt;- runif(N, min = 0, max = 1) Y &lt;- rnorm(N, mean = 0.6 * X, sd = 1) return(tibble(X, Y)) } この関数を使って、N = 50 のデータセットを100個作る。 df_list &lt;- rep(50, 100) %&gt;% map(.f = dgp_example) class(df_list) ## [1] &quot;list&quot; このリストに含まれる100個のデータセットのそれぞれで、lm() を使った回帰分析を実行する。 fit_list &lt;- df_list %&gt;% map(.f = lm, formula = Y ~ X) fit_list の各要素が、lm() で回帰分析を行った結果になっている。例えば、32番目のデータセットを使った結果は、 fit_list[[32]] %&gt;% tidy() ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.0585 0.277 0.211 0.834 ## 2 X 0.714 0.494 1.44 0.155 である。 sapply() も使えるが、結果が行列になって使いにくいので、この場合には lapply() を使ったほうが良い。 fit_list_2 &lt;- df_list %&gt;% lapply(FUN = lm, formula = Y ~ X) 32番目のデータセットを使った結果は fit_list_2[[32]] %&gt;% tidy() ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.0585 0.277 0.211 0.834 ## 2 X 0.714 0.494 1.44 0.155 で、上と同じ結果が出る。 map() や sapply()（あるいはその他の apply 系関数）では、適用する関数に無名関数 (anonymous function) を 使うことができる。無名関数とは、その名の通り名前がついていない関数である。簡単にいうと、使う時点でまだ関数として定義されていないものである。 例えば、1から10の整数ベクトルの各要素に、それぞれの数に2を足した数をかける、つまり、 \\[ f(x) = x (x + 2) = x^2 + 2x \\] を計算してみる。ただし、関数はあらかじめ定義せず、無名関数を使う。 map() の場合： 1:10 %&gt;% map(.f = function(x) x * (x + 2)) %&gt;% unlist() ## [1] 3 8 15 24 35 48 63 80 99 120 このように、.f のところに関数自体を書いてしまえばよい。 sapply() の場合： 1:10 %&gt;% sapply(FUN = function(x) x^2 + 2 * x) ## [1] 3 8 15 24 35 48 63 80 99 120 とできる。 map() やsapply() を使うほうが、for ループを使うより計算が速くなる。また、コードもシンプルに書けることが多い。 しかし、どうしても使い方が難しいと思うなら、無理に使おうとせず、for ループを使えば良い。 4.1.4.3 purrr::array_tree() 行列（正確には配列 [array] に使えるが、行列で説明する）をリストに変換するために、purrr::array_tree() を使う。 まず、行列を作る。 m1 &lt;- matrix(1:12, byrow = TRUE, nrow = 3) %&gt;% print() ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 ## [3,] 9 10 11 12 この行列の各行を要素にもつリストを作る。つまり、各要素が [1, 2, 3, 4]、[5, 6, 7, 8]、[9, 10, 11, 12] で全体の長さが3のリストを作る。 list_row &lt;- m1 %&gt;% array_tree(margin = 1) %&gt;% print() ## [[1]] ## [1] 1 2 3 4 ## ## [[2]] ## [1] 5 6 7 8 ## ## [[3]] ## [1] 9 10 11 12 length(list_row) ## [1] 3 このように、margin = 1 で array_tree() を使うと、行列の各行を要素にもつリストができる。 同様に、行列の各列を要素にもつリストを作る。つまり、各要素が [1, 5, 9]、[2, 6, 10]、[3, 7, 11]、[4, 8, 12] で全体の長さが4のリストを作る。 list_col &lt;- m1 %&gt;% array_tree(margin = 2) %&gt;% print() ## [[1]] ## [1] 1 5 9 ## ## [[2]] ## [1] 2 6 10 ## ## [[3]] ## [1] 3 7 11 ## ## [[4]] ## [1] 4 8 12 length(list_col) ## [1] 4 このように、margin = 2 で array_tree() を使うと、行列の各列を要素にもつリストができる。 tibble::enframe() については、教科書 (安井 2020) の pp.55-56 を参照。 4.2 回帰分析のシミュレーション 4.2.1 単回帰 (1) 処置変数が二値の場合 処置変数 \\(D_i \\in \\{0, 1\\}\\) と結果変数 \\(Y_i \\in \\mathbb{R}\\) を考える。 \\(Y_i\\) が \\(D_i\\) の関数で \\[ Y_i = 0.5 + 0.7 D_i + e_i \\] と表されるとする。この状況をシミュレートする。 set.seed(12345) N &lt;- 500 # sample size D &lt;- rbinom(N, size = 1, prob = 0.4) Y &lt;- 0.5 + 0.8 * D + rnorm(N, mean = 0, sd = 0.5) df_simple &lt;- tibble(Y, D) \\(D\\) と \\(Y\\) の関係を可視化する。 scat_simple &lt;- ggplot(df_simple, aes(x = D, y = Y)) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + geom_beeswarm(shape = 20, alpha = 1/3, size = 1) + scale_x_continuous(breaks = 0:1) plot(scat_simple) 回帰直線の傾きは、 fit_simple &lt;- lm(Y ~ D, data = df_simple) coef(fit_simple)[2] ## D ## 0.8061476 である。これは、処置群（D = 1 の群）の Y の平均値と、統制群（D = 0 の群）の Y の平均値の差である。 with(df_simple, mean(Y[D == 1]) - mean(Y[D == 0])) ## [1] 0.8061476 このように、回帰直線の傾きは、説明変数の値で条件付けた結果変数の期待値の差である。 また、回帰直線の切片は coef(fit_simple)[1] ## (Intercept) ## 0.5173247 であり、これは統制群（D = 0 の群）の Y の平均値 with(df_simple, mean(Y[D == 0])) ## [1] 0.5173247 に等しい。 (2) 処置変数が連続の場合 処置変数 \\(D_i \\sim \\mbox{U}(-2, 2)\\) と結果変数 \\(Y_i \\in \\mathbb{R}\\) を考える。 \\(Y_i\\) が \\(D_i\\) の関数で \\[ Y_i = 0.5 + 0.7 D_i + e_i \\] と表されるとする。この状況をシミュレートする。 set.seed(321) N &lt;- 1000 # sample size D &lt;- runif(N, min = -2, max = 2) Y &lt;- 0.5 + 0.7 * D + rnorm(N, mean = 0, sd = 0.5) df_cont &lt;- tibble(Y, D) \\(D\\) と \\(Y\\) の関係を可視化する。 scat_cont &lt;- ggplot(df_cont, aes(x = D, y = Y)) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + geom_point(shape = 20, alpha = 1/3) plot(scat_cont) 回帰直線の傾きは、 fit_cont &lt;- lm(Y ~ D, data = df_cont) coef(fit_cont)[2] ## D ## 0.710264 である。これは、処置の値を1単位増やしたとき、平均するとY の平均値がどれだけ増加するかを示している。 観測された個体をD の値によって [-2, -1), [-1, 0), [0, 1), [1, 2] の4つのグループに分け、それぞれのグループでY の平均値を計算し、さらに隣のグループとの差をとる。 df_cont &lt;- df_cont %&gt;% mutate(group = case_when( D &lt; -1 ~ 1, D &lt; 0 ~ 2, D &lt; 1 ~ 3, TRUE ~ 4 )) (b1 &lt;- with(df_cont, mean(Y[group == 2]) - mean(Y[group == 1]))) ## [1] 0.6512046 (b2 &lt;- with(df_cont, mean(Y[group == 3]) - mean(Y[group == 2]))) ## [1] 0.7395212 (b3 &lt;- with(df_cont, mean(Y[group == 4]) - mean(Y[group == 3]))) ## [1] 0.7123079 説明変数である D の値が1増えるごとに、回帰係数に概ね近い値の分だけ、Y の平均値が増加していることがわかる。 それぞれのグループに属する観測値の数を重みにして加重平均をとると、 n_groups &lt;- table(df_cont$group)[c(1, 2, 2, 3, 3, 4)] weight &lt;- c(sum(n_groups[1:2]), sum(n_groups[3:4]), sum(n_groups[5:6])) weighted.mean(c(b1, b2, b3), w = weight) ## [1] 0.7016254 となり、傾きの推定値に近い値が得られる。 このように、回帰直線の傾きは、説明変数の値で条件付けた結果変数の期待値の差である。 また、回帰直線の切片は coef(fit_cont)[1] ## (Intercept) ## 0.5032906 であり、これは D = 0 のときのYの期待値の推定値である。シミュレーションデータで、D が 0に近い値の Y の平均値を計算すると、 epsilon &lt;- 0.2 with(df_cont, mean(Y[D &gt; -epsilon &amp; D &lt; epsilon])) ## [1] 0.4909429 となり、推定値におおむね一致する。 このような結果はいつも成り立つのか、1回だけのシミュレーションでは信じられないだろう。 シミュレーションを繰り返す方法を自分で考えて実行してみよう。 4.2.2 重回帰 処置変数 \\(D_i \\in \\{0, 1\\}\\) と結果変数 \\(Y_i \\in \\mathbb{R}\\) に加え、共変量 \\(X \\in \\{-4, -3, \\dots, 4\\}\\) を考える。 \\(Y_i\\) が \\(D_i\\) と \\(X_i\\) の関数で \\[ Y_i = 0.5 + 0.7 D_i + 0.4 X_i + e_i \\] と表されるとする。また、\\(D_i\\) の値は\\(X_i\\) に依存して、次のように決まることにする。 \\[ D_i \\sim \\mbox{Bernoulli}(\\theta_i)\\\\ \\theta_i = \\mathrm{logit}^{-1}(0.5 X_i) \\] つまり、\\(X\\) が大きくなるほど、\\(D_i\\) が1になる確率が大きくなると仮定する。 \\(\\theta\\) と \\(X\\) の関係を可視化すると、以下のようになる。 df &lt;- tibble(X = -4:4) %&gt;% mutate(theta = inv_logit(0.5 * X)) p_logistic &lt;- ggplot(df, aes(x = X, y = theta)) + geom_hline(yintercept = c(0, 1), color = &quot;gray&quot;) + geom_line(color = &quot;dodgerblue&quot;) + labs(y = expression(theta)) plot(p_logistic) この状況をシミュレートする。 set.seed(111) N &lt;- 1000 # sample size X &lt;- sample(-4:4, size = N, replace = TRUE) theta &lt;- inv_logit(0.5 * X) D &lt;- rbinom(N, size = 1, prob = theta) Y &lt;- 0.5 + 0.7 * D + 0.3 * X + rnorm(N, mean = 0, sd = 0.5) df_multiple &lt;- tibble(Y, D, X) Y を D と X に回帰する (long regression) と、D の係数の推定値は、 fit_long &lt;- lm(Y ~ D + X, data = df_multiple) coef(fit_long)[2] ## D ## 0.6905941 となる。 Y を D のみに回帰する (short regression)と、D の係数の推定値は、 fit_short &lt;- lm(Y ~ D, data = df_multiple) coef(fit_short)[2] ## D ## 1.516601 となり、推定値が過大推定されている。この値は、観測された平均値の2群間の差である。 with(df_multiple, mean(Y[D == 1] - mean(Y[D == 0]))) ## [1] 1.516601 4.2.3 重回帰によるブロッキング 重回帰を行う代わりに、上のデータ df_multiple を共変量\\(X\\) の値ごとにブロックに分け、単回帰によってブロックごとに D の係数を推定してみよう。 \\(X = x\\) のブロックで傾きを推定する関数を用意する。 beta_X &lt;- function(x, data) { fit &lt;- data %&gt;% filter(X == x) %&gt;% lm(Y ~ D, data = .) return(coef(fit)[2]) } Xの値ごとに、傾きを推定する。 beta_vec &lt;- sapply(-4:4, beta_X, data = df_multiple) names(beta_vec) &lt;- str_c(&quot;X=&quot;, -4:4) beta_vec ## X=-4 X=-3 X=-2 X=-1 X=0 X=1 X=2 ## 0.8446962 0.6572588 0.7475040 0.6917050 0.6252307 0.7681240 0.5260543 ## X=3 X=4 ## 0.7046942 0.6230728 ブロックごとに処置効果を求めることができた。このように、ブロックに分けて単回帰を行えば、過大推定にはならないことがわかる。これらの値を元に、全体の処置効果を加重平均で求めてみよう。 ATE を求めるために \\(X = x\\) となるブロックの重みを\\(\\Pr (X_i = x)\\)とすると、 w_ate &lt;- table(df_multiple$X) weighted.mean(beta_vec, w = w_ate) ## [1] 0.687105 となる。重回帰によって求めた推定値との差は、 coef(fit_long)[2] - weighted.mean(beta_vec, w = w_ate) ## D ## 0.003489067 である。2つの推定方法にはあまり違いがないようである。 同様に、ATT（処置群における平均処置効果）を求めるために \\(X = x\\) となるブロックの重みを\\(\\Pr (X_i = x \\mid D_i = 1)\\)とすると、 df_treated &lt;- df_multiple %&gt;% filter(D == 1) w_att &lt;- table(df_treated$X) weighted.mean(beta_vec, w = w_att) ## [1] 0.6648775 となる。重回帰によって求めた推定値との差は、 coef(fit_long)[2] - weighted.mean(beta_vec, w = w_att) ## D ## 0.02571656 となる。 1回だけでは信じられないので、重回帰の推定値とブロックごとの単回帰から求めた ATEの推定値の差をとるシミュレーションを繰り返してみよう。 まずは、2つの推定値の差を1回計算するための関数を作る。 sim_reg_block &lt;- function(N = 1000, beta = 0.7, gamma = 0.3, lambda = 0.5) { ## beta: D の因果効果 ## gamma: X と Y の関係の強さ ## lambda X と D の関係の強さ X &lt;- sample(-4:4, size = N, replace = TRUE) theta &lt;- inv_logit(lambda * X) D &lt;- rbinom(N, size = 1, prob = theta) Y &lt;- 0.5 + beta * D + gamma * X + rnorm(N, mean = 0, sd = 0.5) df &lt;- tibble(Y, D, X) fit &lt;- lm(Y ~ D + X) beta_vec &lt;- sapply(-4:4, beta_X, data = df) weight &lt;- table(X) dif &lt;- coef(fit)[2] - weighted.mean(beta_vec, w = weight) names(dif) &lt;- &quot;difference&quot; return(dif) } この関数を1回使ってみる。 sim_reg_block() ## difference ## -0.02281703 1000回繰り返して結果を可視化する。 sim_rb &lt;- replicate(1000, sim_reg_block()) hist_sim_rb &lt;- tibble(difference = sim_rb) %&gt;% ggplot(aes(x = difference, y = after_stat(density))) + geom_histogram(binwidth = 0.005, color = &quot;black&quot;) + labs(x = &quot;「重回帰」と「ブロックの単回帰の加重平均」の差&quot;, y = &quot;確率密度&quot;) plot(hist_sim_rb) 5パーセンタイルと95パーセンタイルをとると、 quantile(sim_rb, p = c(0.05, 0.95)) ## 5% 95% ## -0.02336985 0.02359641 となる。つまり、シミュレーションの値のうち90% が \\([-0.023, 0.024]\\) の間にある。推定しようとしている値は 0.70 なので、2つの推定方法の間には平均的には差がないと考えてよさそうだ。 このように、重回帰の結果は、ブロックごとに単回帰してその加重平均を求めた場合とほぼ同じ結果になることがわかる。 4.2.4 重回帰分析によるセレクションバイアスの除去 トピック2 で考えた、病院と健康状態の例をもう1度考える。 トピック2では、以下の関数でセレクションバイアスのシミュレーションをした（一部書き換え）。 sim_hospital &lt;- function(beta = 0.6, N = 1e4, mu = c(0.75, 0.6, 0.4, 0.3, 0.2), sigma = rep(0.1, 5)) { # sigma は、健康状態ごとに変えても良いことにする if (length(sigma == 1)) sigma &lt;- rep(sigma, 5) h_hidden &lt;- sample(1:5, size = N, replace = TRUE, prob = c(1, 2, 3, 2, 1)) prob &lt;- rnorm(N, mean = mu[h_hidden], sd = sigma[h_hidden]) prob &lt;- case_when( prob &gt; 1 ~ 1, prob &lt; 0 ~ 0, TRUE ~ prob ) D &lt;- rbinom(N, size = 1, prob = prob) Y &lt;- h_hidden + beta * D + rnorm(N) # この行を書き換え：Y にノイズを加える fit &lt;- lm(Y ~ D) return(coef(fit)[2]) } シミュレーションを1000回実行してみよう。 sb1 &lt;- replicate(1000, sim_hospital()) この結果を図示する。 hist_sb1 &lt;- tibble(beta = sb1) %&gt;% ggplot(aes(x = beta, y = after_stat(density))) + geom_histogram(color = &quot;black&quot;, binwidth = 0.01) + labs(x= &quot;単純比較から得られる「効果」&quot;, y = &quot;確率密度&quot;) plot(hist_sb1) 処置効果を0.6 に設定しているのに、セルフセレクションのせいで効果が過小推定されている。問題は、セルフセレクションに使われる、元の健康状態 h_hidden が未観測であることだった。 h_hidden が観測されていれば、重回帰によってセレクションバイアスを取り除くことができる。 関数を書き換えて、確かめてみよう。 sim_hospital2 &lt;- function(beta = 0.6, N = 1e4, mu = c(0.75, 0.6, 0.4, 0.3, 0.2), sigma = rep(0.1, 5)) { # sigma は、健康状態ごとに変えても良いことにする if (length(sigma == 1)) sigma &lt;- rep(sigma, 5) h_hidden &lt;- sample(1:5, size = N, replace = TRUE, prob = c(1, 2, 3, 2, 1)) prob &lt;- rnorm(N, mean = mu[h_hidden], sd = sigma[h_hidden]) prob &lt;- case_when( prob &gt; 1 ~ 1, prob &lt; 0 ~ 0, TRUE ~ prob ) D &lt;- rbinom(N, size = 1, prob = prob) Y &lt;- h_hidden + beta * D + rnorm(N) fit &lt;- lm(Y ~ D + h_hidden) # この行を書き換え：h_hidden を含む重回帰分析を行う return(coef(fit)[2]) } 書き換えたのは、1行だけである。 この関数で、シミュレーションを1000回実行してみよう。 sb2 &lt;- replicate(1000, sim_hospital2()) この結果を可視化しよう。 hist_sb2 &lt;- tibble(beta = sb2) %&gt;% ggplot(aes(x = beta, y = after_stat(density))) + geom_histogram(color = &quot;black&quot;, binwidth = 0.01) + geom_vline(xintercept = 0.6, color = &quot;tomato&quot;) + labs(x= &quot;重回帰によって推定される「効果」&quot;, y = &quot;確率密度&quot;) plot(hist_sb2) このように、セレクションの原因となっている変数を重回帰モデルに加えることができれば、セレクションバイアスを除去することができる。 これができるのは、セレクションの原因が観測されているときだけである。 4.3 脱落変数バイアスと処置後変数バイアス 重回帰分析では複数の説明変数を使う。複数の説明変数を使う理由の1つは、ある結果に影響を与える原因が複数あると考えられるからである。そのようなとき、原因と考えられる複数の説明変数を回帰分析に含めるというのは自然な発想である。しかし、結果変数の原因となる変数のなかには、因果推論のために必ず回帰分析に含める必要があるものもあれば、回帰分析に含めても含めなくてもよいものや、回帰分析に含んではいけないものもある。統計的因果推論のための回帰分析で、統制 (control) すべき変数はどのようなものだろうか。シミュレーションを通じて理解しよう。 4.3.1 脱落変数バイアス (OVB) 2つの変数 \\(Y\\) と\\(D\\) があり、この2変数の間に強い相関があるとする。このとき、\\(D\\) が \\(Y\\) の原因であるとは限らない。1つの可能性は、\\(Y\\) が \\(D\\) の原因であるというものである。因果の向きが逆の場合については、ここでは考えない（実際の研究においては、それぞれの変数がお互いの原因であるという「同時性 (simulteneity)」も重要な問題である）。 もう1つの可能性は、第三の変数 \\(X\\) が存在し、\\(X\\) が \\(D\\) の原因であると同時に、\\(Y\\) の原因でもあるという場合である。 \\(D\\) と \\(Y\\) の相関が \\(X\\) によって説明されてしまうとき、\\(D\\) と \\(Y\\) の相関は、見せかけの因果関係 (spurious correlation) と呼ばれる。また、実際に \\(D\\) が \\(Y\\) の原因だとしても、 \\(X\\) のように \\(D\\) と \\(Y\\) の両者に影響する変数があるかもしれない。このような \\(X\\) は、交絡変数 [交絡因子] (confouding variable or confounder) または共変量 (covariate) と呼ばれる。 回帰分析で \\(D\\) が\\(Y\\) に及ぼす因果効果を推定するためには、交絡変数を必ず統制する必要がある（厳密には、バックドアパスをブロックすればよい）。交絡変数を統制しないと、推定にバイアスが生じる。このバイアスを脱落変数バイアス (omitted variable bias; OVB) と呼ぶ。OVBは、回帰分析におけるセレクションバイアスである。 \\(Y\\) と \\(D\\) の両者に影響を与える \\(X\\) という交絡変数があるとき、\\(X\\) を無視して、 \\[ Y_i = \\alpha^s + \\beta^s D_i + u_i \\] という回帰式を考えると、\\(X\\) は誤差項 \\(u\\) に含まれることになる。 そうすると、\\(\\beta^s\\) は \\(D\\) が \\(Y\\) に与える因果効果の推定量ではなく、バイアスを含んだ推定量になってしまう。そのバイアスが、脱落変数バイアスである。 このことを、シミュレーションで確認してみよう。まず、データを作る。ここでは、D, X1, X2 という3つの変数が Y の原因となっている（muを計算する行を参照）。また、X1 は D の原因でもあるので、X1 は交絡変数である。したがって、X1 を統制（コントロール）しないと、D の係数が正しく推定できないはずである。X3 は結果変数とは無関係の変数である。 この関係を図にしよう。X3は他の変数に影響しないので、省略する。（この図の作り方は後で説明する。） まず、D が Y に与える因果効果 beta の値を決める。 beta &lt;- 0.4 次に、データを生成する。 ## シミュレーションを再度実行したときに同じ結果が得られるように、乱数の種を指定する ## 異なる結果を得たいときは、set.seed() の中身を変える set.seed(777) N &lt;- 100 X1 &lt;- runif(N, min = -5, max = 5) X2 &lt;- runif(N, min = -5, max = 5) X3 &lt;- runif(N, min = -5, max = 5) D &lt;- 0.2 * X1 + rnorm(N) mu &lt;- 1.5 + beta * D + 0.5 * X1 - 0.2 * X2 Y &lt;- rnorm(N, mean = mu, sd = 1) df &lt;- tibble(Y, D, X1, X2, X3) 正しいモデルを作り、パラメタを推定する。 true_model &lt;- lm(Y ~ D + X1 + X2, data = df) tidy(true_model) ## # A tibble: 4 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 1.58 0.114 13.8 1.55e-24 ## 2 D 0.419 0.104 4.04 1.07e- 4 ## 3 X1 0.507 0.0432 11.7 3.19e-20 ## 4 X2 -0.159 0.0415 -3.83 2.26e- 4 D の係数に注目すると、パラメタとして設定した 0.4 にある程度近い値 0.42 が得られる。 次に、交絡変数であるX1を除外した「正しくない」モデル (short regression) でパラメタを推定する。 omitted_1 &lt;- lm(Y ~ D + X2, data = df) tidy(omitted_1) ## # A tibble: 3 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 1.55 0.177 8.77 6.16e-14 ## 2 D 0.983 0.142 6.91 5.14e-10 ## 3 X2 -0.157 0.0644 -2.44 1.64e- 2 このモデルでは、Dの係数の推定値が 0.98 になり、D の Y に対する影響がかなり過大に推定されている。 続いて、\\(Y\\) の原因ではあるが、交絡変数ではないX2 を除外してみる。 omitted_2 &lt;- lm(Y ~ D + X1, data = df) tidy(omitted_2) ## # A tibble: 3 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 1.62 0.121 13.3 1.18e-23 ## 2 D 0.384 0.110 3.48 7.48e- 4 ## 3 X1 0.506 0.0462 11.0 1.16e-18 ここでは D の係数が 0.38 であり、正しい値である 0.4 に近い。 最後に、Y の原因ではない（関係のない）X3 を加えて回帰分析をしてみよう。 extra_model &lt;- lm(Y ~ D + X1 + X2 + X3, data = df) tidy(extra_model) ## # A tibble: 5 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 1.57 0.115 13.7 2.82e-24 ## 2 D 0.422 0.105 4.02 1.17e- 4 ## 3 X1 0.507 0.0435 11.7 5.21e-20 ## 4 X2 -0.159 0.0417 -3.81 2.46e- 4 ## 5 X3 -0.00954 0.0395 -0.241 8.10e- 1 D の係数についてはほぼ正しい値に近い推定値が得られた。また、X3の係数が0に近く、影響がないという事実と整合的な結果が得られた。 ここまでのシミュレーションは、データセットを1つ生成し、それを分析しただけである。1つのデータだけでは偶然そうなっただけかもしれないので、上のシミュレーションを繰り返し行い、推定結果を調べてみよう。 まず、繰り返しシミュレーションを行うための関数を作る。 sim_regression &lt;- function(N = 50, beta = 0.4, gamma = 0.2, lambda = 0.5) { ## 重回帰分析をシミュレートするための関数 ## 引数：N = 標本サイズ（既定値は50） ## beta = 処置効果 ## gamma = 処置と交絡の関係の強さ ## lambda = 結果と交絡の関係の強さ ## 返り値：モデルの名前、beta の推定値、標準誤差の3列をもつデータフレーム X1 &lt;- runif(N, min = -5, max = 5) X2 &lt;- runif(N, min = -5, max = 5) X3 &lt;- runif(N, min = -5, max = 5) D &lt;- gamma * X1 + rnorm(N, mean = 0, sd = 1) mu &lt;- 1.5 + beta * D + lambda * X1 - 0.2 * X2 Y &lt;- mu + rnorm(N, mean = 0, sd = 1) df &lt;- tibble(Y, D, X1, X2, X3) models &lt;- list(true = Y ~ D + X1 + X2, omit1 = Y ~ D + X2, omit2 = Y ~ D + X1, extra = Y ~ D + X1 + X2 + X3) %&gt;% enframe(name = &quot;model&quot;, value = &quot;formula&quot;) %&gt;% mutate(fit = map(.x = formula, .f = lm, data = df), res = map(.x = fit, .f = tidy)) %&gt;% unnest(cols = res) beta &lt;- models %&gt;% filter(term == &quot;D&quot;) %&gt;% select(model, estimate, std.error) return(beta) } この関数を、1度だけ使ってみよう。 sim_regression() ## # A tibble: 4 x 3 ## model estimate std.error ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 true 0.346 0.188 ## 2 omit1 1.00 0.240 ## 3 omit2 0.574 0.200 ## 4 extra 0.345 0.190 各モデルによる beta の推定値とその標準誤差が計算される。 作った関数を使い、シミュレーションを1000回行ってみよう。 n_trials &lt;- 1000 sim_1 &lt;- replicate(n_trials, sim_regression()) この結果は行列になっていて使いにくいので、リストに変換する。 sim1 &lt;- array_tree(sim_1, margin = 2) モデルごとの推定値を取り出して、データフレームにまとめる。 sim1_beta &lt;- tibble(sim_id = 1:n_trials) %&gt;% mutate(true = sapply(1:n_trials, function(i) sim1[[i]]$estimate[1]), omit1 = sapply(1:n_trials, function(i) sim1[[i]]$estimate[2]), omit2 = sapply(1:n_trials, function(i) sim1[[i]]$estimate[3]), extra = sapply(1:n_trials, function(i) sim1[[i]]$estimate[4])) モデルごとの推定値の平均値を確認する。 #sim1_beta %&gt;% summarize(across(true:extra, mean)) # across() の使い方がわかるならこれで sim1_beta %&gt;% select(-sim_id) %&gt;% colMeans() ## true omit1 omit2 extra ## 0.3996831 1.0281552 0.4005514 0.3995259 この結果をみると、問題がある（推定値の平均が設定した処置効果である0.4から外れている）のはomit1だけである。それぞれのモデルから得られた係数betaの推定値の分布を図示してみよう。 正しいモデル (true)： hist1 &lt;- ggplot(sim1_beta, aes(y = after_stat(density))) + labs(x = &quot;処置効果の推定値&quot;, y = &quot;確率密度&quot;) hist1_true &lt;- hist1 + geom_histogram(aes(x = true), binwidth = 0.1, color = &quot;black&quot;) + geom_vline(xintercept = 0.4, color = &quot;tomato&quot;) plot(hist1_true) 交絡変数が脱落したモデル (omit1)： hist1_omit1 &lt;- hist1 + geom_histogram(aes(x = omit1), binwidth = 0.1, color = &quot;black&quot;) + geom_vline(xintercept = 0.4, color = &quot;tomato&quot;) plot(hist1_omit1) 交絡ではない変数を除いたモデル (omit2)： hist1_omit2 &lt;- hist1 + geom_histogram(aes(x = omit2), binwidth = 0.1, color = &quot;black&quot;) + geom_vline(xintercept = 0.4, color = &quot;tomato&quot;) plot(hist1_omit2) 結果変数の原因ではない余分な変数を加えたモデル (extra)： hist1_extra &lt;- hist1 + geom_histogram(aes(x = extra), binwidth = 0.1, color = &quot;black&quot;) + geom_vline(xintercept = 0.4, color = &quot;tomato&quot;) plot(hist1_extra) このシミュレーションから、交絡変数ではない原因を入れ損ねたり、原因ではない変数を入れてしまうのは問題ないが、交絡変数を説明変数に加え忘れると、平均して誤った分析結果を出してしまうことがわかる。したがって、交絡変数は必ず回帰分析に加える必要がある。 交絡を入れ損ねるとバイアスが生じ、関係ない変数を入れても問題がないのであれば、できるだけ多くの変数を統制したほうがよさそうである。実際、脱落変数バイアスを防ぐためには、できるだけたくさんの要因を統制した方がよい。ただし、手当たり次第に変数を投入すると起きる問題が（少なくとも）2つある。 まず、モデルが現実（真実）から乖離する確率が大きくなる。 この問題が起きるのは、モデルに含む説明変数が増えるにつれて、変数同士の関係のあり方のパタン（例えば、2変数以上の相互作用があるかどうか）が増えるのに対し、実際に正しいモデル（実際にデータが生成される過程）は1つしかないはずだからである。この問題は、ノンパラメトリックな方法を使えば回避することができる（今回は考えない）。 もう1つの問題は、処置後変数バイアスという異なる種類のバイアスが生じる可能性である。 この問題を次のシミュレーションで理解しよう。 4.3.2 処置後変数バイアス 処置後変数バイアス (post-treatment variable bias) とは、処置変数 \\(D\\) の影響を受けて生成される変数を説明変数として使うことによって生じるバイアスである。 処置後変数バイアスがあると、\\(D\\) が \\(Y\\) に及ぼす因果効果を正しく推定することができない。 以下のシミュレーションで、処置後変数バイアスを確認してみよう。 処置後変数 X を含むデータ生成過程を表す関数を作る。 D が Y に与える因果効果を beta、D が X に与える影響を gamma とする。 ptb_dgp &lt;- function(N = 100, beta = 0.4, gamma = 0.2) { D &lt;- rbinom(N, size = 1, prob = .5) X &lt;- 0.3 + gamma * D + rnorm(N, mean = 0, sd = 0.1) Y &lt;- 0.2 + (beta / gamma) * X + rnorm(N, mean = 0, sd = 0.1) return(tibble(Y, D, X)) } 試しにデータセットを1つ作る。 set.seed(2020-06-12) df_pt1 &lt;- ptb_dgp() glimpse(df_pt1) ## Observations: 100 ## Variables: 3 ## $ Y &lt;dbl&gt; 0.6508057, 1.0442136, 1.3875204, 0.7219868, 1.3689279, 1.27171… ## $ D &lt;int&gt; 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ X &lt;dbl&gt; 0.30434106, 0.42179182, 0.52854906, 0.24054385, 0.53575256, 0.… ここで、\\(D\\) と \\(X\\) の相関関係を確認してみよう。 with(df_pt1, cor(D, X)) ## [1] 0.6946692 \\(D\\) と \\(X\\) に正の相関があることがわかる。また、\\(Y\\) と \\(X\\) については、 with(df_pt1, cor(Y, X)) ## [1] 0.9449683 となり、やはり強い正の相関がある。 ここで、「脱落変数バイアスを避けるため」（実際には、この考え方は誤りである）に、\\(X\\) を説明変数に含む以下のモデルを考える。 \\[ Y_i = \\alpha^p + \\beta^p D_i + \\lambda X_i + u_i. \\] このモデルのパラメタを推定してみよう。 fit_with &lt;- lm(Y ~ D + X, data = df_pt1) tidy(fit_with) ## # A tibble: 3 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.213 0.0336 6.33 7.64e- 9 ## 2 D 0.0265 0.0268 0.991 3.24e- 1 ## 3 X 1.96 0.0985 19.9 5.58e-36 推定値を見ると、Dの係数 \\(\\beta\\) は0.03 であり、正しい値である 0.4 よりも過小推定されている。 ここで、説明変数 \\(X\\) を除外して、以下のモデルを考えてみよう。 \\[ Y_i = \\alpha + \\beta D_i + e_i. \\] このモデルのパラメタを推定しよう。 fit_wo &lt;- lm(Y ~ D, data = df_pt1) tidy(fit_wo) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.831 0.0289 28.7 1.64e-49 ## 2 D 0.396 0.0431 9.18 7.26e-15 コントロール変数 \\(X\\) を除外したことにより、\\(\\beta\\) の推定値 0.4 となり、設定した値である 0.4 に近づいた。これは偶然だろうか？シミュレーションで確かめてみよう。 1回シミュレーションを実行し、処置後変数を含むモデルと含まないモデルの係数の推定値を返す関数を作る。 sim_ptb &lt;- function(N = 100, beta = 0.4, gamma = 0.2) { df &lt;- ptb_dgp(N = N, beta = beta, gamma = gamma) fit_with &lt;- lm(Y ~ D + X, data = df) fit_wo &lt;- lm(Y ~ D, data = df) betas &lt;- c(coef(fit_with)[2], coef(fit_wo)[2]) names(betas) &lt;- c(&#39;with&#39;, &#39;without&#39;) return(betas) } この関数を、replicate() で複数回実行する。1000回繰り返してみよう。 sim_ptb &lt;- replicate(1000, sim_ptb()) 結果をヒストグラムで確認する。 df_beta_ptb &lt;- tibble(with = sim_ptb[1, ], without = sim_ptb[2, ]) hist2 &lt;- ggplot(df_beta_ptb, aes(y = after_stat(density))) + labs(x = &quot;処置効果の推定値&quot;, y = &quot;確率密度&quot;) hist2_with &lt;- hist2 + geom_histogram(aes(x = with), binwidth = 0.025, color = &quot;black&quot;) + geom_vline(xintercept = 0.4, color = &quot;tomato&quot;) + ggtitle(&quot;処置後変数を含むモデル&quot;) hist2_wo &lt;- hist2 + geom_histogram(aes(x = without), binwidth = 0.025, color = &quot;black&quot;) + geom_vline(xintercept = 0.4, color = &quot;tomato&quot;) + ggtitle(&quot;処置後変数を含まないモデル&quot;) plot(hist2_with + hist2_wo) このように、ある処置変数 \\(D\\) の効果を推定したいとき、その変数の結果として出てくる変数を統制してはいけない。変数間に時間的な前後関係があれば、このバイアスを回避するのは比較的容易である。しかし、時間的な前後関係が不明なとき、ある変数が交絡変数か処置後変数かを見抜くのは難しい場合がある。調査・観察データを分析する場合だけでなく、実験においてもこのバイアスには注意が必要である (Montgomery, Nyhan, and Torres 2018)。 統計モデルを作るときには、自分が統制する変数は交絡であり、処置後変数ではないことを理論的に示すことが求められる。そのためには、実質科学的知見（経済学や経営学など、分析対象に関するドメイン知識）が必須である。 4.4 DAG（有向非巡回グラフ） DAG (irected acyclic graph, 有向非巡回グラフ) をR で描く方法を簡単に説明する。 R で DAG を描くために、dagitty とggdag の2つのパッケージを使う。どちらか片方だけでもDAG は描けるが、両方使えると便利である。 まず、dagitty だけで描いてみる。daggity::dagitty() で DAG を定義し、それぞれの変数の位置を dagitty::coordinates() で指定する。 dag_1 &lt;- dagitty(&quot;dag{D -&gt; Y; X -&gt; D; X -&gt; Y}&quot;) coordinates(dag_1) &lt;- list(x = c(D = 0, X = 1, Y = 2), y = c(D = 0, X = 1, Y = 0)) plot(dag_1) 同じ DAG を描くための dag の指定法はいろいろ考えられる。例えば、次のようにしても同じ図ができる。 dag_2 &lt;- dagitty(&quot;dag{D &lt;- X -&gt; Y; D -&gt; Y}&quot;) coordinates(dag_2) &lt;- coordinates(dag_1) plot(dag_2) あるいは、次のようにしても同じ図ができる。 dag_3 &lt;- dagitty(&quot;dag{X -&gt; {D Y}; D -&gt; Y}&quot;) coordinates(dag_3) &lt;- coordinates(dag_1) plot(dag_3) 変数の役割を指定することもできる。その際、処置は exposure（暴露）、結果は outcome、未観測の変数は unobserved とする。 dag_4 &lt;- dagitty(&quot;dag{ X -&gt; {D Y}; D -&gt; Y D [exposure] Y [outcome] X [unobserved] }&quot;) coordinates(dag_4) &lt;- coordinates(dag_1) plot(dag_4) これを、ggdag::tidy_dagitty で tidy なデータに変換する。 tidy_dag_1 &lt;- tidy_dagitty(dag_4) ggdag::ggdag() で ggplot風のDAGを描く。 ggdag(tidy_dag_1) テーマを theme_dag() に変える。 ggdag(tidy_dag_1) + theme_dag() dagitty を使わずに、ggdag::dagify() でDAG を描くこともできる。ggdag でDAG を描くときは、各ノードの座標はしてしなくても良い（勝手に決めてくれる）。 tidy_dag_2 &lt;- dagify( Y ~ D + X, D ~ Z, X ~ Z, exposure = &quot;D&quot;, # 処置変数（暴露 [exposure]） を指定 outcome = &quot;Y&quot; # 結果変数を指定 ) %&gt;% tidy_dagitty() ggdag(tidy_dag_2) + theme_dag() この DAG から、処置 D と 結果 Y の間には交絡因子があることがわかる。 では、どの変数を重回帰に含めれば良いだろうか？ ggdag::ggdag_adjustment_set() で明らかにすることができる。 ggdag_adjustment_set(tidy_dag_2) “adjusted” とされている変数を重回帰に含めると、そこで経路が塞がれ、バックドア経路が断ち切られることがわかる。ここでは、X または Z をコントロールすれば良いことがわかる。 Z が未観測だったらどうなるだろうか？ tidy_dag_3 &lt;- dagify( Y ~ D + X, D ~ Z, X ~ Z, exposure = &quot;D&quot;, # 処置変数（暴露 [exposure]） を指定 outcome = &quot;Y&quot;, # 結果変数を指定 latent = &quot;Z&quot;, # 未観測（潜在 [latent]）変数を指定 coords = list(x = c(D = 0, Y = 1, Z = 0, X = 1), y = c(D = 0, Y = 0, Z = 1, X = 1)) ) %&gt;% tidy_dagitty() ggdag(tidy_dag_3) + theme_dag() coord で各変数 (node) の座標を指定した以外、DAG自体には変化がない。 コントロールすべき変数はどれだろうか？ ggdag_adjustment_set(tidy_dag_3) 先ほどとは異なり、Z は未観測でコントロールできないので、X だけが候補としてあげられる。 複数のコントロールが必要な場合は次のようになる。 tidy_dag_4 &lt;- dagify( Y ~ D + X1 + X2, D ~ L + X2, X1 ~ L, outcome = &quot;Y&quot;, exposure = &quot;D&quot;, latent = &quot;L&quot;) %&gt;% tidy_dagitty() ggdag(tidy_dag_4) + theme_dag() ggdag_adjustment_set(tidy_dag_4) X1 と X2 の両者をコントロールする必要があることがわかる。 次に、処置後変数がある DAG を作り、コントロールすべきかどうか調べてみよう。 dag_pt1 &lt;- dagitty(&quot;dag{ D -&gt; X -&gt; Y; D -&gt; Y D [exposure] Y [outcome] }&quot;) coordinates(dag_pt1) &lt;- list(x = c(D = 0, Y = 2, X = 1), y = c(D = 0, Y = 0, X = 1)) tidy_dag_pt1 &lt;- tidy_dagitty(dag_pt1) ggdag(tidy_dag_pt1) + theme_dag() ggdag_adjustment_set(tidy_dag_pt1) “Backdoor Paths Unconditionally Closed” （コントロールなしでバックドアは閉じています）と表示され、X をコントールする必要がないことがわかる。 次のような場合はどうだろうか？ tidy_dag_pt2 &lt;- dagify( Y ~ D, X ~ D + Y, exposure = &quot;D&quot;, outcome = &quot;Y&quot;, coords = list(x = c(D = 0, Y = 2, X = 1), y = c(D = 1, Y = 1, X = 0))) %&gt;% tidy_dagitty() ggdag(tidy_dag_pt2) + theme_dag() ggdag_adjustment_set(tidy_dag_pt2) 先ほどと同様に、“Backdoor Paths Unconditionally Closed” （コントロールなしでバックドアは閉じています）と表示され、X をコントールする必要がないことがわかる。 さらに詳しい説明は、dagitty と ggdag の公式サイトと Michael Taylor氏による解説を参照されたい。 DAGitty ggdag “An Introduction to Directed Acyclic Graphs” by Michael Taylor 4.5 トピック4の課題 以下の2つを実行しなさい。 回帰分析のシミュレーション 上で行ったシミュレーションから1つ以上を取り上げ、シミュレーションの設定を変えて（例：gamma の値を変える）実行しなさい。 シミュレーションの結果からどのようなことを学んだか、簡潔に説明しなさい。 シミュレーション結果は、図または表にまとめること。 コントロール変数の選択 以下の図と同じ構造のDAGを作りなさい。 作ったDAG を利用して、重回帰分析によって D が Y に与える処置効果を推定するためにどの変数をコントロールすべきか答えなさい。 注意事項 課題レポートは R Markdown で作成し、PDF に knit して提出すること。 提出するファイル：metrics_hw04_LastFirst.pdf 提出する課題としては2つ目だが、ファイル名の番号はトピックに合わせる。 提出方法：Slack のダイレクトメッセージで提出。 提出期限：2020年6月29日（月）正午（日本時間） 参考文献 "],
["propensity-score.html", "Topic 5 傾向スコア 5.1 準備 5.2 傾向スコアを用いた因果推論の手順 5.3 共変量の選定 5.4 傾向スコアの推定 5.5 バランス調整、バランスチェック、因果効果の推定 5.6 トピック5 の課題", " Topic 5 傾向スコア トピック5の講義スライド (PDF, 1.4MB) 5.1 準備 5.1.1 予習、講義動画、実習課題 このトピックでやるべきことは、以下のとおりである。 シラバス(PDFファイル) に記載されているトピック5の予習課題を読む。 KUTLMS (Moodle) にあるトピック5の講義動画を視聴する。 この資料の続きを読み、Rを使った実習を行うことで、傾向スコアの使い方を学ぶ。 教科書 (安井 2020) 第3章のRを使った分析を自分でやってみる。 課題を提出する。 5.1.2 Rパッケージの読み込み 必要なパッケージを読み込み、作図用の日本語フォントを設定する。 pacman::p_load(tidyverse, broom, haven, WeightIt, cobalt, MatchIt, survey) theme_set(theme_gray(base_size = 10, base_family = &quot;HiraginoSans-W3&quot;)) # macOS用 #theme_set(theme_gray(base_size = 10, base_family = &quot;Meiryo&quot;)) # Windows用 #theme_set(theme_gray(base_size = 10, base_family = &quot;ipaex&quot;)) # Ubuntu用 #showtext::showtext_auto() # Cloud用 #theme_set(theme_gray(base_size = 10, base_family = &quot;noto&quot;)) # Cloud用 5.1.3 関数の自作 R 4.0.0 より前のバージョンで cobalt パッケージを使おうとすると、「deparse1 という関数がありません」というエラーが出る。そこで、deparse1() を自作しておく。 deparse1() は R 4.0.0 で導入されたので、4.0.0 以降のバージョンを使っている場合、この作業は不要。 if (as.integer(version$major) &lt; 4) { deparse1 &lt;- function(x) { paste(deparse(x), collapse = &#39; &#39;) } } 5.1.4 このトピックで使うRコードの説明 5.1.4.1 cut() cut() は連続値をとる変数をもとに、factor 型のカテゴリ変数を作るときに使う。 例として、0から1の間の値をとる変数をカテゴリ変数にしてみよう。 まず、変数をランダムに生成する。 a &lt;- runif(100, min = 0, max = 1) summary(a) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0009268 0.2334818 0.4748502 0.4726042 0.7045828 0.9869757 この変数を、[0, 0.2], (0.2, 0.4], (0.4, 0.6], (0.6, 0.8], (0.8, 1.0] の5つのカテゴリに分類するカテゴリ変数を作る。 f1 &lt;- cut(a, breaks = seq(0, 1, by = 0.2), include.lowest = TRUE) table(f1) ## f1 ## [0,0.2] (0.2,0.4] (0.4,0.6] (0.6,0.8] (0.8,1] ## 20 25 21 19 15 同様に、[0, 0.2), [0.2, 0.4), [0.4, 0.6), [0.6, 0.8), [0.8, 1.0] の5つのカテゴリにするには、right = FALSE にする。 f2 &lt;- cut(a, breaks = seq(0, 1, by = 0.2), include.lowest = TRUE, right = FALSE) table(f2) ## f2 ## [0,0.2) [0.2,0.4) [0.4,0.6) [0.6,0.8) [0.8,1] ## 20 25 21 19 15 各カテゴリに属する観測数を同数にしたいときは、quantile() を利用して次のようにする。 f3 &lt;- cut(a, breaks = quantile(a, prob = seq(0, 1, by = 0.2)), include.lowest = TRUE) table(f3) ## f3 ## [0.000927,0.213] (0.213,0.374] (0.374,0.56] (0.56,0.758] ## 20 20 20 20 ## (0.758,0.987] ## 20 5.2 傾向スコアを用いた因果推論の手順 傾向スコアを使った因果効果の推定は、以下の手順で行う。 共変量の選定 傾向スコアの推定 傾向スコアを用いたバランス調整 重み付け 層別 マッチング\\(\\ast\\)（King and Nielsen (2019) によると、傾向スコアを用いたマッチングを因果効果の推定に用いることは推奨されないので、ここでは説明しない。層別も広い意味ではマッチングだが。） 共変量のバランスチェック 処置効果（因果効果）の推定 感度分析\\(\\ast\\)（この授業では時間の都合で説明できないが、興味があれば Carnegie, Harada, and Hill (2016) を参照されたい。treatSens というパッケージが用意されている。） 教科書 (安井 2020) でも分析されている LaLonde (1986) の実験データ (Dehejia and Wahba 2002) を使い、傾向スコアを使った分析手順を説明する。 まず、データを入手しよう（安井 (2020) の p.120 を参照）。後で読み込み直すことも考えて、data ディレクトリに一旦ダウンロードする。 base_url &lt;- &quot;https://users.nber.org/~rdehejia/data/&quot; targets &lt;- c(&quot;nsw_dw.dta&quot;, &quot;cps_controls.dta&quot;, &quot;cps_controls3.dta&quot;) download.file(url = str_c(base_url, targets), destfile = str_c(&quot;data/&quot;, targets)) 手に入れたデータを読み込む。 d_cps1 &lt;- read_dta(&quot;data/cps_controls.dta&quot;) d_cps3 &lt;- read_dta(&quot;data/cps_controls3.dta&quot;) d_nsw &lt;- read_dta(&quot;data/nsw_dw.dta&quot;) 実験データである d_nsw で回帰分析をしてみる。共変量を全部タイプして + で繋ぐのが面倒なので、次のようにする。 covariates0 &lt;- names(d_nsw)[2:(ncol(d_nsw) - 1)] %&gt;% str_c(collapse = &quot; + &quot;) これで、共変量が + で繋がれた文字列ができた。傾向スコアの推定では、共変量の数が多くなるので、こういう方法を覚えておいたほうがいい。ただし、このままだと使えないので、さらに次のようにする。 rct_formula &lt;- &quot;re78 ~ &quot; %&gt;% str_c(covariates0) %&gt;% formula() これで、lm() で利用できる式 (formula) ができた。 rct_formula ## re78 ~ treat + age + education + black + hispanic + married + ## nodegree + re74 + re75 ## &lt;environment: 0x7fc76237ea88&gt; 回帰式を推定する。 ate_rct &lt;- coef(lm(rct_formula, data = d_nsw))[2] %&gt;% print() ## treat ## 1676.343 教科書に記載されているとおり、実験で推定された処置効果は $1676 であることがわかる。 次に、d_nsw の処置（介入）群を取り出して、d_cps1の処置群として扱うデータセットを作る。 d_cps1_nsw &lt;- d_nsw %&gt;% filter(treat == 1) %&gt;% rbind(d_cps1) 同様に、d_nsw の処置（介入）群を取り出して、d_cps3の処置群として扱うデータセットを作る。 d_cps3_nsw &lt;- d_nsw %&gt;% filter(treat == 1) %&gt;% rbind(d_cps3) 以下では、上のd_cps1_nsw を使って、傾向スコアを使った分析の手順を説明する。 d_cps3_nswの分析は課題とする。 5.3 共変量の選定 まず、データ d_cps1_nsw の中身を確認しよう。変数の数がそれほど多くないことがわかっているので、全体の要約統計量を表示して確認する。 summary(d_cps1_nsw) ## data_id treat age education ## Length:16177 Min. :0.00000 Min. :16.00 Min. : 0.00 ## Class :character 1st Qu.:0.00000 1st Qu.:24.00 1st Qu.:11.00 ## Mode :character Median :0.00000 Median :31.00 Median :12.00 ## Mean :0.01144 Mean :33.14 Mean :12.01 ## 3rd Qu.:0.00000 3rd Qu.:42.00 3rd Qu.:13.00 ## Max. :1.00000 Max. :55.00 Max. :18.00 ## black hispanic married nodegree ## Min. :0.00000 Min. :0.00000 Min. :0.0000 Min. :0.0000 ## 1st Qu.:0.00000 1st Qu.:0.00000 1st Qu.:0.0000 1st Qu.:0.0000 ## Median :0.00000 Median :0.00000 Median :1.0000 Median :0.0000 ## Mean :0.08234 Mean :0.07189 Mean :0.7058 Mean :0.3006 ## 3rd Qu.:0.00000 3rd Qu.:0.00000 3rd Qu.:1.0000 3rd Qu.:1.0000 ## Max. :1.00000 Max. :1.00000 Max. :1.0000 Max. :1.0000 ## re74 re75 re78 ## Min. : 0 Min. : 0 Min. : 0 ## 1st Qu.: 4075 1st Qu.: 4103 1st Qu.: 5493 ## Median :14892 Median :14374 Median :16240 ## Mean :13880 Mean :13512 Mean :14749 ## 3rd Qu.:23492 3rd Qu.:22830 3rd Qu.:25565 ## Max. :35040 Max. :25244 Max. :60308 回帰分析の準備として、処置変数である treat （職業訓練の有無）と、結果変数である re78（1978年の収入）以外の変数を中心化する。また、教科書に倣い、re74 と re75 の二乗項も作る（ただし、標準化する）。 myd &lt;- d_cps1_nsw %&gt;% mutate(age_c = age - mean(age), education_c = education - mean(education), black_c = black - mean(black), hispanic_c = hispanic - mean(hispanic), married_c = married - mean(married), nodegree_c = nodegree - mean(nodegree), re74_c = re74 - mean(re74), re75_c = re75 - mean(re75), re74_sq_c = (re74_c^2 - mean(re74_c^2)) / sd(re74_c^2), re75_sq_c = (re75_c^2- mean(re75_c^2)) / sd(re75_c^2)) %&gt;% dplyr::select(re78, treat, ends_with(&quot;_c&quot;)) 念のため、中心化したデータを確認する。 summary(myd) ## re78 treat age_c education_c ## Min. : 0 Min. :0.00000 Min. :-17.141 Min. :-12.008283 ## 1st Qu.: 5493 1st Qu.:0.00000 1st Qu.: -9.141 1st Qu.: -1.008283 ## Median :16240 Median :0.00000 Median : -2.141 Median : -0.008283 ## Mean :14749 Mean :0.01144 Mean : 0.000 Mean : 0.000000 ## 3rd Qu.:25565 3rd Qu.:0.00000 3rd Qu.: 8.859 3rd Qu.: 0.991717 ## Max. :60308 Max. :1.00000 Max. : 21.859 Max. : 5.991717 ## black_c hispanic_c married_c nodegree_c ## Min. :-0.08234 Min. :-0.07189 Min. :-0.7058 Min. :-0.3006 ## 1st Qu.:-0.08234 1st Qu.:-0.07189 1st Qu.:-0.7058 1st Qu.:-0.3006 ## Median :-0.08234 Median :-0.07189 Median : 0.2942 Median :-0.3006 ## Mean : 0.00000 Mean : 0.00000 Mean : 0.0000 Mean : 0.0000 ## 3rd Qu.:-0.08234 3rd Qu.:-0.07189 3rd Qu.: 0.2942 3rd Qu.: 0.6994 ## Max. : 0.91766 Max. : 0.92811 Max. : 0.2942 Max. : 0.6994 ## re74_c re75_c re74_sq_c re75_sq_c ## Min. :-13880 Min. :-13512.2 Min. :-1.36753 Min. :-1.3609 ## 1st Qu.: -9805 1st Qu.: -9408.8 1st Qu.:-1.02527 1st Qu.:-1.0265 ## Median : 1012 Median : 862.3 Median : 0.02418 Median : 0.0134 ## Mean : 0 Mean : 0.0 Mean : 0.00000 Mean : 0.0000 ## 3rd Qu.: 9611 3rd Qu.: 9318.0 3rd Qu.: 0.75710 3rd Qu.: 0.7986 ## Max. : 21160 Max. : 11731.3 Max. : 5.25847 Max. : 1.5040 この例では、処置変数と結果変数以外の変数をすべて使って傾向スコアを推定するが、自分でリサーチクエスチョンを立ててデータ分析を行う場合には、どの変数を傾向スコアの推定に使うかを考える必要がある。 ここですべての変数を使う理由は、それぞれの変数が結果変数には影響する（処置と結果の両者に影響するか、結果のみに影響する）と考えられるからである。 共変量あるいは傾向スコアによる調整を行わずに、処置群と統制群を単純比較してみよう。 reg_simple &lt;- lm(re78 ~ treat, data = myd) tidy(reg_simple) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 14847. 76.1 195. 0. ## 2 treat -8498. 712. -11.9 1.07e-32 処置（職業訓練）は収入を $8498 減らす という誤った効果が推定されている。この回帰分析によれば、この効果は有意水準0.01 （あるいはもっと小さくてもOK。例えば0.000000001）で統計的に有意である。 「統計的に有意な結果が出たからこれで分析は終わりだ！」などと思ってしまったら、どうなるだろうか？ 5.4 傾向スコアの推定 次に、傾向スコアを推定する。 ここでは、ロジスティック回帰で推定することにする。Rでロジスティック回帰（あるいはその他の一般化線形モデル [GLM]）を実行するには、glm() を使う。 ロジスティック回帰は、結果変数が \\(Y \\in \\{0, 1\\}\\)、説明変数が \\(X\\) だとすると、 \\[ Y_i \\sim \\mbox{Bernoulli}(\\theta_i)\\\\ \\mathrm{logit}(\\theta_i) = \\alpha_0 + \\alpha_1 X_{1i} + \\cdots + \\alpha_k X_{ik} \\] という統計モデルである。つまり、結果変数を生成する確率分布が \\(\\mbox{Bernoulli}(\\theta_i) = \\mbox{Binomial}(1, \\theta_i)\\) であり、リンク関数がロジット (logit) 関数であると仮定している。よって、glm() の引数で、family = binomial(link = \"logit\") を使い、glm(Y ~ X1 + X2 + X3, family = binomial(link = 'logit')) のようにして使う。 この例では共変量の数が多く、共変量を全部タイプして + で繋ぐのが面倒なので、次のようにする。 covariates &lt;- names(myd)[3:ncol(myd)] ps_formula &lt;- covariates %&gt;% str_c(collapse = &quot; + &quot;) %&gt;% str_c(&quot;treat ~ &quot;, .) %&gt;% formula() これで、glm() で利用できる式 (formula) ができた。 ps_formula ## treat ~ age_c + education_c + black_c + hispanic_c + married_c + ## nodegree_c + re74_c + re75_c + re74_sq_c + re75_sq_c ## &lt;environment: 0x7fc792607638&gt; これを使ってロジスティック回帰式を推定する。 fit_logistic &lt;- glm(ps_formula, data = myd, family = binomial(link = &quot;logit&quot;)) これで推定ができた。推定結果の読み方については、浅野 and 矢内 (2018) の第15章を参照。 ここでは、傾向スコアの推定値にのみ興味がある。傾向スコアすなわち \\(\\theta_i\\) の推定値は、fitted() で取り出せる。 myd$ps_logit &lt;- fitted(fit_logistic) 推定された傾向スコアの分布を確認してみよう hist_ps_logit &lt;- ggplot(myd, aes(x = ps_logit, y = after_stat(density))) + geom_histogram(color = &quot;black&quot;) + facet_grid(rows = vars(treat), scales = &quot;free_y&quot;) + labs(x = &quot;傾向スコアの推定値&quot;, y = &quot;確率密度&quot;) plot(hist_ps_logit) 統制群（0; 上段）と処置群（1; 下段）で傾向スコアの分布の傾向が大きく異なることがわかる（上段と下段で縦軸のスケールが異なる [“free_y” を指定した] ことに注意）。 念のため、他の種類の図も作ってみよう。 box_ps_logit &lt;- ggplot(myd, aes(x = as.factor(treat), y = ps_logit)) + geom_boxplot(width = 0.5) + labs(x = &quot;処置&quot;, y = &quot;傾向スコアの推定値&quot;) plot(box_ps_logit) 箱ひげ図で見ても、分布が大きく異なることがわかる（ちなみに、あまりにも分布が異なるので、バイオリン図では違いがよく見えない。また、観測数が多いので、蜂群図を作るのも大変である。この辺りは試行錯誤が必要）。ヒストグラムでは、統制群に傾向スコアの値が0.1以上の個体があるかどうかがよくわからなかったが、箱ひげ図を描いてみたところ、分布の範囲自体は重なり合っていることがわかる。つまり、「共有（共通）サポート (common support)」はありそうだ。 このように、複数の種類の図を描き、多角的に検討することが必要である。 5.5 バランス調整、バランスチェック、因果効果の推定 ここからは、バランス調整の方法別に、(1) その方法、(2) バランスチェック、(3) 因果効果の推定の3つのステップを合わせて説明する。バランス調整の方法として、次の方法を説明する 重み付け ATT を推定するための重み付け ATE を推定するための重み付け（IPW） 層別 5.5.1 重み付け 傾向スコアを利用した重み付けで因果効果を推定する方法を紹介する。推定の対象 (estimand) によって使う重みが異なるので、自分が何を推定したいのか明確にしておく必要がある。 通常、推定の対象としたいのは、ATE（平均処置効果）または ATT（処置群における平均処置効果）であることが多いので、この2つについて説明する。 5.5.1.1 ATT（処置群における平均処置効果）の推定 ATTを推定するために、傾向スコア \\(e_i(X)\\) を用いて次の重み (weight) を計算する。 \\[ w_i^{\\mathrm{ATT}} = D_i + (1 - D_i) \\frac{e_i(X)}{1 - e_i(X)} \\] この重みを使うと、処置群 (\\(D_i = 1\\)) の個体の重みは \\(w_i^{\\mathrm{ATT}} = 1\\) になる。つまり、処置群の個体には、傾向スコアに関係なく等しい重みが与えられる。 それに対し、統制群 (\\(D_i = 0)\\) の個体の重みは、\\(w_i^{\\mathrm{ATT}} = e_i(X) / (1 - e_i(X))\\) になる。つまり、傾向スコアが高いほど、大きな重みが与えられる。これは、傾向スコアが高い、すなわち処置群に入る確率が高いにも拘らず統制群に入った個体は、処置群の比較対象として重宝されるということを意味する。反対に、傾向スコアが低い個体は、処置群の比較対象としてあまり重要ではない（処置群にはそれによく似た個体が少ないのに、同種の個体が統制群にたくさんある）ので、割り引いて考えられるということである。 この重みを計算しよう。 myd &lt;- myd %&gt;% mutate(w_att = treat + (1 - treat) * ps_logit / (1 - ps_logit)) 統制群でこの重みがどのように分布しているか確認しよう。 hist_w_att &lt;- myd %&gt;% filter(treat == 0) %&gt;% ggplot(aes(x = w_att, y = after_stat(density))) + geom_histogram(color = &quot;black&quot;) + labs(x = &quot;ATT を推定するための重み&quot;, y = &quot;˚確率密度&quot;) plot(hist_w_att) 統制群には傾向スコアが小さな個体ばかりが集まっていて、重みも0付近に集中していることがわかる。 WeightIt パッケージのweightit() を使えば、傾向スコアの推定と重みの計算が一挙にできる。傾向スコア (propensity score; ps) を使うために、method = \"ps\" を指定する。また、推定対象 (estimand) に “ATT” を指定する。 w_att2 &lt;- weightit(ps_formula, data = myd, method = &quot;ps&quot;, estimand = &quot;ATT&quot;) weightit() の結果を使うと、cobalt パッケージの cobalt::bal.plot() で重みによる調整前後の傾向スコアの分布も確認できる。 hist_w_att2 &lt;- bal.plot(w_att2, var.name = &quot;prop.score&quot;, which = &quot;both&quot;, type = &quot;histogram&quot;, mirror = TRUE, sample.names = c(&quot;調整前&quot;, &quot;調整後&quot;)) + scale_fill_discrete(name = &quot;処置&quot;) + labs(x = &quot;傾向スコア&quot;, y = &quot;割合&quot;, title = &quot;傾向スコアの分布&quot;) plot(hist_w_att2) 処置群における因果効果を推定するために処置群の分布に合わせて、統制群の分布が調整されたことがわかる。 この調整によって、共変量のバランスが改善したかどうか確認しよう。cobalt::love.plot() を使う。 bal_att &lt;- love.plot(w_att2, threshold = 0.1, abs = TRUE, grid = TRUE, shapes = c(18, 20), color = c(&quot;tomato&quot;, &quot;royalblue&quot;), sample.names = c(&quot;調整前&quot;, &quot;調整後&quot;), title = &quot;共変量のバランス&quot;) + labs(x = &quot;標準化平均差の絶対値&quot;, shape = &quot;&quot;, size = &quot;&quot;, stroke = &quot;&quot;, colour = &quot;&quot;) plot(bal_att) すべての共変量について、重み付けによって処置群と統制群の間のバランスが改善し、標準化平均差の絶対値が0.1未満になっていることがわかる。 この重みを使い、ATT \\(= \\mathbb{E}[Y(1) \\mid D = 1] - \\mathbb{E}[Y(0) \\mid D = 1]\\)を推定してみよう。 \\(\\mathbb{E}[Y(1) \\mid D = 1]\\)は、 e_y1_d1 &lt;- myd %&gt;% filter(treat == 1) %&gt;% pull(re78) %&gt;% mean() %&gt;% print() ## [1] 6349.144 と推定される。\\(\\mathbb{E}[Y(0) \\mid D = 1]\\) は重みを使うと、 e_y0_d1 &lt;- myd %&gt;% filter(treat == 0) %&gt;% with(weighted.mean(re78, w = w_att)) %&gt;% print() ## [1] 5104.037 と、推定される。これらの差をとると、ATTは e_y1_d1 - e_y0_d1 ## [1] 1245.106 であると推定される。RCT によるATEの推定結果は 1676.34 なので、効果が小さく推定されているが、重みを使わない単純な平均値の差に比べると、バイアスがかなり小さくなったことがわかる。 lm() で weight を指定すれば、これと同じ推定値が得られる。 ps_weight_att1 &lt;- lm(re78 ~ treat, data = myd, weight = w_att) tidy(ps_weight_att1) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 5104. 78.8 64.8 0. ## 2 treat 1245. 111. 11.2 6.58e-29 WeightIt パッケージのweightit() で推定した重みを使っても、同じ結果が得られる。 ps_weight_att2 &lt;- lm(re78 ~ treat, weights = w_att2$weights, data = myd) tidy(ps_weight_att2) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 5104. 78.8 64.8 0. ## 2 treat 1245. 111. 11.2 6.58e-29 5.5.1.2 IPW: ATE（平均処置効果）の推定 続いて、ATEを推定するための重み付けについて説明する。 ATE を推定するためには、IPW (inverse probability weighting; 逆確率重み付け) という方法を用いる。 ATE \\(= \\mathbb{E}[Y(1)] - \\mathbb{E}[Y(0)]\\) のそれぞれの項を、傾向スコアを利用した重み付けによって推定する。 \\(\\mathbb{E}[Y(1)]\\)の推定値は、重み \\[ w_{1i} = \\frac{D_i}{e_i(X)} \\] を使って、 \\[ \\hat{\\mathbb{E}}[Y(1)] = \\sum{\\frac{w_{1i}Y_i}{\\sum w_{1i}}} = \\sum{\\frac{D_i / e_i(X)}{\\sum \\left[D_i / e_i(X)\\right]} Y_i} \\] である。また、\\(\\mathbb{E}[Y(0)]\\)の推定値は、重みを \\[ w_{0i} = \\frac{1 - D_i}{1 - e_i(X)} \\] として、 \\[ \\hat{\\mathbb{E}}[Y(0)] = \\sum{\\frac{w_{0i}Y_i}{\\sum w_{0i}}} = \\sum{\\frac{(1 - D_i) / (1 - e_i(X))}{\\sum \\left[(1 - D_i) / (1 - e_i(X))\\right]} Y_i} \\] である。 このように、処置群と統制群のそれぞれについてその群に割り付けられる傾向スコアの逆数で重みが決まるので、この名前が付いている。IPW では、それぞれの群で珍しい個体ほど重みが大きくなる。 この重み、 \\[ w_i = \\frac{D_i}{e_i(X)} + \\frac{1 - D_i}{1 - e_i(X)} \\] を計算しよう myd &lt;- myd %&gt;% mutate(w_ate = ifelse(treat == 1, 1 / ps_logit, 1 / (1 - ps_logit))) この重みがどのように分布しているか確認しよう。 hist_w_ate &lt;- myd %&gt;% ggplot(aes(x = w_ate, y = after_stat(density))) + geom_histogram(color = &quot;black&quot;) + facet_grid(row = vars(treat)) + labs(x = &quot;IPWによる重み&quot;, y = &quot;˚確率密度&quot;) plot(hist_w_ate) 処置群で傾向スコアが大きい個体の重みが割り引かれている一方で、統制群に傾向スコアが大きい個体があまりないため、重みが割増されている個体はあまりないことがわかる。 WeightIt::weightit() で重みを計算してみよう。推定対象 (estimand) に “ATE” を指定する。 w_ate2 &lt;- weightit(ps_formula, data = myd, method = &quot;ps&quot;, estimand = &quot;ATE&quot;) cobalt::bal.plot() で重みによる調整前後の傾向スコアの分布を確認する。 hist_w_ate2 &lt;- bal.plot(w_ate2, var.name = &quot;prop.score&quot;, which = &quot;both&quot;, type = &quot;histogram&quot;, mirror = TRUE, sample.names = c(&quot;調整前&quot;, &quot;調整後&quot;)) + scale_fill_discrete(name = &quot;処置&quot;) + labs(x = &quot;傾向スコア&quot;, y = &quot;割合&quot;, title = &quot;傾向スコアの分布&quot;) plot(hist_w_ate2) 調整後に、処置群の分布が統制群の分布に近づいていることがわかる。これは、処置群の観測数が 185 であるのに対して、統制群の観測数が 16,177 もあるためである。 この調整によって、共変量のバランスが改善したかどうか確認しよう。cobalt::love.plot() を使う。 bal_ate &lt;- love.plot(w_ate2, threshold = 0.1, abs = TRUE, grid = TRUE, shapes = c(18, 20), color = c(&quot;tomato&quot;, &quot;royalblue&quot;), sample.names = c(&quot;調整前&quot;, &quot;調整後&quot;), title = &quot;共変量のバランス&quot;) + labs(x = &quot;標準化平均差の絶対値&quot;, shape = &quot;&quot;, size = &quot;&quot;, stroke = &quot;&quot;, colour = &quot;&quot;) plot(bal_ate) すべての共変量についてバランスの改善は見られるものの、標準化平均値の絶対値が0.1未満になった共変量は3つだけであり、処置群と統制群のバランスがあまりよくないことがわかる。そのため、このまま処置効果を推定してもうまくいかない（バイアスが残る）ことが予想される。 実際のデータ分析では、このような場合には処置効果を推定しないほうがいい。ここでは、推定をしてしまうとどうなるか見てみよう。 上で計算した重みを使い、ATE \\(= \\mathbb{E}[Y(1)] - \\mathbb{E}[Y(0)]\\)を推定する。 まず、\\(Y(1)\\) の期待値の推定値は、 e_y1 &lt;- myd %&gt;% filter(treat == 1) %&gt;% with(weighted.mean(re78, w = w_ate)) %&gt;% print() ## [1] 7108.675 である。\\(Y(0)\\) の期待値の推定値は、 e_y0 &lt;- myd %&gt;% filter(treat == 0) %&gt;% with(weighted.mean(re78, w = w_ate)) %&gt;% print() ## [1] 14735.48 である。これらの差をとると、ATEは e_y1 - e_y0 ## [1] -7626.806 であると推定される。教科書 (pp.127-130) にも書かれているとおり、推定に大きなバイアスがあることがわかる。 lm() で weight を指定すれば、これと同じ結果が得られる。 ps_weight_ate1 &lt;- lm(re78 ~ treat, data = myd, weight = w_ate) tidy(ps_weight_ate1) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 14735. 82.8 178. 0 ## 2 treat -7627. 135. -56.5 0 WeightIt::weightit() で計算した重みを使っても、同じ結果が得られる。 ps_weight_ate2 &lt;- lm(re78 ~ treat, weights = w_ate2$weights, data = myd) tidy(ps_weight_ate2) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 14735. 82.8 178. 0 ## 2 treat -7627. 135. -56.5 0 このように、共変量のバランスがとれていない状態で因果効果を推定しようとすると、バイアスのある推定結果を得ることになるので、注意が必要である。 5.5.2 層別 推定した傾向スコアを利用して、サンプルを層 (strata) に分ける。まず、層の数を決める必要がある。ここでは5にする（層の数については、Thoermmes and Kim (2011) を参照） 。処置群と統制群の合計数がほぼ同じになるように、傾向スコアによって5つの層を作ろう。 myd %&gt;% mutate(subclass = cut(ps_logit, breaks = quantile(ps_logit, prob = seq(0, 1, by = 0.2)), include.lowest = TRUE)) %&gt;% with(table(treat, subclass)) ## subclass ## treat [3.72e-06,2.88e-05] (2.88e-05,7.85e-05] (7.85e-05,0.000463] ## 0 3238 3233 3235 ## 1 0 0 0 ## subclass ## treat (0.000463,0.00293] (0.00293,0.513] ## 0 3231 3055 ## 1 4 181 このような5つの層 (stratum; subclass) ができる。 MatchIt パッケージの matchit() を使えば、傾向スコアの推定と層別が一挙にできる。 層別のために method = \"subclass\" を指定する。また、層の数を subclass = 5 で、処置群と統制群の合計数、つまりサンプル全体の数を基準にして層別を行うため、 sub.by = \"all\" を指定する。 matchit(ps_formula, data = myd, method = &quot;subclass&quot;, subclass = 5, sub.by = &quot;all&quot;) %&gt;% with(table(treat, subclass)) ## subclass ## treat 1 2 3 4 5 ## 0 3235 3236 3235 3231 3055 ## 1 0 0 0 4 181 先ほどと同じ5つの層ができた。 この層別では、3つの層で処置群の個体数が0になってしまった。そんため、それら3つの層では処置効果が推定できない。この例から、処置群と統制群で傾向スコアの分布が大きく異なると、層別が難しいことがわかる。統制群のほとんどの個体にとって、処置群に比較対象となる個体が存在しない状況なので、ATE や ATC を推定するのは困難である。 このデータでは、統制群の観測数に対して処置群の観測数が非常に少ないので、処置群の観測数が等しくなるような5層を作り、ATT の推定を目指すことにしよう。 まず、処置群の個体を5分割するためのカットポイントを見つける。すべてのデータを含むために、最下限と最上限は0と1にする。 cutpoints &lt;- myd %&gt;% filter(treat == 1) %&gt;% pull(ps_logit) %&gt;% quantile(prob = seq(0, 1, by = 0.2)) cutpoints[1] &lt;- 0 cutpoints[6] &lt;- 1 このカットポイントを使って、サンプルを5層に分ける。 myd %&gt;% mutate(subclass = cut(ps_logit, breaks = cutpoints, include.lowest = TRUE)) %&gt;% with(table(treat, subclass)) ## subclass ## treat [0,0.0791] (0.0791,0.265] (0.265,0.299] (0.299,0.495] (0.495,1] ## 0 15607 239 38 79 29 ## 1 37 37 37 37 37 このように、処置群の観測数が等しい5つの層ができた。 MatchIt::matchit() で層別を行ってみよう。処置群に基づいて層別を行うために、sub.by = \"treat\" を指定する。 stratification &lt;- matchit(ps_formula, data = myd, method = &quot;subclass&quot;, subclass = 5, sub.by = &quot;treat&quot;) with(stratification, table(treat, subclass)) ## subclass ## treat 1 2 3 4 5 ## 0 15607 239 38 79 29 ## 1 37 37 37 37 37 上と同じ層別ができた。層の名前が整数値で1から5になっているこちらの層別のほうが便利なので、以下ではこのカテゴリ変数を使う。 myd$subclass &lt;- stratification$subclass バランスチェックは、MatchIt パッケージの機能を使って行うことができる。MatchIt::matchit() の結果に対し、summary() を使う。 summary(stratification, standardize = TRUE) ## ## Call: ## matchit(formula = ps_formula, data = myd, method = &quot;subclass&quot;, ## subclass = 5, sub.by = &quot;treat&quot;) ## Summary of balance for all data: ## Means Treated Means Control Std. Mean Diff. eCDF Med eCDF Mean ## distance 0.2835 0.0083 1.5328 0.5260 0.4935 ## age_c -7.3243 0.0847 -1.0355 0.1969 0.1863 ## education_c -1.6623 0.0192 -0.8363 0.0376 0.0908 ## black_c 0.7609 -0.0088 2.1113 0.3849 0.3849 ## hispanic_c -0.0124 0.0001 -0.0530 0.0063 0.0063 ## married_c -0.5166 0.0060 -1.3306 0.2613 0.2613 ## nodegree_c 0.4076 -0.0047 0.9044 0.2061 0.2061 ## re74_c -11784.8956 136.3310 -2.4396 0.5001 0.4591 ## re75_c -11980.1583 138.5899 -3.7645 0.5125 0.4751 ## re74_sq_c 1.0393 -0.0120 1.1257 0.2437 0.2455 ## re75_sq_c 1.0529 -0.0122 1.4492 0.3105 0.2759 ## eCDF Max ## distance 0.8156 ## age_c 0.3427 ## education_c 0.4123 ## black_c 0.7697 ## hispanic_c 0.0126 ## married_c 0.5225 ## nodegree_c 0.4123 ## re74_c 0.6031 ## re75_c 0.6509 ## re74_sq_c 0.5939 ## re75_sq_c 0.5663 ## ## ## Summary of balance by subclasses: ## , , Subclass 1 ## ## Means Treated Means Control Std. Mean Diff. eCDF Med ## distance 0.0219 0.0025 0.1081 0.4653 ## age_c -7.1135 0.2167 -1.0245 0.2308 ## education_c -1.3596 0.0518 -0.7020 0.0361 ## black_c 0.1609 -0.0304 0.5247 0.0956 ## hispanic_c 0.1984 0.0006 0.8339 0.0989 ## married_c -0.3544 0.0162 -0.9436 0.1853 ## nodegree_c 0.2670 -0.0112 0.6103 0.1391 ## re74_c -9565.1077 433.9322 -2.0462 0.4014 ## re75_c -9811.0064 446.7994 -3.1864 0.4176 ## re74_sq_c 0.4700 -0.0355 0.5412 0.0580 ## re75_sq_c 0.6385 -0.0393 0.9222 0.1932 ## eCDF Mean eCDF Max ## distance 0.4271 0.7228 ## age_c 0.1850 0.3159 ## education_c 0.0870 0.2782 ## black_c 0.0956 0.1913 ## hispanic_c 0.0989 0.1977 ## married_c 0.1853 0.3706 ## nodegree_c 0.1391 0.2782 ## re74_c 0.3857 0.4976 ## re75_c 0.4010 0.5571 ## re74_sq_c 0.0995 0.4360 ## re75_sq_c 0.1777 0.4074 ## ## , , Subclass 2 ## ## Means Treated Means Control Std. Mean Diff. eCDF Med ## distance 0.1740 0.1487 0.1408 0.1512 ## age_c -5.4108 -2.2158 -0.4465 0.1133 ## education_c -1.9813 -0.9539 -0.5110 0.0251 ## black_c 0.8906 0.8340 0.1554 0.0283 ## hispanic_c -0.0449 0.0118 -0.2389 0.0283 ## married_c -0.3274 -0.2288 -0.2511 0.0493 ## nodegree_c 0.4022 0.1220 0.6145 0.1401 ## re74_c -10372.8386 -11220.4982 0.1735 0.0952 ## re75_c -11067.0379 -12058.3668 0.3079 0.1222 ## re74_sq_c 0.4712 0.7476 -0.2960 0.1000 ## re75_sq_c 0.6374 0.9916 -0.4819 0.1222 ## eCDF Mean eCDF Max ## distance 0.1258 0.2428 ## age_c 0.1132 0.1987 ## education_c 0.0671 0.2801 ## black_c 0.0283 0.0567 ## hispanic_c 0.0283 0.0567 ## married_c 0.0493 0.0986 ## nodegree_c 0.1401 0.2801 ## re74_c 0.0909 0.1550 ## re75_c 0.1630 0.3261 ## re74_sq_c 0.1000 0.1676 ## re75_sq_c 0.1630 0.3261 ## ## , , Subclass 3 ## ## Means Treated Means Control Std. Mean Diff. eCDF Med ## distance 0.2823 0.2834 -0.0061 0.0573 ## age_c -6.0054 -5.1931 -0.1135 0.0761 ## education_c -0.1434 0.1759 -0.1588 0.0782 ## black_c 0.9177 0.9177 0.0000 0.0000 ## hispanic_c -0.0719 -0.0719 0.0000 0.0000 ## married_c -0.5166 -0.6794 0.4147 0.0814 ## nodegree_c 0.0238 -0.0637 0.1919 0.0437 ## re74_c -13325.9836 -12267.4256 -0.2166 0.1046 ## re75_c -13056.7155 -12983.7387 -0.0227 0.0228 ## re74_sq_c 1.3652 1.1627 0.2169 0.1046 ## re75_sq_c 1.3344 1.3069 0.0373 0.0228 ## eCDF Mean eCDF Max ## distance 0.0593 0.1664 ## age_c 0.0837 0.2027 ## education_c 0.0667 0.1294 ## black_c 0.0000 0.0000 ## hispanic_c 0.0000 0.0000 ## married_c 0.0814 0.1629 ## nodegree_c 0.0437 0.0875 ## re74_c 0.1311 0.3129 ## re75_c 0.0255 0.1003 ## re74_sq_c 0.1286 0.3129 ## re75_sq_c 0.0255 0.1003 ## ## , , Subclass 4 ## ## Means Treated Means Control Std. Mean Diff. eCDF Med ## distance 0.4367 0.4141 0.1258 0.1204 ## age_c -6.6810 -11.0139 0.6056 0.0486 ## education_c -2.9542 -2.7298 -0.1116 0.0161 ## black_c 0.9177 0.9177 0.0000 0.0000 ## hispanic_c -0.0719 -0.0719 0.0000 0.0000 ## married_c -0.6787 -0.7058 0.0688 0.0135 ## nodegree_c 0.6454 0.6615 -0.0353 0.0080 ## re74_c -11780.0790 -13187.5337 0.2880 0.0862 ## re75_c -12453.8182 -12528.5787 0.0232 0.0724 ## re74_sq_c 1.4064 1.2208 0.1988 0.0783 ## re75_sq_c 1.1502 1.1171 0.0451 0.0724 ## eCDF Mean eCDF Max ## distance 0.1387 0.3431 ## age_c 0.1475 0.4191 ## education_c 0.0310 0.1108 ## black_c 0.0000 0.0000 ## hispanic_c 0.0000 0.0000 ## married_c 0.0135 0.0270 ## nodegree_c 0.0080 0.0161 ## re74_c 0.1262 0.3534 ## re75_c 0.1177 0.3414 ## re74_sq_c 0.1263 0.3804 ## re75_sq_c 0.1177 0.3414 ## ## , , Subclass 5 ## ## Means Treated Means Control Std. Mean Diff. eCDF Med ## distance 0.5026 0.5045 -0.0106 0.0993 ## age_c -11.4108 -14.8302 0.4779 0.2684 ## education_c -1.8731 -2.1807 0.1530 0.0620 ## black_c 0.9177 0.9177 0.0000 0.0000 ## hispanic_c -0.0719 -0.0719 0.0000 0.0000 ## married_c -0.7058 -0.7058 0.0000 0.0000 ## nodegree_c 0.6994 0.6994 0.0000 0.0000 ## re74_c -13880.4693 -13879.2532 -0.0002 0.0172 ## re75_c -13512.2136 -13509.6208 -0.0008 0.0172 ## re74_sq_c 1.4838 1.4833 0.0005 0.0172 ## re75_sq_c 1.5040 1.5029 0.0015 0.0172 ## eCDF Mean eCDF Max ## distance 0.1000 0.2377 ## age_c 0.2346 0.4026 ## education_c 0.0769 0.1836 ## black_c 0.0000 0.0000 ## hispanic_c 0.0000 0.0000 ## married_c 0.0000 0.0000 ## nodegree_c 0.0000 0.0000 ## re74_c 0.0172 0.0345 ## re75_c 0.0172 0.0345 ## re74_sq_c 0.0172 0.0345 ## re75_sq_c 0.0172 0.0345 ## ## ## Sample sizes by subclasses: ## Subclass 1 Subclass 2 Subclass 3 Subclass 4 Subclass 5 ## Treated 37 37 37 37 37 ## Control 15607 239 38 79 29 ## Total 15644 276 75 116 66 ## ## Summary of balance across subclasses ## Means Treated Means Control Std. Mean Diff. eCDF Med eCDF Mean ## distance 0.2835 0.2706 0.0436 0.1787 0.1702 ## age_c -7.3243 -6.6073 0.2725 0.1474 0.1528 ## education_c -1.6623 -1.1273 0.1805 0.0435 0.0657 ## black_c 0.7609 0.7113 0.1094 0.0248 0.0248 ## hispanic_c -0.0124 -0.0406 0.1735 0.0254 0.0254 ## married_c -0.5166 -0.4607 0.2126 0.0659 0.0659 ## nodegree_c 0.4076 0.2816 0.1775 0.0662 0.0662 ## re74_c -11784.8956 -10024.1557 0.4170 0.1409 0.1502 ## re75_c -11980.1583 -10126.7011 0.6403 0.1304 0.1449 ## re74_sq_c 1.0393 0.9158 0.1367 0.0716 0.0943 ## re75_sq_c 1.0529 0.9758 0.2084 0.0856 0.1002 ## eCDF Max ## distance 0.3426 ## age_c 0.3078 ## education_c 0.1964 ## black_c 0.0496 ## hispanic_c 0.0509 ## married_c 0.1318 ## nodegree_c 0.1324 ## re74_c 0.2707 ## re75_c 0.2719 ## re74_sq_c 0.2663 ## re75_sq_c 0.2419 ## ## Percent Balance Improvement: ## Std. Mean Diff. eCDF Med eCDF Mean eCDF Max ## distance 95.3285 66.0277 65.5163 57.9989 ## age_c 90.3223 25.1233 17.9695 10.1943 ## education_c 68.1847 -15.7669 27.6059 52.3516 ## black_c 93.5577 93.5577 93.5577 93.5577 ## hispanic_c -124.3598 -304.5522 -304.5522 -304.5522 ## married_c 89.3108 74.7742 74.7742 74.7742 ## nodegree_c 69.4512 67.8911 67.8911 67.8911 ## re74_c 85.2302 71.8249 67.2800 55.1151 ## re75_c 84.7059 74.5490 69.5076 58.2287 ## re74_sq_c 88.2488 70.6169 61.5797 55.1611 ## re75_sq_c 92.7662 72.4394 63.6699 57.2740 サンプル全体での共変量のバランス (Summary of balance for all data) と、各層 (subclass) での共変量のバランス (Summary of balance by subclasses) が表示されている。ほとんどの共変量について、全体よりも層別した方が標準化平均差 (Std. Mean Diff.) の絶対値 が小さくなっている。しかし、基準である 0.1 または 0.25 よりも大きい差が複数残されており、層別によるバランスはあまり良くないことがわかる。 ヒスパニックであることを示す変数については全体でのバランスが元々良いため、サブクラスにすることによってバランスがむしろ悪化している（特に、層1と層2で特に平均差が大きい）。 図でバランスチェックするには、例えば次のようにする。 bal_subclass &lt;- stratification %&gt;% love.plot(stats = &quot;m&quot;, # 平均差 binary = &quot;std&quot;, # 標準化 abs = TRUE, # 絶対値 disp.subclass = TRUE, threshold = 0.1, grid = TRUE, shapes = c(18, 20), color = c(&quot;tomato&quot;, &quot;royalblue&quot;), title = &quot;共変量のバランス&quot;) + labs(x = &quot;標準化平均差の絶対値&quot;, shape = &quot;&quot;, size = &quot;&quot;, stroke = &quot;&quot;, colour = &quot;&quot;) plot(bal_subclass) このように、処置群と統制群の間のバランスが悪いので、実際のデータ分析であれば因果効果を推定しない方が良い。しかし、ここではこの層別を利用してATTを推定するとどうなるか確認してみよう。 まず、層別のATTを推定する。各層で処置群と統制群の平均値の差を計算すれば良い。 subclass_att &lt;- myd %&gt;% group_by(subclass, treat) %&gt;% summarize(mean = mean(re78)) %&gt;% group_by(subclass) %&gt;% summarize(att = diff(mean)) %&gt;% pull(att) %&gt;% print() ## [1] -8198.9656 1112.3861 4218.7575 2462.4248 -254.7994 この層別のATTの加重平均がATT である。その際の重みは、各層に属する処置群の個体数を、処置群全体の個体数で割ったものである。同じ個体数で5つの層に分けたので、当然すべての重みが0.2であるが、一応計算しておく。 w_subclass &lt;- myd %&gt;% filter(treat == 1) %&gt;% with(table(subclass) / sum(table(subclass))) %&gt;% print() ## subclass ## 1 2 3 4 5 ## 0.2 0.2 0.2 0.2 0.2 （ちなみに、ATEを推定する場合の各層の重みは、各層に属する個体数をサンプルサイズで割ったものである。つまり、全サンプルに占める各層の割合が重みとなる。） よって、ATTの推定値は、 #mean(subclass_att) # すべて同じ重みなので、単純平均でも同じ weighted.mean(subclass_att, w = w_subclass) ## [1] -132.0394 である。効果が過小推定されており、バイアスが残っていることがわかる。やはり、バランスが悪いのに因果効果を推定しようとしてはいけない。 標準誤差も知りたいので、survey パッケージを利用して計算しよう。 まず、survey::svydesign() で利用するデータセットを指定する。引数 ids が必須だが、ここでは id （観測個体の識別子）を利用した分析を行わないので ids = ~ 0 とする（svydesign() の引数に strata があるが、これはサーベイの層別を指定するための引数で、傾向スコアによる層別を指定するものではないので注意。ここでは何も指定しない）。 survey_design &lt;- svydesign(ids = ~ 0, data = myd) 次に、survey::svyby() を使って、層別に結果変数の平均値を計算する。formula に平均値を計算したい結果変数を指定し、by に処置変数と層別の変数を指定する。 平均値を計算するので、FUN = svymean とする。 sub_means &lt;- svyby(formula = ~ re78, by = ~ treat + subclass, design = survey_design, FUN = svymean) %&gt;% print() ## treat subclass re78 se ## 0.1 0 1 15099.216 76.70063 ## 1.1 1 1 6900.250 1004.16699 ## 0.2 0 2 4777.960 411.31318 ## 1.2 1 2 5890.346 987.67556 ## 0.3 0 3 3655.507 847.17351 ## 1.3 1 3 7874.264 1364.47511 ## 0.4 0 4 4723.113 658.70935 ## 1.4 1 4 7185.538 1901.99061 ## 0.5 0 5 4150.119 866.27710 ## 1.5 1 5 3895.319 773.29914 このように、各層別に、処置群と統制群のそれぞれで結果変数の平均値が計算される。 最後にATT の推定値と標準誤差を、survey::svycontrast() で計算する。 そのために、重みをリストで与える必要がある。上の表（処置・層別の平均値の表）で表示されている順番に重みを指定する。その際、処置群には先ほど計算した重みである0.2 を与え、統制群にはそれを負の値にしたものを与える。 svycontrast(sub_means, list(ATT = rep(c(-0.2, 0.2), 5))) ## contrast SE ## ATT -132.04 636.81 上で計算したものと同じ推定値が得られた。また、標準誤差は636.8 であることがわかった。 （これは有意水準 0.05 で統計的に有意ではない。） このように、調査・観察データを使った因果推論には、様々な工夫が必要であり、慎重に分析を進める必要がある。 また、さまざまな仮定をおいて分析を行っており、仮定が成り立たない場合には、因果効果を正しく推定できない。 自分がどのような仮定に基づいてデータを分析しているのか、常に意識するようにしよう。 5.6 トピック5 の課題 上で作ったデータセット d_cps3_nsw を使って、傾向スコアを用いた因果推論を行いなさい。 以下の内容を必ず含めること。 傾向スコアを使わずに、統制群と処置群を単純比較した場合の効果の推定値を求める。 傾向スコアによるバランスの調整（ATEとATTのどちらを推定しようとしているか明確に）。以下の2つを実施する。 重み付け 層別 上のそれぞれについて、バランスチェックを行う。 それぞれの方法で、処置効果を推定する。 1で求めた推定値と4で求めた推定値を比較して、どのようなことがわかるか説明する。 注意事項 課題レポートは R Markdown で作成し、PDF に knit して提出すること。 提出するファイル：metrics_hw05_LastFirst.pdf 提出方法：Slack のダイレクトメッセージで提出。 提出期限：2020年7月6日（月）正午（日本時間） 参考文献 "],
["panel-data.html", "Topic 6 パネルデータ分析", " Topic 6 パネルデータ分析 準備中 "],
["midterm-presentation.html", "Topic 7 分析計画のプレゼンテーション 7.1 このトピックでやるべきこと 7.2 分析計画のプレゼンテーション 7.3 他の受講生へのコメントについて", " Topic 7 分析計画のプレゼンテーション 7.1 このトピックでやるべきこと 自分の分析計画のプレゼンテーションを行う！ 他の受講生のプレゼンテーションを視聴する。 他の受講生の分析計画にコメントする。 各自、自分以外の2人のプレゼンテーションにコメントする。 誰がどのプレゼンテーションにコメントするかは、担当教員が決める。 割り当てられていない相手のプレゼンテーションにコメントすることは自由。 以下の説明をよく読んでプレゼンテーションを用意すること。 この課題には事前の準備が必要なので、早めに取り組むこと。特に、自分の研究に使えそうなデータを探す必要があることに注意。 7.2 分析計画のプレゼンテーション 7.2.1 プレゼンテーションの内容 以下の内容をすべて含むプレゼンテーションを行いなさい。 因果効果（処置効果）に関するリサーチクエスチョン 特定したい因果効果を明確にすること 例：「大学への進学は、生涯賃金を増やすか？」 例：「猫を飼うと、大学の成績は良くなるか？」 研究の対象となる母集団 因果効果の推定に用いる方法 因果効果の推定に用いるデータ 自分が選んだデータと推定方法で、自分のリサーチクエスチョンに答えらえると考える理由 プレゼンテーション時間は5分以上10分以内を目安とする（多少の時間超過は見逃すので、動画編集に余計な時間を費やす必要はない）。 スライドを作る際は、伝わるデザイン を参考に。 7.2.2 プレゼンテーションの方法 プレゼンテーションの条件：スライドを用いた音声つきの動画でプレゼンテーションを行うこと。 動画ファイルは、できれば MP4 形式 (.mp4) または M4V 形式 (.m4v) が望ましい。MP4またはM4V にできないときは相談してほしい。 その他の内容・動画の作り方は自由。自分の姿を写すかどうかも自由。動画は Slack で共有するので、私だけでなく、他の受講生も全員視聴することに注意。 自宅で声が出せない事情がある場合は、6月中に連絡してほしい。 7.2.3 プレゼンテーション動画の作成法 動画の作成法は自由である。例として、簡単な動画の作り方をいくつか提案し、それぞれの方法についての説明が記載されているウェブサイトを紹介する。他に良い方法があれば、Slack で共有してほしい。 7.2.3.1 Zoom ミーティングを録画する Zoom のミーティングを1人で行い、スライド画面を共有して録画すれば動画 (MP4 ファイル）ができる。おそらく、これが1番簡単である。 参考1 参考2 参考3 注意：無料版の Zoom ではクラウドレコーディングが使えないので、ローカルレコーディングを使う。 7.2.3.2 Keynote プレゼンテーションに音声を付ける MacのKeynote でスライドを作った場合は、この方法が使える。 参考4 参考5 参考6 7.2.3.3 PowerPoint に音声を付ける Microsoft Office PowerPoint でスライドを作った場合は、この方法が使える。 参考7 参考8 参考9 注意：ファイルを保存する際は、MP4を選択する。 7.2.4 提出方法と提出期限 提出方法：Slack の # プレゼン1_分析計画 チャンネルに投稿する。 提出するファイル（2つ提出） プレゼンテーションの動画 MP4 または M4V のファイル ファイル名：metrics_mid_LastFirst.mp4 （または metrics_mid_LastFirst.m4v） プレゼンテーションに使用したスライド 必ず PDF ファイル に変換すること ファイル名：metrics_mid_LastFirst.pdf 提出期限：7月17日（金）正午（日本時間） 7.3 他の受講生へのコメントについて このコメントも成績評価の対象になる。提出までの期間が短いので注意。 コメントの内容 分析計画の良いところをできるだけたくさん見つける。 計画の良くないところを批判する（その研究を改善することが目的であることを忘れずに） 良くないと思う理由をできるだけわかりやすく説明する。 どうすればもっと良くなるか、代替案を提示する。 提出するファイル コメントをまとめた PDF ファイル 2人に対するコメントを1つのファイルにまとめる。 誰に対するコメントかわかるようにすること。 ファイル名：metrics_comment_LastFirst.pdf 分量は自由（目安：1つの報告に対し1ページ） 提出方法：Slack の # プレゼン1_分析計画 チャンネルに投稿する。 7月17日（金）の正午以降に投稿すること。 提出期限：7月21日（火曜）正午（日本時間） 自分がコメントを担当する相手のプレゼンテーションが締切までに提出されなかったときは、遅れた分だけこの締め切りも延ばす（Slack上の投稿日時を基準にする）。 "],
["regression-discontinuity.html", "Topic 8 回帰不連続デザイン", " Topic 8 回帰不連続デザイン 準備中 "],
["instrumental-variable.html", "Topic 9 操作変数法", " Topic 9 操作変数法 準備中 "],
["final-presentation.html", "Topic 10 分析結果のプレゼンテーション 10.1 このトピックでやるべきこと 10.2 分析結果のレポート（期末レポート） 10.3 分析結果のプレゼンテーション", " Topic 10 分析結果のプレゼンテーション 10.1 このトピックでやるべきこと 分析結果をレポートにまとめて提出する。 分析結果の概要を発表する。 他の受講生のプレゼンテーションを視聴する。 以下の説明をよく読み、レポートとプレゼンテーションを用意すること。 10.2 分析結果のレポート（期末レポート） 10.2.1 レポートの内容 以下の内容を含むレポートを提出しなさい。 リサーチクエスチョン 分析計画のプレゼンテーションで発表した計画からの変更点 変更点がない場合は不要 計画全体を大幅に変更した（たとえば、リサーチクエスチョンを変えた）場合は、研究計画のプレゼンテーションで要求された内容も含めること 推定に用いた方法と統計モデル（推定に利用する式） 分析に用いたデータの説明 分析結果を示す図（図がないものは減点する） 分析結果の解釈 「統計的に有意」だけでは不十分：統計的に有意だからどうした？ リサーチクエスチョンに対する回答 どういうデータ（今回の分析では手に入らなかったが、自分が理想とするデータ）があれば、因果効果の推定がもっとうまくいくと考えられるか？ 注意：「うまくいく」は、統計的に有意な結果を出すことではない。 10.2.2 レポートの形式と提出方法 形式 レポートはR Markdown で書く R Markdown を knit してPDF ファイルを作る 提出するファイル R Markdown ファイル ファイル名：metrics_final_LastFirst.Rmd PDF ファイル ファイル名：metrics_final_LastFirst.pdf レポートに必要ないと思われるモノ（例：Rのwarnigs）は、見えないようにすることが望ましい 分析に使ったデータセット 私と共有できない事情がある場合は提出しなくてもよいが、提出期限より前に（できれば分析計画のプレゼンの際に）申し出ること 共有できない例：他の教員と共同で実施した実験データで、そのデータを使ってこれから論文を書く予定 共有できない例：データの利用申請を提出して手に入れたデータ Rで読み込みめれば形式は自由（例：.csv, .tsv, Rds） ファイル名は自由（よく考えてファイル名を付けるように） データセットは複数のファイルに分かれていても良い データを提出できない場合は、データに関する詳しい説明をレポートに含めること 提出方法 Slack のダイレクトメッセージで提出 提出期限：8月5日（水）正午（日本時間） 10.3 分析結果のプレゼンテーション 10.3.1 プレゼンテーションの内容 分析結果の概要を発表してもらう。時間に限りがあるので、分析結果のうち自分が注目すべきだと思う点に焦点を絞って発表すること。 プレゼンテーション時間は5分以上10分以内を目安とする（多少の時間超過は見逃すので、動画編集に余計な時間を費やす必要はない）。 プレゼンテーション動画の作り方について、Topic 7 を参照。 10.3.2 提出方法と提出期限 提出方法：Slack の # プレゼン2_分析結果 チャンネルに投稿する。 提出するファイル（2つ提出） プレゼンテーションの動画 MP4 または M4V のファイル ファイル名：metrics_result_LastFirst.mp4 （または metrics_result_LastFirst.m4v） プレゼンテーションに使用したスライド 必ず PDF ファイル に変換すること ファイル名：metrics_result_LastFirst.pdf 提出期限：8月5日（水）正午（日本時間） "],
["references.html", "参考文献", " 参考文献 Angrist, Joshua D., and Jörn-Steffen Pischke. 2009. Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton: Princeton University Press. Carnegie, Nicole Bohme, Masataka Harada, and Jennifer L. Hill. 2016. “Assesing Sensitivity to Unmeasured Confounding Using a Simulated Potential Confounder.” Journal of Research on Education Effectiveness 9 (3): 395–420. https://doi.org/10.1080/19345747.2015.1078862. Dehejia, Rajeev H., and Sadek Wahba. 2002. “Propensity Score-Matching Methods for Nonexperimental Causal Studies.” Review of Economics and Statistics 84 (1): 151–61. https://doi.org/10.1162/003465302317331982. Hansen, Bruce E. 2020. Econometrics. University of Wisconsin. https://www.ssc.wisc.edu/~bhansen/econometrics/. King, Gary, and Richard Nielsen. 2019. “Why Propensity Scores Should Not Be Used for Matching.” Political Analysis 27 (4): 435–54. https://doi.org/10.1017/pan.2019.11. LaLonde, Robert J. 1986. “Evaluating the Econometric Evaluations of Training Programs with Experimental Data.” American Economic Review 76 (4): 604–20. http://www.jstor.com/stable/1806062. List, John A., Sally Sadoff, and Mathis Wagner. 2011. “So You Want to Run an Experiment, Now What? Some Simple Rules of Thumb for Optimal Experimental Design.” Experimental Economics 14: 439. https://doi.org/10.1007/s10683-011-9275-7. Montgomery, Jacob M., Brendan Nyhan, and Michelle Torres. 2018. “How Conditioning on Posttreatment Variables Can Ruin Your Experiment and What to Do About It.” American Journal of Political Science 62 (3): 760–75. https://doi.org/10.1111/ajps.12357. R Core Team. 2020. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Thoermmes, Felix. J., and Eun Sook Kim. 2011. “A Systematic Review of Propensity Score Methods in the Social Sciences.” Multivariate Behavioral Research 3 (46): 514–43. https://doi.org/10.1080/00273171.2011.540475. 安井翔太. 2020. 効果検証入門：正しい比較のための因果推論/計量経済学の基礎. 技術評論社. 末石直也. 2015. 計量経済学：ミクロデータ分析へのいざない. 日本評論社. 浅野正彦, and 矢内勇生. 2018. Rによる計量政治学. オーム社. https://github.com/yukiyanai/quant-methods-R. 縄田和満. 2013. 確率・統計 I. 丸善出版. 西山慶彦, 新谷元嗣, 川口大司, and 奥井亮. 2019. 計量経済学. 有斐閣. "]
]
