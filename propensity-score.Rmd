# 傾向スコア

- [トピック5の講義スライド](http://yukiyanai.github.io/jp/classes/econometrics2/contents/slides/metrics2_topic05_slides.pdf) (PDF, 1.4MB)

## 準備

### 予習、講義動画、実習課題

このトピックでやるべきことは、以下のとおりである。

1. [シラバス(PDFファイル)](http://yukiyanai.github.io/jp/classes/econometrics2/docs/syllabus-applied-econometrics_2020-2Q.pdf) に記載されているトピック5の予習課題を読む。
2.  [KUTLMS (Moodle)](https://lms.kochi-tech.ac.jp/course/view.php?id=793) にあるトピック5の講義動画を視聴する。
3. この資料の続きを読み、Rを使った実習を行うことで、傾向スコアの使い方を学ぶ。
4. 教科書 [@yasui2020] 第3章のRを使った分析を自分でやってみる。
5. 課題を提出する。

### Rパッケージの読み込み

必要なパッケージを読み込み、作図用の日本語フォントを設定する。
```{r, message = FALSE}
pacman::p_load(tidyverse, broom,  haven,
               WeightIt, cobalt, MatchIt, survey)
theme_set(theme_gray(base_size = 10, base_family = "HiraginoSans-W3"))  # macOS用
#theme_set(theme_gray(base_size = 10, base_family = "Meiryo"))        # Windows用
#theme_set(theme_gray(base_size = 10, base_family = "ipaex"))         # Ubuntu用
#showtext::showtext_auto()                                            # Cloud用
#theme_set(theme_gray(base_size = 10, base_family = "noto"))          # Cloud用
```

### 関数の自作

R 4.0.0 より前のバージョンで **cobalt** パッケージを使おうとすると、「deparse1  という関数がありません」というエラーが出る。そこで、`deparse1()` を自作しておく。
`deparse1()` は R 4.0.0 で導入されたので、**4.0.0 以降のバージョンを使っている場合、この作業は不要**。
```{r}
if (as.integer(version$major) < 4) {
  deparse1 <- function(x) {
    paste(deparse(x), collapse = ' ')
  }
}
```


### このトピックで使うRコードの説明

#### `cut()`

`cut()` は連続値をとる変数をもとに、factor 型のカテゴリ変数を作るときに使う。
例として、0から1の間の値をとる変数をカテゴリ変数にしてみよう。

まず、変数をランダムに生成する。
```{r}
a <- runif(100, min = 0, max = 1)
summary(a)
```

この変数を、[0, 0.2], (0.2, 0.4], (0.4, 0.6], (0.6, 0.8], (0.8, 1.0] の5つのカテゴリに分類するカテゴリ変数を作る。
```{r}
f1 <- cut(a, breaks = seq(0, 1, by = 0.2), include.lowest = TRUE)
table(f1)
```

同様に、[0, 0.2), [0.2, 0.4), [0.4, 0.6), [0.6, 0.8), [0.8, 1.0] の5つのカテゴリにするには、`right = FALSE` にする。
```{r}
f2 <- cut(a, breaks = seq(0, 1, by = 0.2), include.lowest = TRUE,
          right = FALSE)
table(f2)
```

各カテゴリに属する観測数を同数にしたいときは、`quantile()` を利用して次のようにする。
```{r}
f3 <- cut(a, breaks = quantile(a, prob = seq(0, 1, by = 0.2)),
          include.lowest = TRUE)
table(f3)
```


## 傾向スコアを用いた因果推論の手順

傾向スコアを使った因果効果の推定は、以下の手順で行う。

1. 共変量の選定
2. 傾向スコアの推定
3. 傾向スコアを用いたバランス調整
  - 重み付け
  - 層別
  - マッチング$\ast$（@king-nielsen2019 によると、傾向スコアを用いたマッチングを因果効果の推定に用いることは推奨されないので、ここでは説明しない。層別も広い意味ではマッチングだが。）
4. 共変量のバランスチェック
5. 処置効果（因果効果）の推定
6. 感度分析$\ast$（この授業では時間の都合で説明できないが、興味があれば @carnegie2016 を参照されたい。**treatSens** というパッケージが用意されている。）


教科書 [@yasui2020] でも分析されている @lalonde1986 の実験データ [@dehejia2002] を使い、傾向スコアを使った分析手順を説明する。

まず、データを入手しよう（@yasui2020 の p.120 を参照）。後で読み込み直すことも考えて、data ディレクトリに一旦ダウンロードする。
```{r, eval = FALSE}
base_url <- "https://users.nber.org/~rdehejia/data/"
targets <- c("nsw_dw.dta", "cps_controls.dta", "cps_controls3.dta")
download.file(url = str_c(base_url, targets),
              destfile = str_c("data/", targets))
```
手に入れたデータを読み込む。
```{r}
d_cps1 <- read_dta("data/cps_controls.dta")
d_cps3 <- read_dta("data/cps_controls3.dta")
d_nsw <- read_dta("data/nsw_dw.dta")
```

実験データである d_nsw で回帰分析をしてみる。共変量を全部タイプして `+` で繋ぐのが面倒なので、次のようにする。
```{r}
covariates0 <- names(d_nsw)[2:(ncol(d_nsw) - 1)] %>% 
  str_c(collapse = " + ") 
```
これで、共変量が `+` で繋がれた文字列ができた。傾向スコアの推定では、共変量の数が多くなるので、こういう方法を覚えておいたほうがいい。ただし、このままだと使えないので、さらに次のようにする。
```{r}
rct_formula <- "re78 ~ " %>% 
  str_c(covariates0) %>% 
  formula()
```
これで、`lm()` で利用できる式 (formula) ができた。
```{r}
rct_formula
```

回帰式を推定する。
```{r}
ate_rct <- coef(lm(rct_formula, data = d_nsw))[2] %>% 
  print()
```
教科書に記載されているとおり、実験で推定された処置効果は $1676 であることがわかる。

次に、d_nsw の処置（介入）群を取り出して、d_cps1の処置群として扱うデータセットを作る。
```{r}
d_cps1_nsw <- d_nsw %>% 
  filter(treat == 1) %>% 
  rbind(d_cps1)
```

同様に、d_nsw の処置（介入）群を取り出して、d_cps3の処置群として扱うデータセットを作る。
```{r}
d_cps3_nsw <- d_nsw %>% 
  filter(treat == 1) %>% 
  rbind(d_cps3)
```


以下では、上のd_cps1_nsw を使って、傾向スコアを使った分析の手順を説明する。
**d_cps3_nswの分析は課題とする。**

## 共変量の選定

まず、データ d_cps1_nsw の中身を確認しよう。変数の数がそれほど多くないことがわかっているので、全体の要約統計量を表示して確認する。
```{r}
summary(d_cps1_nsw)
```
回帰分析の準備として、処置変数である treat （職業訓練の有無）と、結果変数である re78（1978年の収入）以外の変数を中心化する。また、教科書に倣い、re74 と re75 の二乗項も作る（ただし、標準化する）。

```{r}
myd <- d_cps1_nsw %>% 
  mutate(age_c = age - mean(age),
         education_c = education - mean(education),
         black_c = black - mean(black),
         hispanic_c = hispanic - mean(hispanic),
         married_c = married - mean(married),
         nodegree_c = nodegree - mean(nodegree),
         re74_c = re74 - mean(re74),
         re75_c = re75 - mean(re75),
         re74_sq_c = (re74_c^2 - mean(re74_c^2)) / sd(re74_c^2),
         re75_sq_c = (re75_c^2- mean(re75_c^2)) / sd(re75_c^2)) %>% 
  dplyr::select(re78, treat, ends_with("_c"))
```

念のため、中心化したデータを確認する。
```{r}
summary(myd)
```

この例では、処置変数と結果変数以外の変数をすべて使って傾向スコアを推定するが、自分でリサーチクエスチョンを立ててデータ分析を行う場合には、どの変数を傾向スコアの推定に使うかを考える必要がある。

ここですべての変数を使う理由は、それぞれの変数が結果変数には影響する（処置と結果の両者に影響するか、結果のみに影響する）と考えられるからである。

共変量あるいは傾向スコアによる調整を行わずに、処置群と統制群を単純比較してみよう。
```{r}
reg_simple <- lm(re78 ~ treat, data = myd)
tidy(reg_simple)
```
処置（職業訓練）は収入を $8498 **減らす** という誤った効果が推定されている。この回帰分析によれば、この効果は有意水準0.01 （あるいはもっと小さくてもOK。例えば0.000000001）で統計的に有意である。
「統計的に有意な結果が出たからこれで分析は終わりだ！」などと思ってしまったら、どうなるだろうか？

## 傾向スコアの推定

次に、傾向スコアを推定する。
ここでは、ロジスティック回帰で推定することにする。Rでロジスティック回帰（あるいはその他の一般化線形モデル [GLM]）を実行するには、`glm()` を使う。

ロジスティック回帰は、結果変数が $Y \in \{0, 1\}$、説明変数が $X$ だとすると、
$$
Y_i \sim \mbox{Bernoulli}(\theta_i)\\
\mathrm{logit}(\theta_i) = \alpha_0 + \alpha_1 X_{1i} + \cdots + \alpha_k X_{ik}
$$
という統計モデルである。つまり、結果変数を生成する確率分布が $\mbox{Bernoulli}(\theta_i) = \mbox{Binomial}(1, \theta_i)$ であり、リンク関数がロジット (logit) 関数であると仮定している。よって、`glm()` の引数で、`family = binomial(link = "logit")` を使い、`glm(Y ~ X1 + X2 + X3, family = binomial(link = 'logit'))` のようにして使う。

この例では共変量の数が多く、共変量を全部タイプして `+` で繋ぐのが面倒なので、次のようにする。
```{r}
covariates <- names(myd)[3:ncol(myd)]
ps_formula <- covariates %>% 
  str_c(collapse = " + ") %>% 
  str_c("treat ~ ", .) %>% 
  formula()
```
これで、`glm()` で利用できる式 (formula) ができた。
```{r}
ps_formula
```
これを使ってロジスティック回帰式を推定する。
```{r}
fit_logistic <- glm(ps_formula, data = myd,
                    family = binomial(link = "logit"))
```
これで推定ができた。推定結果の読み方については、@asano-yanai2018 の第15章を参照。

ここでは、傾向スコアの推定値にのみ興味がある。傾向スコアすなわち $\theta_i$ の推定値は、`fitted()` で取り出せる。
```{r}
myd$ps_logit <- fitted(fit_logistic)
```

推定された傾向スコアの分布を確認してみよう
```{r, fig.height = 4, fig.width = 6, message = FALSE}
hist_ps_logit <- ggplot(myd, aes(x = ps_logit, y = after_stat(density))) +
  geom_histogram(color = "black") +
  facet_grid(rows = vars(treat), scales = "free_y") +
  labs(x = "傾向スコアの推定値", y = "確率密度")
plot(hist_ps_logit)
```

統制群（0; 上段）と処置群（1; 下段）で傾向スコアの分布の傾向が大きく異なることがわかる（上段と下段で縦軸のスケールが異なる　["free_y" を指定した] ことに注意）。

念のため、他の種類の図も作ってみよう。
```{r, fig.height = 4, fig.width = 3}
box_ps_logit <- ggplot(myd, aes(x = as.factor(treat), y = ps_logit)) +
  geom_boxplot(width = 0.5) +
  labs(x = "処置", y = "傾向スコアの推定値")
plot(box_ps_logit)
```

箱ひげ図で見ても、分布が大きく異なることがわかる（ちなみに、あまりにも分布が異なるので、バイオリン図では違いがよく見えない。また、観測数が多いので、蜂群図を作るのも大変である。この辺りは試行錯誤が必要）。ヒストグラムでは、統制群に傾向スコアの値が0.1以上の個体があるかどうかがよくわからなかったが、箱ひげ図を描いてみたところ、分布の範囲自体は重なり合っていることがわかる。つまり、「共有（共通）サポート (common support)」はありそうだ。

このように、複数の種類の図を描き、多角的に検討することが必要である。


## バランス調整、バランスチェック、因果効果の推定

ここからは、バランス調整の方法別に、(1) その方法、(2) バランスチェック、(3) 因果効果の推定の3つのステップを合わせて説明する。バランス調整の方法として、次の方法を説明する

1. 重み付け
  - ATT を推定するための重み付け
  - ATE を推定するための重み付け（IPW）
2. 層別


### 重み付け

傾向スコアを利用した重み付けで因果効果を推定する方法を紹介する。推定の対象 (estimand) によって使う重みが異なるので、自分が何を推定したいのか明確にしておく必要がある。
通常、推定の対象としたいのは、ATE（平均処置効果）または ATT（処置群における平均処置効果）であることが多いので、この2つについて説明する。

#### ATT（処置群における平均処置効果）の推定

ATTを推定するために、傾向スコア $e_i(X)$ を用いて次の重み (weight) を計算する。
$$
w_i^{\mathrm{ATT}} = D_i + (1 - D_i) \frac{e_i(X)}{1 - e_i(X)}
$$
この重みを使うと、処置群 ($D_i = 1$) の個体の重みは $w_i^{\mathrm{ATT}} = 1$ になる。つまり、処置群の個体には、傾向スコアに関係なく等しい重みが与えられる。

それに対し、統制群 ($D_i = 0)$ の個体の重みは、$w_i^{\mathrm{ATT}} = e_i(X) / (1 - e_i(X))$
になる。つまり、傾向スコアが高いほど、大きな重みが与えられる。これは、傾向スコアが高い、すなわち処置群に入る確率が高いにも拘らず統制群に入った個体は、処置群の比較対象として重宝されるということを意味する。反対に、傾向スコアが低い個体は、処置群の比較対象としてあまり重要ではない（処置群にはそれによく似た個体が少ないのに、同種の個体が統制群にたくさんある）ので、割り引いて考えられるということである。

この重みを計算しよう。
```{r}
myd <- myd %>% 
  mutate(w_att = treat + (1 - treat) * ps_logit / (1 - ps_logit))
```

統制群でこの重みがどのように分布しているか確認しよう。
```{r, fig.width = 4, fig.height = 2}
hist_w_att <- myd %>% 
  filter(treat == 0) %>% 
  ggplot(aes(x = w_att, y = after_stat(density))) +
  geom_histogram(color = "black") +
  labs(x = "ATT を推定するための重み", y = "˚確率密度")
plot(hist_w_att)
```

統制群には傾向スコアが小さな個体ばかりが集まっていて、重みも0付近に集中していることがわかる。


```{r,include = FALSE, eval = FALSE}
att_before <- ggplot(myd, aes(x = ps_logit, y = after_stat(density))) +
  geom_histogram(color = "black") +
  facet_grid(row = vars(treat), scale = "free_y") +
  labs(x = "傾向スコア", y = "確率密度", title = "調整前")
att_after <- ggplot(myd, aes(x = ps_logit, y = after_stat(density), 
                             weight = w_att)) +
  geom_histogram(color = "black") +
  facet_grid(row = vars(treat)) +
  labs(x = "傾向スコア", y = "確率密度", title = "調整後")
quartz(file = "figs/att_before.pdf", type = "pdf", family = "jp",
       width = 3, height = 4)
print(att_before)
dev.off()
quartz(file = "figs/att_after.pdf", type = "pdf", family = "jp",
       width = 3, height = 4)
print(att_after)
dev.off()
```

**WeightIt** パッケージの`weightit()` を使えば、傾向スコアの推定と重みの計算が一挙にできる。傾向スコア (propensity score; ps) を使うために、`method = "ps"` を指定する。また、推定対象 (estimand) に "ATT" を指定する。
```{r, warning = FALSE}
w_att2 <- weightit(ps_formula, data = myd,
                   method = "ps", estimand = "ATT")
```

`weightit()` の結果を使うと、**cobalt** パッケージの `cobalt::bal.plot()` で重みによる調整前後の傾向スコアの分布も確認できる。
```{r, warning = FALSE, message = FALSE, fig.height = 4, fig.width = 5}
hist_w_att2 <- bal.plot(w_att2, var.name = "prop.score", which = "both",
         type = "histogram", mirror = TRUE,
         sample.names = c("調整前", "調整後")) +
  scale_fill_discrete(name = "処置") +
  labs(x = "傾向スコア", y = "割合", title = "傾向スコアの分布")
plot(hist_w_att2)
```

処置群における因果効果を推定するために処置群の分布に合わせて、**統制群の分布が調整された**ことがわかる。

この調整によって、共変量のバランスが改善したかどうか確認しよう。`cobalt::love.plot()` を使う。
```{r,fig.width = 6, fig.height = 4, warning = FALSE, message = FALSE}
bal_att <- love.plot(w_att2, threshold = 0.1, abs = TRUE, grid = TRUE, 
                     shapes = c(18, 20), color = c("tomato", "royalblue"), 
                     sample.names = c("調整前", "調整後"),
                     title = "共変量のバランス") +
  labs(x = "標準化平均差の絶対値",
       shape = "", size = "", stroke = "", colour = "")
plot(bal_att)
```

すべての共変量について、重み付けによって処置群と統制群の間のバランスが改善し、標準化平均差の絶対値が0.1未満になっていることがわかる。

この重みを使い、ATT $= \mathbb{E}[Y(1) \mid D = 1] - \mathbb{E}[Y(0) \mid D = 1]$を推定してみよう。
$\mathbb{E}[Y(1) \mid D = 1]$は、
```{r}
e_y1_d1 <- myd %>% 
  filter(treat == 1) %>% 
  pull(re78) %>% 
  mean() %>% 
  print()
```
と推定される。$\mathbb{E}[Y(0) \mid D = 1]$ は重みを使うと、
```{r}
e_y0_d1 <- myd %>% 
  filter(treat == 0) %>% 
  with(weighted.mean(re78, w = w_att)) %>% 
  print()
```
と、推定される。これらの差をとると、ATTは
```{r}
e_y1_d1 - e_y0_d1
```
であると推定される。RCT によるATEの推定結果は `r round(ate_rct, 2)` なので、効果が小さく推定されているが、重みを使わない単純な平均値の差に比べると、バイアスがかなり小さくなったことがわかる。

`lm()` で `weight` を指定すれば、これと同じ推定値が得られる。
```{r}
ps_weight_att1 <- lm(re78 ~ treat, data = myd, weight = w_att)
tidy(ps_weight_att1)
```
**WeightIt** パッケージの`weightit()` で推定した重みを使っても、同じ結果が得られる。
```{r}
ps_weight_att2 <- lm(re78 ~ treat, weights = w_att2$weights, data = myd)
tidy(ps_weight_att2)
```

#### IPW: ATE（平均処置効果）の推定

続いて、ATEを推定するための重み付けについて説明する。
ATE を推定するためには、**IPW** (inverse probability weighting; 逆確率重み付け) という方法を用いる。
ATE $= \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)]$ のそれぞれの項を、傾向スコアを利用した重み付けによって推定する。

$\mathbb{E}[Y(1)]$の推定値は、重み
$$
w_{1i} = \frac{D_i}{e_i(X)}
$$
を使って、
$$
\hat{\mathbb{E}}[Y(1)] =
\sum{\frac{w_{1i}Y_i}{\sum w_{1i}}} =
\sum{\frac{D_i / e_i(X)}{\sum \left[D_i / e_i(X)\right]} Y_i}
$$
である。また、$\mathbb{E}[Y(0)]$の推定値は、重みを
$$
w_{0i} = \frac{1 - D_i}{1 - e_i(X)}
$$
として、
$$
\hat{\mathbb{E}}[Y(0)] =
\sum{\frac{w_{0i}Y_i}{\sum w_{0i}}} =
\sum{\frac{(1 - D_i) / (1 - e_i(X))}{\sum \left[(1 - D_i) / (1 - e_i(X))\right]} Y_i}
$$
である。

このように、処置群と統制群のそれぞれについてその群に割り付けられる傾向スコアの逆数で重みが決まるので、この名前が付いている。IPW では、それぞれの群で珍しい個体ほど重みが大きくなる。
この重み、
$$
w_i =   \frac{D_i}{e_i(X)} + \frac{1 - D_i}{1 - e_i(X)}
$$
を計算しよう
```{r}
myd <- myd %>% 
  mutate(w_ate = ifelse(treat == 1, 
                        1 / ps_logit, 
                        1 / (1 - ps_logit)))
```
この重みがどのように分布しているか確認しよう。
```{r, fig.width = 4, fig.height = 3}
hist_w_ate <- myd %>% 
  ggplot(aes(x = w_ate, y = after_stat(density))) +
  geom_histogram(color = "black") +
  facet_grid(row = vars(treat)) +
  labs(x = "IPWによる重み", y = "˚確率密度")
plot(hist_w_ate)
```

処置群で傾向スコアが大きい個体の重みが割り引かれている一方で、統制群に傾向スコアが大きい個体があまりないため、重みが割増されている個体はあまりないことがわかる。

`WeightIt::weightit()` で重みを計算してみよう。推定対象 (estimand) に "ATE" を指定する。
```{r, warning = FALSE}
w_ate2 <- weightit(ps_formula, data = myd,
                   method = "ps", estimand = "ATE")
```

`cobalt::bal.plot()` で重みによる調整前後の傾向スコアの分布を確認する。
```{r, warning = FALSE, message = FALSE, fig.height = 4, fig.width = 5}
hist_w_ate2 <- bal.plot(w_ate2, var.name = "prop.score", which = "both",
         type = "histogram", mirror = TRUE,
         sample.names = c("調整前", "調整後")) +
  scale_fill_discrete(name = "処置") +
  labs(x = "傾向スコア", y = "割合", title = "傾向スコアの分布")
plot(hist_w_ate2)
```

調整後に、処置群の分布が統制群の分布に近づいていることがわかる。これは、処置群の観測数が 185 であるのに対して、統制群の観測数が 16,177 もあるためである。

この調整によって、共変量のバランスが改善したかどうか確認しよう。`cobalt::love.plot()` を使う。
```{r,fig.width = 6, fig.height = 4, warning = FALSE, message = FALSE}
bal_ate <- love.plot(w_ate2, threshold = 0.1, abs = TRUE, grid = TRUE, 
                     shapes = c(18, 20),
                     color = c("tomato", "royalblue"), 
                     sample.names = c("調整前", "調整後"),
                     title = "共変量のバランス") +
  labs(x = "標準化平均差の絶対値",
       shape = "", size = "", stroke = "", colour = "")
plot(bal_ate)
```

すべての共変量についてバランスの改善は見られるものの、標準化平均値の絶対値が0.1未満になった共変量は3つだけであり、処置群と統制群のバランスがあまりよくないことがわかる。そのため、このまま処置効果を推定してもうまくいかない（バイアスが残る）ことが予想される。

実際のデータ分析では、このような場合には処置効果を推定しないほうがいい。ここでは、推定をしてしまうとどうなるか見てみよう。

```{r,include = FALSE, eval = FALSE}
ate_before <- ggplot(myd, aes(x = ps_logit, y = after_stat(density))) +
  geom_histogram(color = "black") +
  facet_grid(row = vars(treat), scale = "free_y") +
  labs(x = "傾向スコア", y = "確率密度", title = "調整前")
ate_after <- ggplot(myd, aes(x = ps_logit, y = after_stat(density), 
                             weight = w_ate)) +
  geom_histogram(color = "black") +
  facet_grid(row = vars(treat)) +
  labs(x = "傾向スコア", y = "確率密度", title = "調整後")
quartz(file = "figs/ate_before.pdf", type = "pdf", family = "jp",
       width = 3, height = 4)
print(ate_before)
dev.off()
quartz(file = "figs/ate_after.pdf", type = "pdf", family = "jp",
       width = 3, height = 4)
print(ate_after)
dev.off()
```


上で計算した重みを使い、ATE $= \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)]$を推定する。
まず、$Y(1)$ の期待値の推定値は、
```{r}
e_y1 <- myd %>% 
  filter(treat == 1) %>% 
  with(weighted.mean(re78, w = w_ate)) %>% 
  print()
```
である。$Y(0)$ の期待値の推定値は、
```{r}
e_y0 <- myd %>% 
  filter(treat == 0) %>% 
  with(weighted.mean(re78, w = w_ate)) %>% 
  print()
```
である。これらの差をとると、ATEは
```{r}
e_y1 - e_y0
```
であると推定される。教科書 (pp.127-130) にも書かれているとおり、推定に大きなバイアスがあることがわかる。

`lm()` で `weight` を指定すれば、これと同じ結果が得られる。
```{r}
ps_weight_ate1 <- lm(re78 ~ treat, data = myd, weight = w_ate)
tidy(ps_weight_ate1)
```

`WeightIt::weightit()` で計算した重みを使っても、同じ結果が得られる。

```{r}
ps_weight_ate2 <- lm(re78 ~ treat, weights = w_ate2$weights, data = myd)
tidy(ps_weight_ate2)
```

このように、共変量のバランスがとれていない状態で因果効果を推定しようとすると、バイアスのある推定結果を得ることになるので、注意が必要である。


### 層別

推定した傾向スコアを利用して、サンプルを層 (strata) に分ける。まず、層の数を決める必要がある。ここでは5にする（層の数については、@thoe2011 を参照）
。処置群と統制群の合計数がほぼ同じになるように、傾向スコアによって5つの層を作ろう。
```{r}
myd %>% 
  mutate(subclass = cut(ps_logit, 
                        breaks = quantile(ps_logit, prob = seq(0, 1, by = 0.2)),
                        include.lowest = TRUE)) %>% 
  with(table(treat, subclass))
```
 このような5つの層 (stratum; subclass) ができる。

**MatchIt** パッケージの `matchit()` を使えば、傾向スコアの推定と層別が一挙にできる。
層別のために `method = "subclass"` を指定する。また、層の数を `subclass = 5` で、処置群と統制群の合計数、つまりサンプル全体の数を基準にして層別を行うため、 `sub.by = "all"` を指定する。
```{r}
matchit(ps_formula,  data = myd,
        method = "subclass", subclass = 5, sub.by = "all") %>% 
  with(table(treat, subclass))
```
先ほどと同じ5つの層ができた。

この層別では、3つの層で処置群の個体数が0になってしまった。そんため、それら3つの層では処置効果が推定できない。この例から、処置群と統制群で傾向スコアの分布が大きく異なると、層別が難しいことがわかる。統制群のほとんどの個体にとって、処置群に比較対象となる個体が存在しない状況なので、ATE や ATC を推定するのは困難である。

このデータでは、統制群の観測数に対して処置群の観測数が非常に少ないので、処置群の観測数が等しくなるような5層を作り、ATT の推定を目指すことにしよう。

まず、処置群の個体を5分割するためのカットポイントを見つける。すべてのデータを含むために、最下限と最上限は0と1にする。
```{r}
cutpoints <- myd %>% 
  filter(treat == 1) %>% 
  pull(ps_logit) %>% 
  quantile(prob = seq(0, 1, by = 0.2))
cutpoints[1] <- 0
cutpoints[6] <- 1
```
このカットポイントを使って、サンプルを5層に分ける。
```{r}
myd %>% 
  mutate(subclass = cut(ps_logit, breaks = cutpoints, include.lowest = TRUE)) %>% 
  with(table(treat, subclass))
```
このように、処置群の観測数が等しい5つの層ができた。

`MatchIt::matchit()` で層別を行ってみよう。処置群に基づいて層別を行うために、`sub.by = "treat"` を指定する。
```{r}
stratification <- matchit(ps_formula,  data = myd,
        method = "subclass", subclass = 5, sub.by = "treat") 
with(stratification, table(treat, subclass))
```
上と同じ層別ができた。層の名前が整数値で1から5になっているこちらの層別のほうが便利なので、以下ではこのカテゴリ変数を使う。
```{r}
myd$subclass <- stratification$subclass
```

バランスチェックは、**MatchIt** パッケージの機能を使って行うことができる。`MatchIt::matchit()` の結果に対し、`summary()` を使う。
```{r}
summary(stratification, standardize = TRUE)
```

サンプル全体での共変量のバランス (Summary of balance for all data) と、各層 (subclass) での共変量のバランス (Summary of balance by subclasses) が表示されている。ほとんどの共変量について、全体よりも層別した方が標準化平均差 (Std. Mean Diff.) の絶対値 が小さくなっている。しかし、基準である 0.1 または 0.25 よりも大きい差が複数残されており、層別によるバランスはあまり良くないことがわかる。
ヒスパニックであることを示す変数については全体でのバランスが元々良いため、サブクラスにすることによってバランスがむしろ悪化している（特に、層1と層2で特に平均差が大きい）。

図でバランスチェックするには、例えば次のようにする。
```{r, fig.height = 4, fig.width = 7}
bal_subclass <- stratification %>% 
  love.plot(stats = "m",    # 平均差
            binary = "std", # 標準化
            abs = TRUE,     # 絶対値
            disp.subclass = TRUE,
            threshold = 0.1, grid = TRUE,
            shapes = c(18, 20), color = c("tomato", "royalblue"), 
            title = "共変量のバランス") +
  labs(x = "標準化平均差の絶対値",
       shape = "", size = "", stroke = "", colour = "")
plot(bal_subclass)
```
このように、処置群と統制群の間のバランスが悪いので、実際のデータ分析であれば因果効果を推定しない方が良い。しかし、ここではこの層別を利用してATTを推定するとどうなるか確認してみよう。

まず、層別のATTを推定する。各層で処置群と統制群の平均値の差を計算すれば良い。
```{r, message = FALSE, warning = FALSE}
subclass_att <- myd %>% 
  group_by(subclass, treat) %>% 
  summarize(mean = mean(re78)) %>% 
  group_by(subclass) %>% 
  summarize(att = diff(mean)) %>% 
  pull(att) %>% 
  print()
```

この層別のATTの加重平均がATT である。その際の重みは、各層に属する処置群の個体数を、処置群全体の個体数で割ったものである。同じ個体数で5つの層に分けたので、当然すべての重みが0.2であるが、一応計算しておく。
```{r}
w_subclass <- myd %>% 
  filter(treat == 1) %>% 
  with(table(subclass) / sum(table(subclass))) %>% 
  print()
```
（ちなみに、ATEを推定する場合の各層の重みは、各層に属する個体数をサンプルサイズで割ったものである。つまり、全サンプルに占める各層の割合が重みとなる。）

よって、ATTの推定値は、
```{r}
#mean(subclass_att) # すべて同じ重みなので、単純平均でも同じ
weighted.mean(subclass_att, w = w_subclass)
```
である。効果が過小推定されており、バイアスが残っていることがわかる。やはり、**バランスが悪いのに因果効果を推定しようとしてはいけない**。

標準誤差も知りたいので、**survey** パッケージを利用して計算しよう。
まず、`survey::svydesign()` で利用するデータセットを指定する。引数 `ids` が必須だが、ここでは id （観測個体の識別子）を利用した分析を行わないので `ids = ~ 0` とする（`svydesign()` の引数に `strata` があるが、これはサーベイの層別を指定するための引数で、傾向スコアによる層別を指定するものではないので注意。ここでは何も指定しない）。
```{r, message = FALSE, warning = FALSE}
survey_design <- svydesign(ids = ~ 0, data = myd)
```

次に、`survey::svyby()` を使って、層別に結果変数の平均値を計算する。`formula` に平均値を計算したい結果変数を指定し、`by` に処置変数と層別の変数を指定する。
平均値を計算するので、`FUN = svymean` とする。
```{r}
sub_means <- svyby(formula = ~ re78, by = ~ treat + subclass, 
                   design = survey_design, FUN = svymean) %>% 
  print()
```
このように、各層別に、処置群と統制群のそれぞれで結果変数の平均値が計算される。

最後にATT の推定値と標準誤差を、`survey::svycontrast()` で計算する。
そのために、重みをリストで与える必要がある。上の表（処置・層別の平均値の表）で表示されている順番に重みを指定する。その際、処置群には先ほど計算した重みである0.2 を与え、統制群にはそれを負の値にしたものを与える。
```{r,message = FALSE, warning = FALSE}
svycontrast(sub_means, list(ATT = rep(c(-0.2, 0.2), 5)))
```
上で計算したものと同じ推定値が得られた。また、標準誤差は636.8 であることがわかった。
（これは有意水準 0.05 で統計的に有意ではない。）

このように、調査・観察データを使った因果推論には、様々な工夫が必要であり、慎重に分析を進める必要がある。
また、さまざまな仮定をおいて分析を行っており、仮定が成り立たない場合には、因果効果を正しく推定できない。
自分がどのような仮定に基づいてデータを分析しているのか、常に意識するようにしよう。

## トピック5 の課題

上で作ったデータセット d_cps3_nsw を使って、傾向スコアを用いた因果推論を行いなさい。
以下の内容を必ず含めること。

1. 傾向スコアを使わずに、統制群と処置群を単純比較した場合の効果の推定値を求める。
2. 傾向スコアによるバランスの調整（ATEとATTのどちらを推定しようとしているか明確に）。以下の2つを実施する。
  - 重み付け
  - 層別
3. 上のそれぞれについて、バランスチェックを行う。
4. それぞれの方法で、処置効果を推定する。
5. 1で求めた推定値と4で求めた推定値を比較して、どのようなことがわかるか説明する。


**注意事項**

- 課題レポートは R Markdown で作成し、PDF に knit して提出すること。
- 提出するファイル：metrics_hw05_LastFirst.pdf
- 提出方法：Slack のダイレクトメッセージで提出。
- **提出期限：2020年7月6日（月）正午**（日本時間）
